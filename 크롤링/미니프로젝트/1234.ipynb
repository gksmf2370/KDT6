{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def get_links(link_list, name_list, career_list, education_list, worker_list, city_list):\n",
    "    '''\n",
    "    잡코리아 링크 가져오는 함수\n",
    "    parms= 링크 모아놓을 빈 리스트\n",
    "    return\n",
    "    '''\n",
    "    num = 1\n",
    "    regions = [\"서울\", \"도쿄\", \"부산\", \"대구\", \"인천\", \"광주\", \"대전\", \"울산\", \"세종\", \"경기\", \"강원\", \"충북\", \"충남\", \"전북\", \"전남\", \"경북\", \"경남\", \"제주\"]\n",
    "    workers = [\"정규직\", \"계약직\", \"인턴\", \"파견직\", \"도급\", \"프리랜서\", \"아르바이트\", \"연수생/교육생\", \"병역특례\", \"위촉직/개인사업자\"]\n",
    "    \n",
    "    while num <= 2:\n",
    "        url = urlopen(f'https://www.jobkorea.co.kr/Search/?stext=c%2B%2B&tabType=recruit&Page_No={num}')\n",
    "        soup = BeautifulSoup(url, 'html.parser')\n",
    "\n",
    "        # 회사명과 링크 가져오기\n",
    "        company_tags = soup.find_all('a', {'class': \"name dev_view\"})\n",
    "        for tag in company_tags:\n",
    "            link = tag['href']\n",
    "            name = tag['title']\n",
    "            link_list.append(link)\n",
    "            name_list.append(name)\n",
    "\n",
    "        # 경력, 학력, 근무형태, 지역 정보 가져오기\n",
    "        job_info_tags = soup.find_all('ul', {'class': \"supportCondition\"})\n",
    "        for tag in job_info_tags:\n",
    "            li_items = tag.find_all('li')\n",
    "            career = None\n",
    "            education = None\n",
    "            city = None\n",
    "            worker_type = None\n",
    "\n",
    "            for item in li_items:\n",
    "                text = item.text.strip()\n",
    "                if \"경력\" in text or \"신입\" in text:\n",
    "                    career = text\n",
    "                elif \"졸\" in text or \"무관\" in text:\n",
    "                    education = text\n",
    "                elif any(worker in text for worker in workers):\n",
    "                    worker_type = text\n",
    "                elif any(region in text for region in regions):\n",
    "                    city = text\n",
    "\n",
    "            career_list.append(career if career else 'null')\n",
    "            education_list.append(education if education else 'null')\n",
    "            worker_list.append(worker_type if worker_type else 'null')\n",
    "            city_list.append(city if city else 'null')\n",
    "\n",
    "        num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list=[]\n",
    "name_list=[]\n",
    "career_list = []\n",
    "education_list = []\n",
    "worker_list = []\n",
    "city_list = []\n",
    "get_links(link_list, name_list, career_list, education_list, worker_list, city_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data ={'name': name_list,\n",
    "       'link': link_list,\n",
    "       'career': career_list,\n",
    "       'education': education_list,\n",
    "       'worker' : worker_list,\n",
    "       'city':city_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(link_list),len(name_list),len(career_list),len(education_list),len(city_list),len(worker_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
