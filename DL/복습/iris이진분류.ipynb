{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN 기반 이진분류 모델 구현\n",
    "- 데이터셋 : iris.scv\n",
    "- 피쳐 : 4개\n",
    "- 타겟 : variety [setosa와 나머지]\n",
    "- 학습방법 : 지도학습 - 분류 - 이진분류\n",
    "- 알고리즘 : 인공신경망(ANN) => MLP, DNN : 은닉층이 많은 구성\n",
    "- 프레임워크 : pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 관련 모듈 로딩\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import F1Score, BinaryF1Score\n",
    "from torchmetrics.classification import BinaryConfusionMatrix\n",
    "from torchinfo import summary\n",
    "\n",
    "# Data 관련 모듈 로딩\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch V. 2.4.1\n",
      "Pandas V. 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# 활용 패키지 버전 체크 => 사용자 정의 함수로 구현하기\n",
    "print(f'Pytorch V. {torch.__version__}')\n",
    "print(f'Pandas V. {torch.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로딩\n",
    "FILE_PATH='../data/iris.csv'\n",
    "\n",
    "# CSV => DataFrame\n",
    "irisDF=pd.read_csv(FILE_PATH)\n",
    "\n",
    "# 데이터 확인\n",
    "irisDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Setosa', 'Versicolor', 'Virginica'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟 변경 => 정수화, 클래스 3개 => 2개\n",
    "irisDF['variety'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisDF['variety'] =(irisDF['variety'] =='Setosa')\n",
    "irisDF['variety'] = irisDF['variety'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고유값 : [1 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0           5.1          3.5           1.4          0.2        1\n",
       "1           4.9          3.0           1.4          0.2        1\n",
       "2           4.7          3.2           1.3          0.2        1\n",
       "3           4.6          3.1           1.5          0.2        1\n",
       "4           5.0          3.6           1.4          0.2        1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'고유값 : {irisDF[\"variety\"].unique()}')\n",
    "irisDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 클래스 설계 및 정의<hr>\n",
    "- 클래스목적 : iris 데이터를 학습 및 추론 목적 \n",
    "- 클래스이름 : IrisBCFModel\n",
    "- 부모클래스 : nn.Module\n",
    "- 매개변수 : 층별 입출력 개수 고정하기때문에 필요 없음\n",
    "- 속성필드 : \n",
    "- 기능역할 : __init__() : 모델 구조, forward() : 순방향 학습 <= 오버라이딩\n",
    "- 클래스구조\n",
    "    * 입력층 : 입력  4개(피처)  출력 10개(퍼셉트론/뉴런 10개 존재)\n",
    "    * 은닉층 : 입력 10개        출력 5개(퍼셉트론/뉴런 5개 존재)\n",
    "    * 출력층 : 입력  5개        출력 1개(퍼셉트론/뉴런 1개 존재 : 2진분류)\n",
    "\n",
    "- 활성화함수\n",
    "    * 클래스형태 => nn.MESLoss, nn.ReLU => __init__() 메서드\n",
    "    * 함수형태 => torch.nn.fuctional 아래에 => forward() 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisBCFModel(nn.Module): # 이진분류\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__() # 부모\n",
    "\n",
    "        self.in_layer = nn.Linear(4,10) #입력층\n",
    "        self.h_layer = nn.Linear(10,5) #은닉층\n",
    "        self.out_layer = nn.Linear(5,1) #출력층\n",
    "\n",
    "    # 순방향 학습 진행 메서드\n",
    "    def forward(self, x):\n",
    "        y=F.relu(self.in_layer(x))\n",
    "        y=F.relu(self.h_layer(y))\n",
    "        return F.sigmoid(self.out_layer(y)) # 2진 분류는 출력층이 시그모이드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IrisBCFModel(\n",
      "  (in_layer): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (h_layer): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (out_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model=IrisBCFModel()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "IrisBCFModel                             [1000, 1]                 --\n",
       "├─Linear: 1-1                            [1000, 10]                50\n",
       "├─Linear: 1-2                            [1000, 5]                 55\n",
       "├─Linear: 1-3                            [1000, 1]                 6\n",
       "==========================================================================================\n",
       "Total params: 111\n",
       "Trainable params: 111\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.11\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 0.13\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.14\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 사용 메모리 정보 확인\n",
    "summary(model, input_size=(1000,4)) #첫번째는 입력데이터수, 두번째는 피쳐수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 클래스 설계 및 정의<hr>\n",
    "- 데이터셋 : iris.csv\n",
    "- 피쳐개수 : 4개\n",
    "- 타겟개수 : 1개\n",
    "- 클래스이름 : IrisDataset\n",
    "- 부모클래스 : utils.data.Dataset\n",
    "- 속성필드 : featureDF, targetDF, n_rows, n_features\n",
    "- 필수메서드\n",
    "    * __init__(self) : 데이터셋 저장 및 전처리, 개발자가 필요한 속성 설정\n",
    "    * __len__(self) : 데이터의 개수 반환\n",
    "    * __getitem__(self, index) : 특정 인덱스의 피쳐와 타겟 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        self.featureDF=featureDF\n",
    "        self.targetDF=targetDF\n",
    "        self.n_rows=featureDF.shape[0]\n",
    "        self.n_features=featureDF.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 넘파이를 텐서로\n",
    "        featureTS=torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS=torch.FloatTensor(self.targetDF.iloc[index].values)        \n",
    "        # 피쳐와 타겟 반환\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureDF => (150, 4), targetDF => (150, 1)\n"
     ]
    }
   ],
   "source": [
    "# 피쳐, 타겟 추출\n",
    "featureDF, targetDF=irisDF[irisDF.columns[:-1]], irisDF[irisDF.columns[-1:]]\n",
    "print(f'featureDF => {featureDF.shape}, targetDF => {targetDF.shape}')\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "irisDS=IrisDataset(featureDF, targetDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 준비\n",
    "- 학습 횟수 : EPOCH <= 처음부터 끝까지 학습하는 단위\n",
    "- 배치 크기 : BATCH_SIZE <= 한번에 학습할 데이터셋 양\n",
    "- 위치 지정 : DEVICE <= 텐서 저장 및 실행 위치 (GPU/CPU)\n",
    "- 학습률 : LR 가중치와 절편 업데이트 시 경사하강법으로 업데이트 간격 설정 0.001~0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 진행 관련 설정\n",
    "EPOCH=1000\n",
    "BATCH_SIZE=10\n",
    "BATCH_CNT=irisDF.shape[0]/BATCH_SIZE\n",
    "DEVICE= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인스턴스/객체 : 모델, 데이터셋, 최적화 (+ 손실함수, 성능지표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 4) (38, 4) (28, 4)\n",
      "(84, 1) (38, 1) (28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스\n",
    "model=IrisBCFModel()\n",
    "\n",
    "# 데이터셋 인스턴스\n",
    "\n",
    "# 학습용, 검증용, 테스트용 데이터 분리\n",
    "X_train, X_test, y_train, y_test=train_test_split(featureDF, targetDF, random_state=1)\n",
    "X_train, X_val, y_train, y_val=train_test_split(X_train, y_train, random_state=1)\n",
    "print(f'{X_train.shape} {X_test.shape} {X_val.shape}')\n",
    "print(f'{y_train.shape} {y_test.shape} {y_val.shape}')\n",
    "\n",
    "trainDS=IrisDataset(X_train, y_train)\n",
    "valDS=IrisDataset(X_val, y_val)\n",
    "testDS=IrisDataset(X_test, y_test)\n",
    "\n",
    "# 데이터로드 인스턴스\n",
    "trainDL=DataLoader(trainDS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 인스턴스 => W, b 텐서 즉, model.parameters() 전달\n",
    "optimizer=optim.Adam(model.parameters(),lr=LR)\n",
    "\n",
    "# 손실함수 인스턴스 => 분류 => 이진분류 BinaryCrossEntropyLoss => BCELoss\n",
    "#                            예측값은 확률값으로 전달 => sigmoid() AF 처리 후 전달\n",
    "bceLoss=nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000]\n",
      "- [TRAIN] LOSS : 0.4482939759890238 [SCORE] : 0.26263071099917096\n",
      "[1/1000]\n",
      "- [VAL] LOSS : 0.6894301772117615 [SCORE] : 0.6000000238418579\n",
      "[2/1000]\n",
      "- [TRAIN] LOSS : 0.4291562000910441 [SCORE] : 0.26263071099917096\n",
      "[2/1000]\n",
      "- [VAL] LOSS : 0.6760192513465881 [SCORE] : 0.6000000238418579\n",
      "[3/1000]\n",
      "- [TRAIN] LOSS : 0.41556172370910643 [SCORE] : 0.26263071099917096\n",
      "[3/1000]\n",
      "- [VAL] LOSS : 0.666265070438385 [SCORE] : 0.6486486196517944\n",
      "[4/1000]\n",
      "- [TRAIN] LOSS : 0.40386046171188356 [SCORE] : 0.40484330654144285\n",
      "[4/1000]\n",
      "- [VAL] LOSS : 0.6561342477798462 [SCORE] : 1.0\n",
      "[5/1000]\n",
      "- [TRAIN] LOSS : 0.3924932718276978 [SCORE] : 0.6\n",
      "[5/1000]\n",
      "- [VAL] LOSS : 0.6458105444908142 [SCORE] : 1.0\n",
      "[6/1000]\n",
      "- [TRAIN] LOSS : 0.381380025545756 [SCORE] : 0.4446560879548391\n",
      "[6/1000]\n",
      "- [VAL] LOSS : 0.6356163620948792 [SCORE] : 0.1538461595773697\n",
      "[7/1000]\n",
      "- [TRAIN] LOSS : 0.37059656778971356 [SCORE] : 0.03333333333333333\n",
      "[7/1000]\n",
      "- [VAL] LOSS : 0.6258201599121094 [SCORE] : 0.0\n",
      "[8/1000]\n",
      "- [TRAIN] LOSS : 0.36041928132375084 [SCORE] : 0.0\n",
      "[8/1000]\n",
      "- [VAL] LOSS : 0.6173095107078552 [SCORE] : 0.0\n",
      "[9/1000]\n",
      "- [TRAIN] LOSS : 0.3507697582244873 [SCORE] : 0.0\n",
      "[9/1000]\n",
      "- [VAL] LOSS : 0.6097778677940369 [SCORE] : 0.0\n",
      "[10/1000]\n",
      "- [TRAIN] LOSS : 0.3416611949602763 [SCORE] : 0.0\n",
      "[10/1000]\n",
      "- [VAL] LOSS : 0.6029404997825623 [SCORE] : 0.0\n",
      "[11/1000]\n",
      "- [TRAIN] LOSS : 0.33328850865364074 [SCORE] : 0.0\n",
      "[11/1000]\n",
      "- [VAL] LOSS : 0.5973894000053406 [SCORE] : 0.0\n",
      "[12/1000]\n",
      "- [TRAIN] LOSS : 0.32603176434834796 [SCORE] : 0.0\n",
      "[12/1000]\n",
      "- [VAL] LOSS : 0.5928857922554016 [SCORE] : 0.0\n",
      "[13/1000]\n",
      "- [TRAIN] LOSS : 0.3198387245337168 [SCORE] : 0.0\n",
      "[13/1000]\n",
      "- [VAL] LOSS : 0.5857552886009216 [SCORE] : 0.0\n",
      "[14/1000]\n",
      "- [TRAIN] LOSS : 0.3138719956080119 [SCORE] : 0.0\n",
      "[14/1000]\n",
      "- [VAL] LOSS : 0.5780307054519653 [SCORE] : 0.0\n",
      "[15/1000]\n",
      "- [TRAIN] LOSS : 0.3082712431748708 [SCORE] : 0.0\n",
      "[15/1000]\n",
      "- [VAL] LOSS : 0.5716348886489868 [SCORE] : 0.0\n",
      "[16/1000]\n",
      "- [TRAIN] LOSS : 0.3027404526869456 [SCORE] : 0.0\n",
      "[16/1000]\n",
      "- [VAL] LOSS : 0.565533459186554 [SCORE] : 0.0\n",
      "[17/1000]\n",
      "- [TRAIN] LOSS : 0.2972428023815155 [SCORE] : 0.0\n",
      "[17/1000]\n",
      "- [VAL] LOSS : 0.5587600469589233 [SCORE] : 0.0\n",
      "[18/1000]\n",
      "- [TRAIN] LOSS : 0.29182584484418234 [SCORE] : 0.0\n",
      "[18/1000]\n",
      "- [VAL] LOSS : 0.5512672066688538 [SCORE] : 0.0\n",
      "[19/1000]\n",
      "- [TRAIN] LOSS : 0.28642034928003945 [SCORE] : 0.0\n",
      "[19/1000]\n",
      "- [VAL] LOSS : 0.5428634285926819 [SCORE] : 0.0\n",
      "[20/1000]\n",
      "- [TRAIN] LOSS : 0.2810079554716746 [SCORE] : 0.0\n",
      "[20/1000]\n",
      "- [VAL] LOSS : 0.5337066054344177 [SCORE] : 0.0\n",
      "[21/1000]\n",
      "- [TRAIN] LOSS : 0.27559197346369424 [SCORE] : 0.0\n",
      "[21/1000]\n",
      "- [VAL] LOSS : 0.524226725101471 [SCORE] : 0.0\n",
      "[22/1000]\n",
      "- [TRAIN] LOSS : 0.27013375560442604 [SCORE] : 0.0\n",
      "[22/1000]\n",
      "- [VAL] LOSS : 0.5149246454238892 [SCORE] : 0.0\n",
      "[23/1000]\n",
      "- [TRAIN] LOSS : 0.26453979015350343 [SCORE] : 0.0\n",
      "[23/1000]\n",
      "- [VAL] LOSS : 0.50489741563797 [SCORE] : 0.0\n",
      "[24/1000]\n",
      "- [TRAIN] LOSS : 0.25876991351445516 [SCORE] : 0.0\n",
      "[24/1000]\n",
      "- [VAL] LOSS : 0.4935271441936493 [SCORE] : 0.0\n",
      "[25/1000]\n",
      "- [TRAIN] LOSS : 0.25287830630938213 [SCORE] : 0.0\n",
      "[25/1000]\n",
      "- [VAL] LOSS : 0.48135843873023987 [SCORE] : 0.0\n",
      "[26/1000]\n",
      "- [TRAIN] LOSS : 0.24686368107795714 [SCORE] : 0.0\n",
      "[26/1000]\n",
      "- [VAL] LOSS : 0.46895503997802734 [SCORE] : 0.0\n",
      "[27/1000]\n",
      "- [TRAIN] LOSS : 0.24066437681516012 [SCORE] : 0.0\n",
      "[27/1000]\n",
      "- [VAL] LOSS : 0.4560544192790985 [SCORE] : 0.0\n",
      "[28/1000]\n",
      "- [TRAIN] LOSS : 0.23429443836212158 [SCORE] : 0.0\n",
      "[28/1000]\n",
      "- [VAL] LOSS : 0.44251784682273865 [SCORE] : 0.1538461595773697\n",
      "[29/1000]\n",
      "- [TRAIN] LOSS : 0.22773784001668293 [SCORE] : 0.026666667064030966\n",
      "[29/1000]\n",
      "- [VAL] LOSS : 0.4281880259513855 [SCORE] : 0.1538461595773697\n",
      "[30/1000]\n",
      "- [TRAIN] LOSS : 0.22109251022338866 [SCORE] : 0.026666667064030966\n",
      "[30/1000]\n",
      "- [VAL] LOSS : 0.41393083333969116 [SCORE] : 0.2857142984867096\n",
      "[31/1000]\n",
      "- [TRAIN] LOSS : 0.2142629086971283 [SCORE] : 0.2200000027815501\n",
      "[31/1000]\n",
      "- [VAL] LOSS : 0.3991644084453583 [SCORE] : 0.800000011920929\n",
      "[32/1000]\n",
      "- [TRAIN] LOSS : 0.20732688009738923 [SCORE] : 0.4088888943195343\n",
      "[32/1000]\n",
      "- [VAL] LOSS : 0.38414105772972107 [SCORE] : 0.9090909361839294\n",
      "[33/1000]\n",
      "- [TRAIN] LOSS : 0.20028847853342693 [SCORE] : 0.5523809552192688\n",
      "[33/1000]\n",
      "- [VAL] LOSS : 0.36889100074768066 [SCORE] : 1.0\n",
      "[34/1000]\n",
      "- [TRAIN] LOSS : 0.19319018324216206 [SCORE] : 0.5833333333333334\n",
      "[34/1000]\n",
      "- [VAL] LOSS : 0.3536492884159088 [SCORE] : 1.0\n",
      "[35/1000]\n",
      "- [TRAIN] LOSS : 0.1860457589228948 [SCORE] : 0.6\n",
      "[35/1000]\n",
      "- [VAL] LOSS : 0.3385177552700043 [SCORE] : 1.0\n",
      "[36/1000]\n",
      "- [TRAIN] LOSS : 0.1788858413696289 [SCORE] : 0.6\n",
      "[36/1000]\n",
      "- [VAL] LOSS : 0.32356882095336914 [SCORE] : 1.0\n",
      "[37/1000]\n",
      "- [TRAIN] LOSS : 0.1717148830493291 [SCORE] : 0.6\n",
      "[37/1000]\n",
      "- [VAL] LOSS : 0.30862268805503845 [SCORE] : 1.0\n",
      "[38/1000]\n",
      "- [TRAIN] LOSS : 0.1645888179540634 [SCORE] : 0.6\n",
      "[38/1000]\n",
      "- [VAL] LOSS : 0.29383713006973267 [SCORE] : 1.0\n",
      "[39/1000]\n",
      "- [TRAIN] LOSS : 0.15753934383392335 [SCORE] : 0.6\n",
      "[39/1000]\n",
      "- [VAL] LOSS : 0.2793123126029968 [SCORE] : 1.0\n",
      "[40/1000]\n",
      "- [TRAIN] LOSS : 0.15058457056681315 [SCORE] : 0.6\n",
      "[40/1000]\n",
      "- [VAL] LOSS : 0.2649781405925751 [SCORE] : 1.0\n",
      "[41/1000]\n",
      "- [TRAIN] LOSS : 0.14378045499324799 [SCORE] : 0.6\n",
      "[41/1000]\n",
      "- [VAL] LOSS : 0.2510538399219513 [SCORE] : 1.0\n",
      "[42/1000]\n",
      "- [TRAIN] LOSS : 0.13711701035499574 [SCORE] : 0.6\n",
      "[42/1000]\n",
      "- [VAL] LOSS : 0.23742662370204926 [SCORE] : 1.0\n",
      "[43/1000]\n",
      "- [TRAIN] LOSS : 0.13065114120642343 [SCORE] : 0.6\n",
      "[43/1000]\n",
      "- [VAL] LOSS : 0.22434964776039124 [SCORE] : 1.0\n",
      "[44/1000]\n",
      "- [TRAIN] LOSS : 0.12440040012200673 [SCORE] : 0.6\n",
      "[44/1000]\n",
      "- [VAL] LOSS : 0.2119668573141098 [SCORE] : 1.0\n",
      "[45/1000]\n",
      "- [TRAIN] LOSS : 0.11835718949635823 [SCORE] : 0.6\n",
      "[45/1000]\n",
      "- [VAL] LOSS : 0.2002170979976654 [SCORE] : 1.0\n",
      "[46/1000]\n",
      "- [TRAIN] LOSS : 0.11254300475120545 [SCORE] : 0.6\n",
      "[46/1000]\n",
      "- [VAL] LOSS : 0.18913625180721283 [SCORE] : 1.0\n",
      "[47/1000]\n",
      "- [TRAIN] LOSS : 0.10695691108703613 [SCORE] : 0.6\n",
      "[47/1000]\n",
      "- [VAL] LOSS : 0.17872795462608337 [SCORE] : 1.0\n",
      "[48/1000]\n",
      "- [TRAIN] LOSS : 0.10159303098917008 [SCORE] : 0.6\n",
      "[48/1000]\n",
      "- [VAL] LOSS : 0.1688743531703949 [SCORE] : 1.0\n",
      "[49/1000]\n",
      "- [TRAIN] LOSS : 0.09646102736393611 [SCORE] : 0.6\n",
      "[49/1000]\n",
      "- [VAL] LOSS : 0.15955515205860138 [SCORE] : 1.0\n",
      "[50/1000]\n",
      "- [TRAIN] LOSS : 0.09156271864970525 [SCORE] : 0.6\n",
      "[50/1000]\n",
      "- [VAL] LOSS : 0.15076228976249695 [SCORE] : 1.0\n",
      "[51/1000]\n",
      "- [TRAIN] LOSS : 0.08689515093962351 [SCORE] : 0.6\n",
      "[51/1000]\n",
      "- [VAL] LOSS : 0.14245623350143433 [SCORE] : 1.0\n",
      "[52/1000]\n",
      "- [TRAIN] LOSS : 0.08245494316021601 [SCORE] : 0.6\n",
      "[52/1000]\n",
      "- [VAL] LOSS : 0.13463157415390015 [SCORE] : 1.0\n",
      "[53/1000]\n",
      "- [TRAIN] LOSS : 0.07824641267458597 [SCORE] : 0.6\n",
      "[53/1000]\n",
      "- [VAL] LOSS : 0.12718220055103302 [SCORE] : 1.0\n",
      "[54/1000]\n",
      "- [TRAIN] LOSS : 0.07425570785999298 [SCORE] : 0.6\n",
      "[54/1000]\n",
      "- [VAL] LOSS : 0.12006967514753342 [SCORE] : 1.0\n",
      "[55/1000]\n",
      "- [TRAIN] LOSS : 0.07049922496080399 [SCORE] : 0.6\n",
      "[55/1000]\n",
      "- [VAL] LOSS : 0.11341426521539688 [SCORE] : 1.0\n",
      "[56/1000]\n",
      "- [TRAIN] LOSS : 0.06695718516906103 [SCORE] : 0.6\n",
      "[56/1000]\n",
      "- [VAL] LOSS : 0.10724343359470367 [SCORE] : 1.0\n",
      "[57/1000]\n",
      "- [TRAIN] LOSS : 0.06360713889201482 [SCORE] : 0.6\n",
      "[57/1000]\n",
      "- [VAL] LOSS : 0.10146258771419525 [SCORE] : 1.0\n",
      "[58/1000]\n",
      "- [TRAIN] LOSS : 0.060451074441274004 [SCORE] : 0.6\n",
      "[58/1000]\n",
      "- [VAL] LOSS : 0.09607172012329102 [SCORE] : 1.0\n",
      "[59/1000]\n",
      "- [TRAIN] LOSS : 0.0574749360481898 [SCORE] : 0.6\n",
      "[59/1000]\n",
      "- [VAL] LOSS : 0.09105170518159866 [SCORE] : 1.0\n",
      "[60/1000]\n",
      "- [TRAIN] LOSS : 0.05466659466425578 [SCORE] : 0.6\n",
      "[60/1000]\n",
      "- [VAL] LOSS : 0.0863625779747963 [SCORE] : 1.0\n",
      "[61/1000]\n",
      "- [TRAIN] LOSS : 0.05201727921764056 [SCORE] : 0.6\n",
      "[61/1000]\n",
      "- [VAL] LOSS : 0.08196753263473511 [SCORE] : 1.0\n",
      "[62/1000]\n",
      "- [TRAIN] LOSS : 0.049521433065334956 [SCORE] : 0.6\n",
      "[62/1000]\n",
      "- [VAL] LOSS : 0.07782415300607681 [SCORE] : 1.0\n",
      "[63/1000]\n",
      "- [TRAIN] LOSS : 0.047168507675329846 [SCORE] : 0.6\n",
      "[63/1000]\n",
      "- [VAL] LOSS : 0.07391764968633652 [SCORE] : 1.0\n",
      "[64/1000]\n",
      "- [TRAIN] LOSS : 0.04495605950554212 [SCORE] : 0.6\n",
      "[64/1000]\n",
      "- [VAL] LOSS : 0.07025110721588135 [SCORE] : 1.0\n",
      "[65/1000]\n",
      "- [TRAIN] LOSS : 0.042871772001187004 [SCORE] : 0.6\n",
      "[65/1000]\n",
      "- [VAL] LOSS : 0.06680478155612946 [SCORE] : 1.0\n",
      "[66/1000]\n",
      "- [TRAIN] LOSS : 0.040910310794909796 [SCORE] : 0.6\n",
      "[66/1000]\n",
      "- [VAL] LOSS : 0.06358568370342255 [SCORE] : 1.0\n",
      "[67/1000]\n",
      "- [TRAIN] LOSS : 0.03906198764840762 [SCORE] : 0.6\n",
      "[67/1000]\n",
      "- [VAL] LOSS : 0.060586731880903244 [SCORE] : 1.0\n",
      "[68/1000]\n",
      "- [TRAIN] LOSS : 0.037316940476497015 [SCORE] : 0.6\n",
      "[68/1000]\n",
      "- [VAL] LOSS : 0.05776580795645714 [SCORE] : 1.0\n",
      "[69/1000]\n",
      "- [TRAIN] LOSS : 0.0356723353266716 [SCORE] : 0.6\n",
      "[69/1000]\n",
      "- [VAL] LOSS : 0.05509331822395325 [SCORE] : 1.0\n",
      "[70/1000]\n",
      "- [TRAIN] LOSS : 0.03412412777543068 [SCORE] : 0.6\n",
      "[70/1000]\n",
      "- [VAL] LOSS : 0.052578914910554886 [SCORE] : 1.0\n",
      "[71/1000]\n",
      "- [TRAIN] LOSS : 0.03266287272175153 [SCORE] : 0.6\n",
      "[71/1000]\n",
      "- [VAL] LOSS : 0.05020437017083168 [SCORE] : 1.0\n",
      "[72/1000]\n",
      "- [TRAIN] LOSS : 0.03128830144802729 [SCORE] : 0.6\n",
      "[72/1000]\n",
      "- [VAL] LOSS : 0.04797288402915001 [SCORE] : 1.0\n",
      "[73/1000]\n",
      "- [TRAIN] LOSS : 0.02999133790532748 [SCORE] : 0.6\n",
      "[73/1000]\n",
      "- [VAL] LOSS : 0.045879822224378586 [SCORE] : 1.0\n",
      "[74/1000]\n",
      "- [TRAIN] LOSS : 0.028766501446564993 [SCORE] : 0.6\n",
      "[74/1000]\n",
      "- [VAL] LOSS : 0.04392075911164284 [SCORE] : 1.0\n",
      "[75/1000]\n",
      "- [TRAIN] LOSS : 0.027606788898507754 [SCORE] : 0.6\n",
      "[75/1000]\n",
      "- [VAL] LOSS : 0.04207737371325493 [SCORE] : 1.0\n",
      "[76/1000]\n",
      "- [TRAIN] LOSS : 0.026509759326775868 [SCORE] : 0.6\n",
      "[76/1000]\n",
      "- [VAL] LOSS : 0.04034268483519554 [SCORE] : 1.0\n",
      "[77/1000]\n",
      "- [TRAIN] LOSS : 0.02547060636182626 [SCORE] : 0.6\n",
      "[77/1000]\n",
      "- [VAL] LOSS : 0.03870074823498726 [SCORE] : 1.0\n",
      "[78/1000]\n",
      "- [TRAIN] LOSS : 0.024486385037501654 [SCORE] : 0.6\n",
      "[78/1000]\n",
      "- [VAL] LOSS : 0.03714696690440178 [SCORE] : 1.0\n",
      "[79/1000]\n",
      "- [TRAIN] LOSS : 0.02355413995683193 [SCORE] : 0.6\n",
      "[79/1000]\n",
      "- [VAL] LOSS : 0.035680245608091354 [SCORE] : 1.0\n",
      "[80/1000]\n",
      "- [TRAIN] LOSS : 0.022669823840260506 [SCORE] : 0.6\n",
      "[80/1000]\n",
      "- [VAL] LOSS : 0.03429543226957321 [SCORE] : 1.0\n",
      "[81/1000]\n",
      "- [TRAIN] LOSS : 0.021830137819051743 [SCORE] : 0.6\n",
      "[81/1000]\n",
      "- [VAL] LOSS : 0.03298625349998474 [SCORE] : 1.0\n",
      "[82/1000]\n",
      "- [TRAIN] LOSS : 0.021032267063856126 [SCORE] : 0.6\n",
      "[82/1000]\n",
      "- [VAL] LOSS : 0.03174656257033348 [SCORE] : 1.0\n",
      "[83/1000]\n",
      "- [TRAIN] LOSS : 0.02027326263487339 [SCORE] : 0.6\n",
      "[83/1000]\n",
      "- [VAL] LOSS : 0.03056490793824196 [SCORE] : 1.0\n",
      "[84/1000]\n",
      "- [TRAIN] LOSS : 0.01955270196000735 [SCORE] : 0.6\n",
      "[84/1000]\n",
      "- [VAL] LOSS : 0.029442323371767998 [SCORE] : 1.0\n",
      "[85/1000]\n",
      "- [TRAIN] LOSS : 0.01886731485525767 [SCORE] : 0.6\n",
      "[85/1000]\n",
      "- [VAL] LOSS : 0.02837223932147026 [SCORE] : 1.0\n",
      "[86/1000]\n",
      "- [TRAIN] LOSS : 0.018215938409169515 [SCORE] : 0.6\n",
      "[86/1000]\n",
      "- [VAL] LOSS : 0.027354106307029724 [SCORE] : 1.0\n",
      "[87/1000]\n",
      "- [TRAIN] LOSS : 0.017596228669087093 [SCORE] : 0.6\n",
      "[87/1000]\n",
      "- [VAL] LOSS : 0.026385357603430748 [SCORE] : 1.0\n",
      "[88/1000]\n",
      "- [TRAIN] LOSS : 0.017005636791388192 [SCORE] : 0.6\n",
      "[88/1000]\n",
      "- [VAL] LOSS : 0.025464044883847237 [SCORE] : 1.0\n",
      "[89/1000]\n",
      "- [TRAIN] LOSS : 0.016442344089349113 [SCORE] : 0.6\n",
      "[89/1000]\n",
      "- [VAL] LOSS : 0.024585071951150894 [SCORE] : 1.0\n",
      "[90/1000]\n",
      "- [TRAIN] LOSS : 0.015905985484520595 [SCORE] : 0.6\n",
      "[90/1000]\n",
      "- [VAL] LOSS : 0.023750266060233116 [SCORE] : 1.0\n",
      "[91/1000]\n",
      "- [TRAIN] LOSS : 0.015394256015618642 [SCORE] : 0.6\n",
      "[91/1000]\n",
      "- [VAL] LOSS : 0.022958215326070786 [SCORE] : 1.0\n",
      "[92/1000]\n",
      "- [TRAIN] LOSS : 0.014905348606407642 [SCORE] : 0.6\n",
      "[92/1000]\n",
      "- [VAL] LOSS : 0.02220587618649006 [SCORE] : 1.0\n",
      "[93/1000]\n",
      "- [TRAIN] LOSS : 0.014437465369701386 [SCORE] : 0.6\n",
      "[93/1000]\n",
      "- [VAL] LOSS : 0.0214840155094862 [SCORE] : 1.0\n",
      "[94/1000]\n",
      "- [TRAIN] LOSS : 0.013991250718633334 [SCORE] : 0.6\n",
      "[94/1000]\n",
      "- [VAL] LOSS : 0.02079424075782299 [SCORE] : 1.0\n",
      "[95/1000]\n",
      "- [TRAIN] LOSS : 0.013564971213539442 [SCORE] : 0.6\n",
      "[95/1000]\n",
      "- [VAL] LOSS : 0.02013699896633625 [SCORE] : 1.0\n",
      "[96/1000]\n",
      "- [TRAIN] LOSS : 0.013157010699311892 [SCORE] : 0.6\n",
      "[96/1000]\n",
      "- [VAL] LOSS : 0.01950928568840027 [SCORE] : 1.0\n",
      "[97/1000]\n",
      "- [TRAIN] LOSS : 0.01276624749104182 [SCORE] : 0.6\n",
      "[97/1000]\n",
      "- [VAL] LOSS : 0.01890856958925724 [SCORE] : 1.0\n",
      "[98/1000]\n",
      "- [TRAIN] LOSS : 0.012392252186934153 [SCORE] : 0.6\n",
      "[98/1000]\n",
      "- [VAL] LOSS : 0.018334997817873955 [SCORE] : 1.0\n",
      "[99/1000]\n",
      "- [TRAIN] LOSS : 0.012033751420676708 [SCORE] : 0.6\n",
      "[99/1000]\n",
      "- [VAL] LOSS : 0.01778731495141983 [SCORE] : 1.0\n",
      "[100/1000]\n",
      "- [TRAIN] LOSS : 0.011690043471753597 [SCORE] : 0.6\n",
      "[100/1000]\n",
      "- [VAL] LOSS : 0.01726280152797699 [SCORE] : 1.0\n",
      "[101/1000]\n",
      "- [TRAIN] LOSS : 0.011359650890032451 [SCORE] : 0.6\n",
      "[101/1000]\n",
      "- [VAL] LOSS : 0.01675856113433838 [SCORE] : 1.0\n",
      "[102/1000]\n",
      "- [TRAIN] LOSS : 0.011042962409555912 [SCORE] : 0.6\n",
      "[102/1000]\n",
      "- [VAL] LOSS : 0.01627539098262787 [SCORE] : 1.0\n",
      "[103/1000]\n",
      "- [TRAIN] LOSS : 0.010738892666995525 [SCORE] : 0.6\n",
      "[103/1000]\n",
      "- [VAL] LOSS : 0.01581272855401039 [SCORE] : 1.0\n",
      "[104/1000]\n",
      "- [TRAIN] LOSS : 0.010446632467210292 [SCORE] : 0.6\n",
      "[104/1000]\n",
      "- [VAL] LOSS : 0.015369498170912266 [SCORE] : 1.0\n",
      "[105/1000]\n",
      "- [TRAIN] LOSS : 0.010165523178875447 [SCORE] : 0.6\n",
      "[105/1000]\n",
      "- [VAL] LOSS : 0.014944464899599552 [SCORE] : 1.0\n",
      "[106/1000]\n",
      "- [TRAIN] LOSS : 0.009894528053700924 [SCORE] : 0.6\n",
      "[106/1000]\n",
      "- [VAL] LOSS : 0.014533150009810925 [SCORE] : 1.0\n",
      "[107/1000]\n",
      "- [TRAIN] LOSS : 0.009634497699638207 [SCORE] : 0.6\n",
      "[107/1000]\n",
      "- [VAL] LOSS : 0.01413754466921091 [SCORE] : 1.0\n",
      "[108/1000]\n",
      "- [TRAIN] LOSS : 0.009384434173504512 [SCORE] : 0.6\n",
      "[108/1000]\n",
      "- [VAL] LOSS : 0.013757819309830666 [SCORE] : 1.0\n",
      "[109/1000]\n",
      "- [TRAIN] LOSS : 0.009143625323971113 [SCORE] : 0.6\n",
      "[109/1000]\n",
      "- [VAL] LOSS : 0.013393410481512547 [SCORE] : 1.0\n",
      "[110/1000]\n",
      "- [TRAIN] LOSS : 0.00891097541898489 [SCORE] : 0.6\n",
      "[110/1000]\n",
      "- [VAL] LOSS : 0.013038159348070621 [SCORE] : 1.0\n",
      "[111/1000]\n",
      "- [TRAIN] LOSS : 0.008687202942868073 [SCORE] : 0.6\n",
      "[111/1000]\n",
      "- [VAL] LOSS : 0.012692926451563835 [SCORE] : 1.0\n",
      "[112/1000]\n",
      "- [TRAIN] LOSS : 0.008472849677006403 [SCORE] : 0.6\n",
      "[112/1000]\n",
      "- [VAL] LOSS : 0.012361476197838783 [SCORE] : 1.0\n",
      "[113/1000]\n",
      "- [TRAIN] LOSS : 0.008266656411190827 [SCORE] : 0.6\n",
      "[113/1000]\n",
      "- [VAL] LOSS : 0.012044447474181652 [SCORE] : 1.0\n",
      "[114/1000]\n",
      "- [TRAIN] LOSS : 0.00806779886285464 [SCORE] : 0.6\n",
      "[114/1000]\n",
      "- [VAL] LOSS : 0.011741121299564838 [SCORE] : 1.0\n",
      "[115/1000]\n",
      "- [TRAIN] LOSS : 0.007875730283558369 [SCORE] : 0.6\n",
      "[115/1000]\n",
      "- [VAL] LOSS : 0.011450367979705334 [SCORE] : 1.0\n",
      "[116/1000]\n",
      "- [TRAIN] LOSS : 0.007690070476382971 [SCORE] : 0.6\n",
      "[116/1000]\n",
      "- [VAL] LOSS : 0.011171055026352406 [SCORE] : 1.0\n",
      "[117/1000]\n",
      "- [TRAIN] LOSS : 0.007510529148081938 [SCORE] : 0.6\n",
      "[117/1000]\n",
      "- [VAL] LOSS : 0.01090221107006073 [SCORE] : 1.0\n",
      "[118/1000]\n",
      "- [TRAIN] LOSS : 0.007336854810516039 [SCORE] : 0.6\n",
      "[118/1000]\n",
      "- [VAL] LOSS : 0.010643036104738712 [SCORE] : 1.0\n",
      "[119/1000]\n",
      "- [TRAIN] LOSS : 0.007168825343251228 [SCORE] : 0.6\n",
      "[119/1000]\n",
      "- [VAL] LOSS : 0.010392860509455204 [SCORE] : 1.0\n",
      "[120/1000]\n",
      "- [TRAIN] LOSS : 0.0070062245552738505 [SCORE] : 0.6\n",
      "[120/1000]\n",
      "- [VAL] LOSS : 0.010151148773729801 [SCORE] : 1.0\n",
      "[121/1000]\n",
      "- [TRAIN] LOSS : 0.006848826135198275 [SCORE] : 0.6\n",
      "[121/1000]\n",
      "- [VAL] LOSS : 0.009917461313307285 [SCORE] : 1.0\n",
      "[122/1000]\n",
      "- [TRAIN] LOSS : 0.00669643459841609 [SCORE] : 0.6\n",
      "[122/1000]\n",
      "- [VAL] LOSS : 0.009691411629319191 [SCORE] : 1.0\n",
      "[123/1000]\n",
      "- [TRAIN] LOSS : 0.006548120236645142 [SCORE] : 0.6\n",
      "[123/1000]\n",
      "- [VAL] LOSS : 0.009470030665397644 [SCORE] : 1.0\n",
      "[124/1000]\n",
      "- [TRAIN] LOSS : 0.006405469806243976 [SCORE] : 0.6\n",
      "[124/1000]\n",
      "- [VAL] LOSS : 0.00925533939152956 [SCORE] : 1.0\n",
      "[125/1000]\n",
      "- [TRAIN] LOSS : 0.006267606280744076 [SCORE] : 0.6\n",
      "[125/1000]\n",
      "- [VAL] LOSS : 0.009047934785485268 [SCORE] : 1.0\n",
      "[126/1000]\n",
      "- [TRAIN] LOSS : 0.006134103486935298 [SCORE] : 0.6\n",
      "[126/1000]\n",
      "- [VAL] LOSS : 0.00884775910526514 [SCORE] : 1.0\n",
      "[127/1000]\n",
      "- [TRAIN] LOSS : 0.006004680662105481 [SCORE] : 0.6\n",
      "[127/1000]\n",
      "- [VAL] LOSS : 0.008654444478452206 [SCORE] : 1.0\n",
      "[128/1000]\n",
      "- [TRAIN] LOSS : 0.0058791296246151125 [SCORE] : 0.6\n",
      "[128/1000]\n",
      "- [VAL] LOSS : 0.008467617444694042 [SCORE] : 1.0\n",
      "[129/1000]\n",
      "- [TRAIN] LOSS : 0.005757294781506062 [SCORE] : 0.6\n",
      "[129/1000]\n",
      "- [VAL] LOSS : 0.00828684214502573 [SCORE] : 1.0\n",
      "[130/1000]\n",
      "- [TRAIN] LOSS : 0.005639019360144933 [SCORE] : 0.6\n",
      "[130/1000]\n",
      "- [VAL] LOSS : 0.00811179168522358 [SCORE] : 1.0\n",
      "[131/1000]\n",
      "- [TRAIN] LOSS : 0.005524169032772382 [SCORE] : 0.6\n",
      "[131/1000]\n",
      "- [VAL] LOSS : 0.007942142896354198 [SCORE] : 1.0\n",
      "[132/1000]\n",
      "- [TRAIN] LOSS : 0.0054125265218317505 [SCORE] : 0.6\n",
      "[132/1000]\n",
      "- [VAL] LOSS : 0.00777707202360034 [SCORE] : 1.0\n",
      "[133/1000]\n",
      "- [TRAIN] LOSS : 0.005304223764687777 [SCORE] : 0.6\n",
      "[133/1000]\n",
      "- [VAL] LOSS : 0.007616723887622356 [SCORE] : 1.0\n",
      "[134/1000]\n",
      "- [TRAIN] LOSS : 0.005199108552187681 [SCORE] : 0.6\n",
      "[134/1000]\n",
      "- [VAL] LOSS : 0.007461132947355509 [SCORE] : 1.0\n",
      "[135/1000]\n",
      "- [TRAIN] LOSS : 0.0050969920431574185 [SCORE] : 0.6\n",
      "[135/1000]\n",
      "- [VAL] LOSS : 0.007310210727155209 [SCORE] : 1.0\n",
      "[136/1000]\n",
      "- [TRAIN] LOSS : 0.004997242242097855 [SCORE] : 0.6\n",
      "[136/1000]\n",
      "- [VAL] LOSS : 0.007162355352193117 [SCORE] : 1.0\n",
      "[137/1000]\n",
      "- [TRAIN] LOSS : 0.004900768181929986 [SCORE] : 0.6\n",
      "[137/1000]\n",
      "- [VAL] LOSS : 0.007018490694463253 [SCORE] : 1.0\n",
      "[138/1000]\n",
      "- [TRAIN] LOSS : 0.004807212017476558 [SCORE] : 0.6\n",
      "[138/1000]\n",
      "- [VAL] LOSS : 0.006878993473947048 [SCORE] : 1.0\n",
      "[139/1000]\n",
      "- [TRAIN] LOSS : 0.004716297145932913 [SCORE] : 0.6\n",
      "[139/1000]\n",
      "- [VAL] LOSS : 0.00674386415630579 [SCORE] : 1.0\n",
      "[140/1000]\n",
      "- [TRAIN] LOSS : 0.004627863193551699 [SCORE] : 0.6\n",
      "[140/1000]\n",
      "- [VAL] LOSS : 0.0066129295155406 [SCORE] : 1.0\n",
      "[141/1000]\n",
      "- [TRAIN] LOSS : 0.004541782227655252 [SCORE] : 0.6\n",
      "[141/1000]\n",
      "- [VAL] LOSS : 0.006485936231911182 [SCORE] : 1.0\n",
      "[142/1000]\n",
      "- [TRAIN] LOSS : 0.004457729527105888 [SCORE] : 0.6\n",
      "[142/1000]\n",
      "- [VAL] LOSS : 0.006362052168697119 [SCORE] : 1.0\n",
      "[143/1000]\n",
      "- [TRAIN] LOSS : 0.004376147376994292 [SCORE] : 0.6\n",
      "[143/1000]\n",
      "- [VAL] LOSS : 0.006241571623831987 [SCORE] : 1.0\n",
      "[144/1000]\n",
      "- [TRAIN] LOSS : 0.004296789132058621 [SCORE] : 0.6\n",
      "[144/1000]\n",
      "- [VAL] LOSS : 0.006124540232121944 [SCORE] : 1.0\n",
      "[145/1000]\n",
      "- [TRAIN] LOSS : 0.004219512827694416 [SCORE] : 0.6\n",
      "[145/1000]\n",
      "- [VAL] LOSS : 0.006010858807712793 [SCORE] : 1.0\n",
      "[146/1000]\n",
      "- [TRAIN] LOSS : 0.004144212479392687 [SCORE] : 0.6\n",
      "[146/1000]\n",
      "- [VAL] LOSS : 0.00590036204084754 [SCORE] : 1.0\n",
      "[147/1000]\n",
      "- [TRAIN] LOSS : 0.0040708080089340605 [SCORE] : 0.6\n",
      "[147/1000]\n",
      "- [VAL] LOSS : 0.005792898591607809 [SCORE] : 1.0\n",
      "[148/1000]\n",
      "- [TRAIN] LOSS : 0.003999231724689404 [SCORE] : 0.6\n",
      "[148/1000]\n",
      "- [VAL] LOSS : 0.005688333418220282 [SCORE] : 1.0\n",
      "[149/1000]\n",
      "- [TRAIN] LOSS : 0.003929430712014436 [SCORE] : 0.6\n",
      "[149/1000]\n",
      "- [VAL] LOSS : 0.005586514715105295 [SCORE] : 1.0\n",
      "[150/1000]\n",
      "- [TRAIN] LOSS : 0.0038612302858382465 [SCORE] : 0.6\n",
      "[150/1000]\n",
      "- [VAL] LOSS : 0.005487061571329832 [SCORE] : 1.0\n",
      "[151/1000]\n",
      "- [TRAIN] LOSS : 0.003794822795316577 [SCORE] : 0.6\n",
      "[151/1000]\n",
      "- [VAL] LOSS : 0.005390113685280085 [SCORE] : 1.0\n",
      "[152/1000]\n",
      "- [TRAIN] LOSS : 0.0037300727174927792 [SCORE] : 0.6\n",
      "[152/1000]\n",
      "- [VAL] LOSS : 0.005295689683407545 [SCORE] : 1.0\n",
      "[153/1000]\n",
      "- [TRAIN] LOSS : 0.0036668979407598573 [SCORE] : 0.6\n",
      "[153/1000]\n",
      "- [VAL] LOSS : 0.005203700624406338 [SCORE] : 1.0\n",
      "[154/1000]\n",
      "- [TRAIN] LOSS : 0.0036052398073176542 [SCORE] : 0.6\n",
      "[154/1000]\n",
      "- [VAL] LOSS : 0.005114005412906408 [SCORE] : 1.0\n",
      "[155/1000]\n",
      "- [TRAIN] LOSS : 0.003544907768567403 [SCORE] : 0.6\n",
      "[155/1000]\n",
      "- [VAL] LOSS : 0.005026259459555149 [SCORE] : 1.0\n",
      "[156/1000]\n",
      "- [TRAIN] LOSS : 0.0034861477091908456 [SCORE] : 0.6\n",
      "[156/1000]\n",
      "- [VAL] LOSS : 0.0049405694007873535 [SCORE] : 1.0\n",
      "[157/1000]\n",
      "- [TRAIN] LOSS : 0.0034288416616618635 [SCORE] : 0.6\n",
      "[157/1000]\n",
      "- [VAL] LOSS : 0.004857037216424942 [SCORE] : 1.0\n",
      "[158/1000]\n",
      "- [TRAIN] LOSS : 0.003372891278316577 [SCORE] : 0.6\n",
      "[158/1000]\n",
      "- [VAL] LOSS : 0.00477557722479105 [SCORE] : 1.0\n",
      "[159/1000]\n",
      "- [TRAIN] LOSS : 0.003318238367016117 [SCORE] : 0.6\n",
      "[159/1000]\n",
      "- [VAL] LOSS : 0.004696147982031107 [SCORE] : 1.0\n",
      "[160/1000]\n",
      "- [TRAIN] LOSS : 0.003264832776039839 [SCORE] : 0.6\n",
      "[160/1000]\n",
      "- [VAL] LOSS : 0.004618649836629629 [SCORE] : 1.0\n",
      "[161/1000]\n",
      "- [TRAIN] LOSS : 0.003212628265221914 [SCORE] : 0.6\n",
      "[161/1000]\n",
      "- [VAL] LOSS : 0.004543030168861151 [SCORE] : 1.0\n",
      "[162/1000]\n",
      "- [TRAIN] LOSS : 0.0031615949235856535 [SCORE] : 0.6\n",
      "[162/1000]\n",
      "- [VAL] LOSS : 0.0044691720977425575 [SCORE] : 1.0\n",
      "[163/1000]\n",
      "- [TRAIN] LOSS : 0.0031116940236339966 [SCORE] : 0.6\n",
      "[163/1000]\n",
      "- [VAL] LOSS : 0.0043971654959023 [SCORE] : 1.0\n",
      "[164/1000]\n",
      "- [TRAIN] LOSS : 0.0030629025927434365 [SCORE] : 0.6\n",
      "[164/1000]\n",
      "- [VAL] LOSS : 0.004326929803937674 [SCORE] : 1.0\n",
      "[165/1000]\n",
      "- [TRAIN] LOSS : 0.003015180475388964 [SCORE] : 0.6\n",
      "[165/1000]\n",
      "- [VAL] LOSS : 0.004258282016962767 [SCORE] : 1.0\n",
      "[166/1000]\n",
      "- [TRAIN] LOSS : 0.002968502122287949 [SCORE] : 0.6\n",
      "[166/1000]\n",
      "- [VAL] LOSS : 0.004191183485090733 [SCORE] : 1.0\n",
      "[167/1000]\n",
      "- [TRAIN] LOSS : 0.002922836396222313 [SCORE] : 0.6\n",
      "[167/1000]\n",
      "- [VAL] LOSS : 0.004125564359128475 [SCORE] : 1.0\n",
      "[168/1000]\n",
      "- [TRAIN] LOSS : 0.0028781524083266656 [SCORE] : 0.6\n",
      "[168/1000]\n",
      "- [VAL] LOSS : 0.004061389248818159 [SCORE] : 1.0\n",
      "[169/1000]\n",
      "- [TRAIN] LOSS : 0.0028344274653742713 [SCORE] : 0.6\n",
      "[169/1000]\n",
      "- [VAL] LOSS : 0.003998614381998777 [SCORE] : 1.0\n",
      "[170/1000]\n",
      "- [TRAIN] LOSS : 0.0027916309889405968 [SCORE] : 0.6\n",
      "[170/1000]\n",
      "- [VAL] LOSS : 0.003937195986509323 [SCORE] : 1.0\n",
      "[171/1000]\n",
      "- [TRAIN] LOSS : 0.0027497369796037675 [SCORE] : 0.6\n",
      "[171/1000]\n",
      "- [VAL] LOSS : 0.003877083072438836 [SCORE] : 1.0\n",
      "[172/1000]\n",
      "- [TRAIN] LOSS : 0.0027087246843924126 [SCORE] : 0.6\n",
      "[172/1000]\n",
      "- [VAL] LOSS : 0.0038182621356099844 [SCORE] : 1.0\n",
      "[173/1000]\n",
      "- [TRAIN] LOSS : 0.00266856726569434 [SCORE] : 0.6\n",
      "[173/1000]\n",
      "- [VAL] LOSS : 0.0037606791593134403 [SCORE] : 1.0\n",
      "[174/1000]\n",
      "- [TRAIN] LOSS : 0.0026292397174984216 [SCORE] : 0.6\n",
      "[174/1000]\n",
      "- [VAL] LOSS : 0.0037042959593236446 [SCORE] : 1.0\n",
      "[175/1000]\n",
      "- [TRAIN] LOSS : 0.0025907226372510195 [SCORE] : 0.6\n",
      "[175/1000]\n",
      "- [VAL] LOSS : 0.0036490934435278177 [SCORE] : 1.0\n",
      "[176/1000]\n",
      "- [TRAIN] LOSS : 0.002552994635577003 [SCORE] : 0.6\n",
      "[176/1000]\n",
      "- [VAL] LOSS : 0.0035950306337326765 [SCORE] : 1.0\n",
      "[177/1000]\n",
      "- [TRAIN] LOSS : 0.0025160283160706363 [SCORE] : 0.6\n",
      "[177/1000]\n",
      "- [VAL] LOSS : 0.0035420760978013277 [SCORE] : 1.0\n",
      "[178/1000]\n",
      "- [TRAIN] LOSS : 0.0024798111679653328 [SCORE] : 0.6\n",
      "[178/1000]\n",
      "- [VAL] LOSS : 0.0034901967737823725 [SCORE] : 1.0\n",
      "[179/1000]\n",
      "- [TRAIN] LOSS : 0.0024443215069671472 [SCORE] : 0.6\n",
      "[179/1000]\n",
      "- [VAL] LOSS : 0.0034393814858049154 [SCORE] : 1.0\n",
      "[180/1000]\n",
      "- [TRAIN] LOSS : 0.002409538921589653 [SCORE] : 0.6\n",
      "[180/1000]\n",
      "- [VAL] LOSS : 0.0033895825035870075 [SCORE] : 1.0\n",
      "[181/1000]\n",
      "- [TRAIN] LOSS : 0.0023754453596969444 [SCORE] : 0.6\n",
      "[181/1000]\n",
      "- [VAL] LOSS : 0.0033407900482416153 [SCORE] : 1.0\n",
      "[182/1000]\n",
      "- [TRAIN] LOSS : 0.002341942023485899 [SCORE] : 0.6\n",
      "[182/1000]\n",
      "- [VAL] LOSS : 0.00329281622543931 [SCORE] : 1.0\n",
      "[183/1000]\n",
      "- [TRAIN] LOSS : 0.0023091906992097695 [SCORE] : 0.6\n",
      "[183/1000]\n",
      "- [VAL] LOSS : 0.003245784668251872 [SCORE] : 1.0\n",
      "[184/1000]\n",
      "- [TRAIN] LOSS : 0.002277113466213147 [SCORE] : 0.6\n",
      "[184/1000]\n",
      "- [VAL] LOSS : 0.0031996832694858313 [SCORE] : 1.0\n",
      "[185/1000]\n",
      "- [TRAIN] LOSS : 0.0022456722411637506 [SCORE] : 0.6\n",
      "[185/1000]\n",
      "- [VAL] LOSS : 0.0031545315869152546 [SCORE] : 1.0\n",
      "[186/1000]\n",
      "- [TRAIN] LOSS : 0.0022148493754987914 [SCORE] : 0.6\n",
      "[186/1000]\n",
      "- [VAL] LOSS : 0.0031102574430406094 [SCORE] : 1.0\n",
      "[187/1000]\n",
      "- [TRAIN] LOSS : 0.002184484813672801 [SCORE] : 0.6\n",
      "[187/1000]\n",
      "- [VAL] LOSS : 0.0030666261445730925 [SCORE] : 1.0\n",
      "[188/1000]\n",
      "- [TRAIN] LOSS : 0.0021548176649957896 [SCORE] : 0.6\n",
      "[188/1000]\n",
      "- [VAL] LOSS : 0.003023814409971237 [SCORE] : 1.0\n",
      "[189/1000]\n",
      "- [TRAIN] LOSS : 0.00212576234092315 [SCORE] : 0.6\n",
      "[189/1000]\n",
      "- [VAL] LOSS : 0.002981880446895957 [SCORE] : 1.0\n",
      "[190/1000]\n",
      "- [TRAIN] LOSS : 0.0020972713672866425 [SCORE] : 0.6\n",
      "[190/1000]\n",
      "- [VAL] LOSS : 0.0029408163391053677 [SCORE] : 1.0\n",
      "[191/1000]\n",
      "- [TRAIN] LOSS : 0.0020693192180866998 [SCORE] : 0.6\n",
      "[191/1000]\n",
      "- [VAL] LOSS : 0.0029006002005189657 [SCORE] : 1.0\n",
      "[192/1000]\n",
      "- [TRAIN] LOSS : 0.002041881741024554 [SCORE] : 0.6\n",
      "[192/1000]\n",
      "- [VAL] LOSS : 0.002861196408048272 [SCORE] : 1.0\n",
      "[193/1000]\n",
      "- [TRAIN] LOSS : 0.0020149442988137405 [SCORE] : 0.6\n",
      "[193/1000]\n",
      "- [VAL] LOSS : 0.002822563052177429 [SCORE] : 1.0\n",
      "[194/1000]\n",
      "- [TRAIN] LOSS : 0.001988494473819931 [SCORE] : 0.6\n",
      "[194/1000]\n",
      "- [VAL] LOSS : 0.002784690586850047 [SCORE] : 1.0\n",
      "[195/1000]\n",
      "- [TRAIN] LOSS : 0.001962520220937828 [SCORE] : 0.6\n",
      "[195/1000]\n",
      "- [VAL] LOSS : 0.002747549908235669 [SCORE] : 1.0\n",
      "[196/1000]\n",
      "- [TRAIN] LOSS : 0.0019370163790881634 [SCORE] : 0.6\n",
      "[196/1000]\n",
      "- [VAL] LOSS : 0.0027111403178423643 [SCORE] : 1.0\n",
      "[197/1000]\n",
      "- [TRAIN] LOSS : 0.0019119664561003447 [SCORE] : 0.6\n",
      "[197/1000]\n",
      "- [VAL] LOSS : 0.0026754552964121103 [SCORE] : 1.0\n",
      "[198/1000]\n",
      "- [TRAIN] LOSS : 0.0018873598737021288 [SCORE] : 0.6\n",
      "[198/1000]\n",
      "- [VAL] LOSS : 0.0026404287200421095 [SCORE] : 1.0\n",
      "[199/1000]\n",
      "- [TRAIN] LOSS : 0.0018631872798626622 [SCORE] : 0.6\n",
      "[199/1000]\n",
      "- [VAL] LOSS : 0.002606034278869629 [SCORE] : 1.0\n",
      "[200/1000]\n",
      "- [TRAIN] LOSS : 0.0018394414568319918 [SCORE] : 0.6\n",
      "[200/1000]\n",
      "- [VAL] LOSS : 0.002572277095168829 [SCORE] : 1.0\n",
      "[201/1000]\n",
      "- [TRAIN] LOSS : 0.001816107239574194 [SCORE] : 0.6\n",
      "[201/1000]\n",
      "- [VAL] LOSS : 0.0025391168892383575 [SCORE] : 1.0\n",
      "[202/1000]\n",
      "- [TRAIN] LOSS : 0.0017931832854325572 [SCORE] : 0.6\n",
      "[202/1000]\n",
      "- [VAL] LOSS : 0.002506535965949297 [SCORE] : 1.0\n",
      "[203/1000]\n",
      "- [TRAIN] LOSS : 0.001770657394081354 [SCORE] : 0.6\n",
      "[203/1000]\n",
      "- [VAL] LOSS : 0.002474540611729026 [SCORE] : 1.0\n",
      "[204/1000]\n",
      "- [TRAIN] LOSS : 0.0017485151222596566 [SCORE] : 0.6\n",
      "[204/1000]\n",
      "- [VAL] LOSS : 0.002443100092932582 [SCORE] : 1.0\n",
      "[205/1000]\n",
      "- [TRAIN] LOSS : 0.0017267541804661354 [SCORE] : 0.6\n",
      "[205/1000]\n",
      "- [VAL] LOSS : 0.0024122141767293215 [SCORE] : 1.0\n",
      "[206/1000]\n",
      "- [TRAIN] LOSS : 0.001705364362957577 [SCORE] : 0.6\n",
      "[206/1000]\n",
      "- [VAL] LOSS : 0.0023819974157959223 [SCORE] : 1.0\n",
      "[207/1000]\n",
      "- [TRAIN] LOSS : 0.0016843381570652127 [SCORE] : 0.6\n",
      "[207/1000]\n",
      "- [VAL] LOSS : 0.002352379495278001 [SCORE] : 1.0\n",
      "[208/1000]\n",
      "- [TRAIN] LOSS : 0.0016636631606767574 [SCORE] : 0.6\n",
      "[208/1000]\n",
      "- [VAL] LOSS : 0.0023232826497405767 [SCORE] : 1.0\n",
      "[209/1000]\n",
      "- [TRAIN] LOSS : 0.0016433449927717447 [SCORE] : 0.6\n",
      "[209/1000]\n",
      "- [VAL] LOSS : 0.0022946782410144806 [SCORE] : 1.0\n",
      "[210/1000]\n",
      "- [TRAIN] LOSS : 0.0016233549530928334 [SCORE] : 0.6\n",
      "[210/1000]\n",
      "- [VAL] LOSS : 0.002266533439978957 [SCORE] : 1.0\n",
      "[211/1000]\n",
      "- [TRAIN] LOSS : 0.0016037019435316325 [SCORE] : 0.6\n",
      "[211/1000]\n",
      "- [VAL] LOSS : 0.002238872228190303 [SCORE] : 1.0\n",
      "[212/1000]\n",
      "- [TRAIN] LOSS : 0.0015843776986002923 [SCORE] : 0.6\n",
      "[212/1000]\n",
      "- [VAL] LOSS : 0.002211677609011531 [SCORE] : 1.0\n",
      "[213/1000]\n",
      "- [TRAIN] LOSS : 0.0015653668204322457 [SCORE] : 0.6\n",
      "[213/1000]\n",
      "- [VAL] LOSS : 0.0021849193144589663 [SCORE] : 1.0\n",
      "[214/1000]\n",
      "- [TRAIN] LOSS : 0.0015466682612895965 [SCORE] : 0.6\n",
      "[214/1000]\n",
      "- [VAL] LOSS : 0.0021586206275969744 [SCORE] : 1.0\n",
      "[215/1000]\n",
      "- [TRAIN] LOSS : 0.0015282733598724007 [SCORE] : 0.6\n",
      "[215/1000]\n",
      "- [VAL] LOSS : 0.0021327566355466843 [SCORE] : 1.0\n",
      "[216/1000]\n",
      "- [TRAIN] LOSS : 0.001510173447119693 [SCORE] : 0.6\n",
      "[216/1000]\n",
      "- [VAL] LOSS : 0.002107294974848628 [SCORE] : 1.0\n",
      "[217/1000]\n",
      "- [TRAIN] LOSS : 0.0014923699821035067 [SCORE] : 0.6\n",
      "[217/1000]\n",
      "- [VAL] LOSS : 0.0020822451915591955 [SCORE] : 1.0\n",
      "[218/1000]\n",
      "- [TRAIN] LOSS : 0.001474850772259136 [SCORE] : 0.6\n",
      "[218/1000]\n",
      "- [VAL] LOSS : 0.002057604258880019 [SCORE] : 1.0\n",
      "[219/1000]\n",
      "- [TRAIN] LOSS : 0.001457609049975872 [SCORE] : 0.6\n",
      "[219/1000]\n",
      "- [VAL] LOSS : 0.002033357275649905 [SCORE] : 1.0\n",
      "[220/1000]\n",
      "- [TRAIN] LOSS : 0.0014406448230147363 [SCORE] : 0.6\n",
      "[220/1000]\n",
      "- [VAL] LOSS : 0.002009505871683359 [SCORE] : 1.0\n",
      "[221/1000]\n",
      "- [TRAIN] LOSS : 0.0014239467214792966 [SCORE] : 0.6\n",
      "[221/1000]\n",
      "- [VAL] LOSS : 0.0019860307220369577 [SCORE] : 1.0\n",
      "[222/1000]\n",
      "- [TRAIN] LOSS : 0.0014075121221443017 [SCORE] : 0.6\n",
      "[222/1000]\n",
      "- [VAL] LOSS : 0.0019629246089607477 [SCORE] : 1.0\n",
      "[223/1000]\n",
      "- [TRAIN] LOSS : 0.0013913334269697467 [SCORE] : 0.6\n",
      "[223/1000]\n",
      "- [VAL] LOSS : 0.0019401723984628916 [SCORE] : 1.0\n",
      "[224/1000]\n",
      "- [TRAIN] LOSS : 0.0013754102944706877 [SCORE] : 0.6\n",
      "[224/1000]\n",
      "- [VAL] LOSS : 0.001917794463224709 [SCORE] : 1.0\n",
      "[225/1000]\n",
      "- [TRAIN] LOSS : 0.0013597288091356555 [SCORE] : 0.6\n",
      "[225/1000]\n",
      "- [VAL] LOSS : 0.0018957488937303424 [SCORE] : 1.0\n",
      "[226/1000]\n",
      "- [TRAIN] LOSS : 0.0013442893978208303 [SCORE] : 0.6\n",
      "[226/1000]\n",
      "- [VAL] LOSS : 0.0018740479135885835 [SCORE] : 1.0\n",
      "[227/1000]\n",
      "- [TRAIN] LOSS : 0.0013290915017326673 [SCORE] : 0.6\n",
      "[227/1000]\n",
      "- [VAL] LOSS : 0.0018526894273236394 [SCORE] : 1.0\n",
      "[228/1000]\n",
      "- [TRAIN] LOSS : 0.0013141223307078084 [SCORE] : 0.6\n",
      "[228/1000]\n",
      "- [VAL] LOSS : 0.0018316662171855569 [SCORE] : 1.0\n",
      "[229/1000]\n",
      "- [TRAIN] LOSS : 0.0012993785242239634 [SCORE] : 0.6\n",
      "[229/1000]\n",
      "- [VAL] LOSS : 0.0018109569791704416 [SCORE] : 1.0\n",
      "[230/1000]\n",
      "- [TRAIN] LOSS : 0.0012848652278383574 [SCORE] : 0.6\n",
      "[230/1000]\n",
      "- [VAL] LOSS : 0.0017905586864799261 [SCORE] : 1.0\n",
      "[231/1000]\n",
      "- [TRAIN] LOSS : 0.0012705656467005611 [SCORE] : 0.6\n",
      "[231/1000]\n",
      "- [VAL] LOSS : 0.001770457485690713 [SCORE] : 1.0\n",
      "[232/1000]\n",
      "- [TRAIN] LOSS : 0.0012564864242449402 [SCORE] : 0.6\n",
      "[232/1000]\n",
      "- [VAL] LOSS : 0.001750683062709868 [SCORE] : 1.0\n",
      "[233/1000]\n",
      "- [TRAIN] LOSS : 0.001242607447784394 [SCORE] : 0.6\n",
      "[233/1000]\n",
      "- [VAL] LOSS : 0.0017311881529167295 [SCORE] : 1.0\n",
      "[234/1000]\n",
      "- [TRAIN] LOSS : 0.0012289596527504424 [SCORE] : 0.6\n",
      "[234/1000]\n",
      "- [VAL] LOSS : 0.0017119658878073096 [SCORE] : 1.0\n",
      "[235/1000]\n",
      "- [TRAIN] LOSS : 0.0012154171282115081 [SCORE] : 0.6\n",
      "[235/1000]\n",
      "- [VAL] LOSS : 0.0016929323319345713 [SCORE] : 1.0\n",
      "[236/1000]\n",
      "- [TRAIN] LOSS : 0.0012021580749812224 [SCORE] : 0.6\n",
      "[236/1000]\n",
      "- [VAL] LOSS : 0.0016741352155804634 [SCORE] : 1.0\n",
      "[237/1000]\n",
      "- [TRAIN] LOSS : 0.0011891344212926925 [SCORE] : 0.6\n",
      "[237/1000]\n",
      "- [VAL] LOSS : 0.0016556483460590243 [SCORE] : 1.0\n",
      "[238/1000]\n",
      "- [TRAIN] LOSS : 0.0011763166907864313 [SCORE] : 0.6\n",
      "[238/1000]\n",
      "- [VAL] LOSS : 0.0016374514671042562 [SCORE] : 1.0\n",
      "[239/1000]\n",
      "- [TRAIN] LOSS : 0.0011636896524578333 [SCORE] : 0.6\n",
      "[239/1000]\n",
      "- [VAL] LOSS : 0.0016195556381717324 [SCORE] : 1.0\n",
      "[240/1000]\n",
      "- [TRAIN] LOSS : 0.0011512470354015627 [SCORE] : 0.6\n",
      "[240/1000]\n",
      "- [VAL] LOSS : 0.0016019372269511223 [SCORE] : 1.0\n",
      "[241/1000]\n",
      "- [TRAIN] LOSS : 0.001138983911368996 [SCORE] : 0.6\n",
      "[241/1000]\n",
      "- [VAL] LOSS : 0.0015845972811803222 [SCORE] : 1.0\n",
      "[242/1000]\n",
      "- [TRAIN] LOSS : 0.0011268936020011704 [SCORE] : 0.6\n",
      "[242/1000]\n",
      "- [VAL] LOSS : 0.001567532541230321 [SCORE] : 1.0\n",
      "[243/1000]\n",
      "- [TRAIN] LOSS : 0.001114974570615838 [SCORE] : 0.6\n",
      "[243/1000]\n",
      "- [VAL] LOSS : 0.0015507201896980405 [SCORE] : 1.0\n",
      "[244/1000]\n",
      "- [TRAIN] LOSS : 0.0011032209343587358 [SCORE] : 0.6\n",
      "[244/1000]\n",
      "- [VAL] LOSS : 0.0015341630205512047 [SCORE] : 1.0\n",
      "[245/1000]\n",
      "- [TRAIN] LOSS : 0.0010916368414958318 [SCORE] : 0.6\n",
      "[245/1000]\n",
      "- [VAL] LOSS : 0.0015178498579189181 [SCORE] : 1.0\n",
      "[246/1000]\n",
      "- [TRAIN] LOSS : 0.001080208655912429 [SCORE] : 0.6\n",
      "[246/1000]\n",
      "- [VAL] LOSS : 0.001501779188401997 [SCORE] : 1.0\n",
      "[247/1000]\n",
      "- [TRAIN] LOSS : 0.0010689409488501649 [SCORE] : 0.6\n",
      "[247/1000]\n",
      "- [VAL] LOSS : 0.0014859494986012578 [SCORE] : 1.0\n",
      "[248/1000]\n",
      "- [TRAIN] LOSS : 0.001057830584856371 [SCORE] : 0.6\n",
      "[248/1000]\n",
      "- [VAL] LOSS : 0.0014703382039442658 [SCORE] : 1.0\n",
      "[249/1000]\n",
      "- [TRAIN] LOSS : 0.001046869057851533 [SCORE] : 0.6\n",
      "[249/1000]\n",
      "- [VAL] LOSS : 0.001454932731576264 [SCORE] : 1.0\n",
      "[250/1000]\n",
      "- [TRAIN] LOSS : 0.001036064284077535 [SCORE] : 0.6\n",
      "[250/1000]\n",
      "- [VAL] LOSS : 0.0014397735940292478 [SCORE] : 1.0\n",
      "[251/1000]\n",
      "- [TRAIN] LOSS : 0.001025404625882705 [SCORE] : 0.6\n",
      "[251/1000]\n",
      "- [VAL] LOSS : 0.0014248135266825557 [SCORE] : 1.0\n",
      "[252/1000]\n",
      "- [TRAIN] LOSS : 0.0010148894158191978 [SCORE] : 0.6\n",
      "[252/1000]\n",
      "- [VAL] LOSS : 0.0014100567204877734 [SCORE] : 1.0\n",
      "[253/1000]\n",
      "- [TRAIN] LOSS : 0.0010045215021818876 [SCORE] : 0.6\n",
      "[253/1000]\n",
      "- [VAL] LOSS : 0.0013955134199932218 [SCORE] : 1.0\n",
      "[254/1000]\n",
      "- [TRAIN] LOSS : 0.0009942797167847553 [SCORE] : 0.6\n",
      "[254/1000]\n",
      "- [VAL] LOSS : 0.0013811516109853983 [SCORE] : 1.0\n",
      "[255/1000]\n",
      "- [TRAIN] LOSS : 0.0009841772921693821 [SCORE] : 0.6\n",
      "[255/1000]\n",
      "- [VAL] LOSS : 0.0013669779291376472 [SCORE] : 1.0\n",
      "[256/1000]\n",
      "- [TRAIN] LOSS : 0.0009742287918925285 [SCORE] : 0.6\n",
      "[256/1000]\n",
      "- [VAL] LOSS : 0.0013529935386031866 [SCORE] : 1.0\n",
      "[257/1000]\n",
      "- [TRAIN] LOSS : 0.0009644245263189077 [SCORE] : 0.6\n",
      "[257/1000]\n",
      "- [VAL] LOSS : 0.001339198905043304 [SCORE] : 1.0\n",
      "[258/1000]\n",
      "- [TRAIN] LOSS : 0.0009547526715323329 [SCORE] : 0.6\n",
      "[258/1000]\n",
      "- [VAL] LOSS : 0.0013256053207442164 [SCORE] : 1.0\n",
      "[259/1000]\n",
      "- [TRAIN] LOSS : 0.0009452111553400755 [SCORE] : 0.6\n",
      "[259/1000]\n",
      "- [VAL] LOSS : 0.0013121882220730186 [SCORE] : 1.0\n",
      "[260/1000]\n",
      "- [TRAIN] LOSS : 0.0009357982392733296 [SCORE] : 0.6\n",
      "[260/1000]\n",
      "- [VAL] LOSS : 0.0012989620445296168 [SCORE] : 1.0\n",
      "[261/1000]\n",
      "- [TRAIN] LOSS : 0.0009265004269157846 [SCORE] : 0.6\n",
      "[261/1000]\n",
      "- [VAL] LOSS : 0.0012859207345172763 [SCORE] : 1.0\n",
      "[262/1000]\n",
      "- [TRAIN] LOSS : 0.0009173309934946398 [SCORE] : 0.6\n",
      "[262/1000]\n",
      "- [VAL] LOSS : 0.0012730542803183198 [SCORE] : 1.0\n",
      "[263/1000]\n",
      "- [TRAIN] LOSS : 0.0009082807460799813 [SCORE] : 0.6\n",
      "[263/1000]\n",
      "- [VAL] LOSS : 0.001260354882106185 [SCORE] : 1.0\n",
      "[264/1000]\n",
      "- [TRAIN] LOSS : 0.0008993496924328307 [SCORE] : 0.6\n",
      "[264/1000]\n",
      "- [VAL] LOSS : 0.0012478260323405266 [SCORE] : 1.0\n",
      "[265/1000]\n",
      "- [TRAIN] LOSS : 0.0008905292333414157 [SCORE] : 0.6\n",
      "[265/1000]\n",
      "- [VAL] LOSS : 0.001235478324815631 [SCORE] : 1.0\n",
      "[266/1000]\n",
      "- [TRAIN] LOSS : 0.0008818247510741155 [SCORE] : 0.6\n",
      "[266/1000]\n",
      "- [VAL] LOSS : 0.0012232770677655935 [SCORE] : 1.0\n",
      "[267/1000]\n",
      "- [TRAIN] LOSS : 0.0008732112473808229 [SCORE] : 0.6\n",
      "[267/1000]\n",
      "- [VAL] LOSS : 0.0012112187687307596 [SCORE] : 1.0\n",
      "[268/1000]\n",
      "- [TRAIN] LOSS : 0.0008647176204249263 [SCORE] : 0.6\n",
      "[268/1000]\n",
      "- [VAL] LOSS : 0.0011993251973763108 [SCORE] : 1.0\n",
      "[269/1000]\n",
      "- [TRAIN] LOSS : 0.000856345472857356 [SCORE] : 0.6\n",
      "[269/1000]\n",
      "- [VAL] LOSS : 0.0011875767959281802 [SCORE] : 1.0\n",
      "[270/1000]\n",
      "- [TRAIN] LOSS : 0.0008480711452042063 [SCORE] : 0.6\n",
      "[270/1000]\n",
      "- [VAL] LOSS : 0.001175984158180654 [SCORE] : 1.0\n",
      "[271/1000]\n",
      "- [TRAIN] LOSS : 0.0008399059336322049 [SCORE] : 0.6\n",
      "[271/1000]\n",
      "- [VAL] LOSS : 0.0011645294725894928 [SCORE] : 1.0\n",
      "[272/1000]\n",
      "- [TRAIN] LOSS : 0.0008318602805957199 [SCORE] : 0.6\n",
      "[272/1000]\n",
      "- [VAL] LOSS : 0.0011532248463481665 [SCORE] : 1.0\n",
      "[273/1000]\n",
      "- [TRAIN] LOSS : 0.0008239369955845178 [SCORE] : 0.6\n",
      "[273/1000]\n",
      "- [VAL] LOSS : 0.0011420926311984658 [SCORE] : 1.0\n",
      "[274/1000]\n",
      "- [TRAIN] LOSS : 0.0008161061909049749 [SCORE] : 0.6\n",
      "[274/1000]\n",
      "- [VAL] LOSS : 0.0011311158305034041 [SCORE] : 1.0\n",
      "[275/1000]\n",
      "- [TRAIN] LOSS : 0.000808349628156672 [SCORE] : 0.6\n",
      "[275/1000]\n",
      "- [VAL] LOSS : 0.0011202541645616293 [SCORE] : 1.0\n",
      "[276/1000]\n",
      "- [TRAIN] LOSS : 0.0008006810715111593 [SCORE] : 0.6\n",
      "[276/1000]\n",
      "- [VAL] LOSS : 0.0011095264926552773 [SCORE] : 1.0\n",
      "[277/1000]\n",
      "- [TRAIN] LOSS : 0.000793113970818619 [SCORE] : 0.6\n",
      "[277/1000]\n",
      "- [VAL] LOSS : 0.0010989517904818058 [SCORE] : 1.0\n",
      "[278/1000]\n",
      "- [TRAIN] LOSS : 0.0007856782254142066 [SCORE] : 0.6\n",
      "[278/1000]\n",
      "- [VAL] LOSS : 0.0010885077062994242 [SCORE] : 1.0\n",
      "[279/1000]\n",
      "- [TRAIN] LOSS : 0.0007783365785144269 [SCORE] : 0.6\n",
      "[279/1000]\n",
      "- [VAL] LOSS : 0.001078201225027442 [SCORE] : 1.0\n",
      "[280/1000]\n",
      "- [TRAIN] LOSS : 0.0007710656034760177 [SCORE] : 0.6\n",
      "[280/1000]\n",
      "- [VAL] LOSS : 0.0010680287377908826 [SCORE] : 1.0\n",
      "[281/1000]\n",
      "- [TRAIN] LOSS : 0.0007639208614515762 [SCORE] : 0.6\n",
      "[281/1000]\n",
      "- [VAL] LOSS : 0.0010579858208075166 [SCORE] : 1.0\n",
      "[282/1000]\n",
      "- [TRAIN] LOSS : 0.000756841734983027 [SCORE] : 0.6\n",
      "[282/1000]\n",
      "- [VAL] LOSS : 0.0010480699129402637 [SCORE] : 1.0\n",
      "[283/1000]\n",
      "- [TRAIN] LOSS : 0.000749833583055685 [SCORE] : 0.6\n",
      "[283/1000]\n",
      "- [VAL] LOSS : 0.0010382848558947444 [SCORE] : 1.0\n",
      "[284/1000]\n",
      "- [TRAIN] LOSS : 0.0007429240349059303 [SCORE] : 0.6\n",
      "[284/1000]\n",
      "- [VAL] LOSS : 0.0010286198230460286 [SCORE] : 1.0\n",
      "[285/1000]\n",
      "- [TRAIN] LOSS : 0.0007360965479165316 [SCORE] : 0.6\n",
      "[285/1000]\n",
      "- [VAL] LOSS : 0.0010190773755311966 [SCORE] : 1.0\n",
      "[286/1000]\n",
      "- [TRAIN] LOSS : 0.0007293546960378687 [SCORE] : 0.6\n",
      "[286/1000]\n",
      "- [VAL] LOSS : 0.001009650295600295 [SCORE] : 1.0\n",
      "[287/1000]\n",
      "- [TRAIN] LOSS : 0.0007226924800003569 [SCORE] : 0.6\n",
      "[287/1000]\n",
      "- [VAL] LOSS : 0.0010003288043662906 [SCORE] : 1.0\n",
      "[288/1000]\n",
      "- [TRAIN] LOSS : 0.0007160923637760182 [SCORE] : 0.6\n",
      "[288/1000]\n",
      "- [VAL] LOSS : 0.0009911289671435952 [SCORE] : 1.0\n",
      "[289/1000]\n",
      "- [TRAIN] LOSS : 0.0007095742621459067 [SCORE] : 0.6\n",
      "[289/1000]\n",
      "- [VAL] LOSS : 0.000982043333351612 [SCORE] : 1.0\n",
      "[290/1000]\n",
      "- [TRAIN] LOSS : 0.0007031463513461252 [SCORE] : 0.6\n",
      "[290/1000]\n",
      "- [VAL] LOSS : 0.0009730750462040305 [SCORE] : 1.0\n",
      "[291/1000]\n",
      "- [TRAIN] LOSS : 0.0006968051427975297 [SCORE] : 0.6\n",
      "[291/1000]\n",
      "- [VAL] LOSS : 0.0009642004151828587 [SCORE] : 1.0\n",
      "[292/1000]\n",
      "- [TRAIN] LOSS : 0.0006905429627901565 [SCORE] : 0.6\n",
      "[292/1000]\n",
      "- [VAL] LOSS : 0.0009554520365782082 [SCORE] : 1.0\n",
      "[293/1000]\n",
      "- [TRAIN] LOSS : 0.0006843537538467596 [SCORE] : 0.6\n",
      "[293/1000]\n",
      "- [VAL] LOSS : 0.0009468037751503289 [SCORE] : 1.0\n",
      "[294/1000]\n",
      "- [TRAIN] LOSS : 0.0006782348151318729 [SCORE] : 0.6\n",
      "[294/1000]\n",
      "- [VAL] LOSS : 0.0009382666903547943 [SCORE] : 1.0\n",
      "[295/1000]\n",
      "- [TRAIN] LOSS : 0.0006721899514862647 [SCORE] : 0.6\n",
      "[295/1000]\n",
      "- [VAL] LOSS : 0.0009298211080022156 [SCORE] : 1.0\n",
      "[296/1000]\n",
      "- [TRAIN] LOSS : 0.0006662141861549268 [SCORE] : 0.6\n",
      "[296/1000]\n",
      "- [VAL] LOSS : 0.0009214789606630802 [SCORE] : 1.0\n",
      "[297/1000]\n",
      "- [TRAIN] LOSS : 0.0006603053014259785 [SCORE] : 0.6\n",
      "[297/1000]\n",
      "- [VAL] LOSS : 0.0009132312843576074 [SCORE] : 1.0\n",
      "[298/1000]\n",
      "- [TRAIN] LOSS : 0.0006544647175663461 [SCORE] : 0.6\n",
      "[298/1000]\n",
      "- [VAL] LOSS : 0.0009050750522874296 [SCORE] : 1.0\n",
      "[299/1000]\n",
      "- [TRAIN] LOSS : 0.0006486897686651598 [SCORE] : 0.6\n",
      "[299/1000]\n",
      "- [VAL] LOSS : 0.0008970313938334584 [SCORE] : 1.0\n",
      "[300/1000]\n",
      "- [TRAIN] LOSS : 0.0006429820457318177 [SCORE] : 0.6\n",
      "[300/1000]\n",
      "- [VAL] LOSS : 0.0008890728349797428 [SCORE] : 1.0\n",
      "[301/1000]\n",
      "- [TRAIN] LOSS : 0.0006373378273565322 [SCORE] : 0.6\n",
      "[301/1000]\n",
      "- [VAL] LOSS : 0.000881205836776644 [SCORE] : 1.0\n",
      "[302/1000]\n",
      "- [TRAIN] LOSS : 0.0006317554507404566 [SCORE] : 0.6\n",
      "[302/1000]\n",
      "- [VAL] LOSS : 0.0008734171860851347 [SCORE] : 1.0\n",
      "[303/1000]\n",
      "- [TRAIN] LOSS : 0.0006262392678763717 [SCORE] : 0.6\n",
      "[303/1000]\n",
      "- [VAL] LOSS : 0.0008657321450300515 [SCORE] : 1.0\n",
      "[304/1000]\n",
      "- [TRAIN] LOSS : 0.0006207837218729158 [SCORE] : 0.6\n",
      "[304/1000]\n",
      "- [VAL] LOSS : 0.000858123239595443 [SCORE] : 1.0\n",
      "[305/1000]\n",
      "- [TRAIN] LOSS : 0.0006153876893222332 [SCORE] : 0.6\n",
      "[305/1000]\n",
      "- [VAL] LOSS : 0.0008506090962328017 [SCORE] : 1.0\n",
      "[306/1000]\n",
      "- [TRAIN] LOSS : 0.0006100539253869404 [SCORE] : 0.6\n",
      "[306/1000]\n",
      "- [VAL] LOSS : 0.0008431787719018757 [SCORE] : 1.0\n",
      "[307/1000]\n",
      "- [TRAIN] LOSS : 0.0006047757497678201 [SCORE] : 0.6\n",
      "[307/1000]\n",
      "- [VAL] LOSS : 0.0008358312770724297 [SCORE] : 1.0\n",
      "[308/1000]\n",
      "- [TRAIN] LOSS : 0.0005995579005684704 [SCORE] : 0.6\n",
      "[308/1000]\n",
      "- [VAL] LOSS : 0.0008285567746497691 [SCORE] : 1.0\n",
      "[309/1000]\n",
      "- [TRAIN] LOSS : 0.0005944023975947251 [SCORE] : 0.6\n",
      "[309/1000]\n",
      "- [VAL] LOSS : 0.000821365334559232 [SCORE] : 1.0\n",
      "[310/1000]\n",
      "- [TRAIN] LOSS : 0.0005892983598945041 [SCORE] : 0.6\n",
      "[310/1000]\n",
      "- [VAL] LOSS : 0.0008142562001012266 [SCORE] : 1.0\n",
      "[311/1000]\n",
      "- [TRAIN] LOSS : 0.0005842503839327643 [SCORE] : 0.6\n",
      "[311/1000]\n",
      "- [VAL] LOSS : 0.0008072257624007761 [SCORE] : 1.0\n",
      "[312/1000]\n",
      "- [TRAIN] LOSS : 0.0005792605904086182 [SCORE] : 0.6\n",
      "[312/1000]\n",
      "- [VAL] LOSS : 0.0008002748945727944 [SCORE] : 1.0\n",
      "[313/1000]\n",
      "- [TRAIN] LOSS : 0.0005743228558761378 [SCORE] : 0.6\n",
      "[313/1000]\n",
      "- [VAL] LOSS : 0.0007933949818834662 [SCORE] : 1.0\n",
      "[314/1000]\n",
      "- [TRAIN] LOSS : 0.0005694410084591558 [SCORE] : 0.6\n",
      "[314/1000]\n",
      "- [VAL] LOSS : 0.0007865921361371875 [SCORE] : 1.0\n",
      "[315/1000]\n",
      "- [TRAIN] LOSS : 0.0005646066584934791 [SCORE] : 0.6\n",
      "[315/1000]\n",
      "- [VAL] LOSS : 0.0007798661827109754 [SCORE] : 1.0\n",
      "[316/1000]\n",
      "- [TRAIN] LOSS : 0.0005598321945096056 [SCORE] : 0.6\n",
      "[316/1000]\n",
      "- [VAL] LOSS : 0.0007732091471552849 [SCORE] : 1.0\n",
      "[317/1000]\n",
      "- [TRAIN] LOSS : 0.0005551072050972531 [SCORE] : 0.6\n",
      "[317/1000]\n",
      "- [VAL] LOSS : 0.0007666258024983108 [SCORE] : 1.0\n",
      "[318/1000]\n",
      "- [TRAIN] LOSS : 0.0005504297247777382 [SCORE] : 0.6\n",
      "[318/1000]\n",
      "- [VAL] LOSS : 0.0007601202232763171 [SCORE] : 1.0\n",
      "[319/1000]\n",
      "- [TRAIN] LOSS : 0.0005458015094821652 [SCORE] : 0.6\n",
      "[319/1000]\n",
      "- [VAL] LOSS : 0.0007536740740761161 [SCORE] : 1.0\n",
      "[320/1000]\n",
      "- [TRAIN] LOSS : 0.0005412299554639807 [SCORE] : 0.6\n",
      "[320/1000]\n",
      "- [VAL] LOSS : 0.0007473033620044589 [SCORE] : 1.0\n",
      "[321/1000]\n",
      "- [TRAIN] LOSS : 0.0005367031417942296 [SCORE] : 0.6\n",
      "[321/1000]\n",
      "- [VAL] LOSS : 0.0007409998215734959 [SCORE] : 1.0\n",
      "[322/1000]\n",
      "- [TRAIN] LOSS : 0.0005322249742069592 [SCORE] : 0.6\n",
      "[322/1000]\n",
      "- [VAL] LOSS : 0.0007347501232288778 [SCORE] : 1.0\n",
      "[323/1000]\n",
      "- [TRAIN] LOSS : 0.0005277900549117476 [SCORE] : 0.6\n",
      "[323/1000]\n",
      "- [VAL] LOSS : 0.0007285819156095386 [SCORE] : 1.0\n",
      "[324/1000]\n",
      "- [TRAIN] LOSS : 0.0005234056055390587 [SCORE] : 0.6\n",
      "[324/1000]\n",
      "- [VAL] LOSS : 0.0007224708679132164 [SCORE] : 1.0\n",
      "[325/1000]\n",
      "- [TRAIN] LOSS : 0.0005190693152447542 [SCORE] : 0.6\n",
      "[325/1000]\n",
      "- [VAL] LOSS : 0.0007164281560108066 [SCORE] : 1.0\n",
      "[326/1000]\n",
      "- [TRAIN] LOSS : 0.0005147750062557559 [SCORE] : 0.6\n",
      "[326/1000]\n",
      "- [VAL] LOSS : 0.0007104419055394828 [SCORE] : 1.0\n",
      "[327/1000]\n",
      "- [TRAIN] LOSS : 0.0005105258741726477 [SCORE] : 0.6\n",
      "[327/1000]\n",
      "- [VAL] LOSS : 0.00070452771615237 [SCORE] : 1.0\n",
      "[328/1000]\n",
      "- [TRAIN] LOSS : 0.0005063232480703542 [SCORE] : 0.6\n",
      "[328/1000]\n",
      "- [VAL] LOSS : 0.0006986689986661077 [SCORE] : 1.0\n",
      "[329/1000]\n",
      "- [TRAIN] LOSS : 0.0005021614701642345 [SCORE] : 0.6\n",
      "[329/1000]\n",
      "- [VAL] LOSS : 0.0006928747752681375 [SCORE] : 1.0\n",
      "[330/1000]\n",
      "- [TRAIN] LOSS : 0.0004980456336246183 [SCORE] : 0.6\n",
      "[330/1000]\n",
      "- [VAL] LOSS : 0.0006871340447105467 [SCORE] : 1.0\n",
      "[331/1000]\n",
      "- [TRAIN] LOSS : 0.0004939716192893684 [SCORE] : 0.6\n",
      "[331/1000]\n",
      "- [VAL] LOSS : 0.0006814696243964136 [SCORE] : 1.0\n",
      "[332/1000]\n",
      "- [TRAIN] LOSS : 0.0004899392699978004 [SCORE] : 0.6\n",
      "[332/1000]\n",
      "- [VAL] LOSS : 0.0006758493254892528 [SCORE] : 1.0\n",
      "[333/1000]\n",
      "- [TRAIN] LOSS : 0.0004859499594507118 [SCORE] : 0.6\n",
      "[333/1000]\n",
      "- [VAL] LOSS : 0.000670294277369976 [SCORE] : 1.0\n",
      "[334/1000]\n",
      "- [TRAIN] LOSS : 0.00048200190843393406 [SCORE] : 0.6\n",
      "[334/1000]\n",
      "- [VAL] LOSS : 0.0006647934787906706 [SCORE] : 1.0\n",
      "[335/1000]\n",
      "- [TRAIN] LOSS : 0.00047809264700238906 [SCORE] : 0.6\n",
      "[335/1000]\n",
      "- [VAL] LOSS : 0.0006593480356968939 [SCORE] : 1.0\n",
      "[336/1000]\n",
      "- [TRAIN] LOSS : 0.00047421967804742355 [SCORE] : 0.6\n",
      "[336/1000]\n",
      "- [VAL] LOSS : 0.0006539570167660713 [SCORE] : 1.0\n",
      "[337/1000]\n",
      "- [TRAIN] LOSS : 0.0004703833488747478 [SCORE] : 0.6\n",
      "[337/1000]\n",
      "- [VAL] LOSS : 0.0006486325291916728 [SCORE] : 1.0\n",
      "[338/1000]\n",
      "- [TRAIN] LOSS : 0.0004665890223501871 [SCORE] : 0.6\n",
      "[338/1000]\n",
      "- [VAL] LOSS : 0.0006433529779314995 [SCORE] : 1.0\n",
      "[339/1000]\n",
      "- [TRAIN] LOSS : 0.000462839057824264 [SCORE] : 0.6\n",
      "[339/1000]\n",
      "- [VAL] LOSS : 0.0006381351267918944 [SCORE] : 1.0\n",
      "[340/1000]\n",
      "- [TRAIN] LOSS : 0.00045912975911051036 [SCORE] : 0.6\n",
      "[340/1000]\n",
      "- [VAL] LOSS : 0.0006329636089503765 [SCORE] : 1.0\n",
      "[341/1000]\n",
      "- [TRAIN] LOSS : 0.00045545232327034074 [SCORE] : 0.6\n",
      "[341/1000]\n",
      "- [VAL] LOSS : 0.0006278469227254391 [SCORE] : 1.0\n",
      "[342/1000]\n",
      "- [TRAIN] LOSS : 0.0004518150934018195 [SCORE] : 0.6\n",
      "[342/1000]\n",
      "- [VAL] LOSS : 0.0006227814010344446 [SCORE] : 1.0\n",
      "[343/1000]\n",
      "- [TRAIN] LOSS : 0.0004482156325442096 [SCORE] : 0.6\n",
      "[343/1000]\n",
      "- [VAL] LOSS : 0.0006177777540870011 [SCORE] : 1.0\n",
      "[344/1000]\n",
      "- [TRAIN] LOSS : 0.00044465331787553925 [SCORE] : 0.6\n",
      "[344/1000]\n",
      "- [VAL] LOSS : 0.0006128153763711452 [SCORE] : 1.0\n",
      "[345/1000]\n",
      "- [TRAIN] LOSS : 0.00044112062508550786 [SCORE] : 0.6\n",
      "[345/1000]\n",
      "- [VAL] LOSS : 0.0006078974693082273 [SCORE] : 1.0\n",
      "[346/1000]\n",
      "- [TRAIN] LOSS : 0.00043762588175013664 [SCORE] : 0.6\n",
      "[346/1000]\n",
      "- [VAL] LOSS : 0.0006030266522429883 [SCORE] : 1.0\n",
      "[347/1000]\n",
      "- [TRAIN] LOSS : 0.00043416580301709474 [SCORE] : 0.6\n",
      "[347/1000]\n",
      "- [VAL] LOSS : 0.000598221377003938 [SCORE] : 1.0\n",
      "[348/1000]\n",
      "- [TRAIN] LOSS : 0.0004307374202956756 [SCORE] : 0.6\n",
      "[348/1000]\n",
      "- [VAL] LOSS : 0.0005934466025792062 [SCORE] : 1.0\n",
      "[349/1000]\n",
      "- [TRAIN] LOSS : 0.0004273450273709993 [SCORE] : 0.6\n",
      "[349/1000]\n",
      "- [VAL] LOSS : 0.0005887142033316195 [SCORE] : 1.0\n",
      "[350/1000]\n",
      "- [TRAIN] LOSS : 0.00042398375420210264 [SCORE] : 0.6\n",
      "[350/1000]\n",
      "- [VAL] LOSS : 0.0005840386147610843 [SCORE] : 1.0\n",
      "[351/1000]\n",
      "- [TRAIN] LOSS : 0.00042065893843149145 [SCORE] : 0.6\n",
      "[351/1000]\n",
      "- [VAL] LOSS : 0.0005794055759906769 [SCORE] : 1.0\n",
      "[352/1000]\n",
      "- [TRAIN] LOSS : 0.00041736753385824464 [SCORE] : 0.6\n",
      "[352/1000]\n",
      "- [VAL] LOSS : 0.0005748262628912926 [SCORE] : 1.0\n",
      "[353/1000]\n",
      "- [TRAIN] LOSS : 0.0004141038206095497 [SCORE] : 0.6\n",
      "[353/1000]\n",
      "- [VAL] LOSS : 0.0005702854250557721 [SCORE] : 1.0\n",
      "[354/1000]\n",
      "- [TRAIN] LOSS : 0.0004108746322647979 [SCORE] : 0.6\n",
      "[354/1000]\n",
      "- [VAL] LOSS : 0.0005657884175889194 [SCORE] : 1.0\n",
      "[355/1000]\n",
      "- [TRAIN] LOSS : 0.00040767571578423183 [SCORE] : 0.6\n",
      "[355/1000]\n",
      "- [VAL] LOSS : 0.0005613443208858371 [SCORE] : 1.0\n",
      "[356/1000]\n",
      "- [TRAIN] LOSS : 0.0004044936028852438 [SCORE] : 0.6\n",
      "[356/1000]\n",
      "- [VAL] LOSS : 0.0005569385248236358 [SCORE] : 1.0\n",
      "[357/1000]\n",
      "- [TRAIN] LOSS : 0.0004013468569610268 [SCORE] : 0.6\n",
      "[357/1000]\n",
      "- [VAL] LOSS : 0.0005525880260393023 [SCORE] : 1.0\n",
      "[358/1000]\n",
      "- [TRAIN] LOSS : 0.0003982432254512484 [SCORE] : 0.6\n",
      "[358/1000]\n",
      "- [VAL] LOSS : 0.0005482990527525544 [SCORE] : 1.0\n",
      "[359/1000]\n",
      "- [TRAIN] LOSS : 0.0003951717168092728 [SCORE] : 0.6\n",
      "[359/1000]\n",
      "- [VAL] LOSS : 0.000544037960935384 [SCORE] : 1.0\n",
      "[360/1000]\n",
      "- [TRAIN] LOSS : 0.0003921341306219498 [SCORE] : 0.6\n",
      "[360/1000]\n",
      "- [VAL] LOSS : 0.0005398242501541972 [SCORE] : 1.0\n",
      "[361/1000]\n",
      "- [TRAIN] LOSS : 0.00038912466649586953 [SCORE] : 0.6\n",
      "[361/1000]\n",
      "- [VAL] LOSS : 0.000535649131052196 [SCORE] : 1.0\n",
      "[362/1000]\n",
      "- [TRAIN] LOSS : 0.00038614425090296816 [SCORE] : 0.6\n",
      "[362/1000]\n",
      "- [VAL] LOSS : 0.0005315086455084383 [SCORE] : 1.0\n",
      "[363/1000]\n",
      "- [TRAIN] LOSS : 0.0003831909251554559 [SCORE] : 0.6\n",
      "[363/1000]\n",
      "- [VAL] LOSS : 0.0005274166469462216 [SCORE] : 1.0\n",
      "[364/1000]\n",
      "- [TRAIN] LOSS : 0.0003802682079064349 [SCORE] : 0.6\n",
      "[364/1000]\n",
      "- [VAL] LOSS : 0.0005233411211520433 [SCORE] : 1.0\n",
      "[365/1000]\n",
      "- [TRAIN] LOSS : 0.00037737086434693384 [SCORE] : 0.6\n",
      "[365/1000]\n",
      "- [VAL] LOSS : 0.000519322173204273 [SCORE] : 1.0\n",
      "[366/1000]\n",
      "- [TRAIN] LOSS : 0.0003745006863027811 [SCORE] : 0.6\n",
      "[366/1000]\n",
      "- [VAL] LOSS : 0.0005153401871211827 [SCORE] : 1.0\n",
      "[367/1000]\n",
      "- [TRAIN] LOSS : 0.00037166025625386584 [SCORE] : 0.6\n",
      "[367/1000]\n",
      "- [VAL] LOSS : 0.0005113878287374973 [SCORE] : 1.0\n",
      "[368/1000]\n",
      "- [TRAIN] LOSS : 0.000368840898348329 [SCORE] : 0.6\n",
      "[368/1000]\n",
      "- [VAL] LOSS : 0.000507485237903893 [SCORE] : 1.0\n",
      "[369/1000]\n",
      "- [TRAIN] LOSS : 0.000366048661332267 [SCORE] : 0.6\n",
      "[369/1000]\n",
      "- [VAL] LOSS : 0.000503609306178987 [SCORE] : 1.0\n",
      "[370/1000]\n",
      "- [TRAIN] LOSS : 0.00036328746064100413 [SCORE] : 0.6\n",
      "[370/1000]\n",
      "- [VAL] LOSS : 0.0004997613723389804 [SCORE] : 1.0\n",
      "[371/1000]\n",
      "- [TRAIN] LOSS : 0.0003605490259360522 [SCORE] : 0.6\n",
      "[371/1000]\n",
      "- [VAL] LOSS : 0.0004959582583978772 [SCORE] : 1.0\n",
      "[372/1000]\n",
      "- [TRAIN] LOSS : 0.00035783584074427686 [SCORE] : 0.6\n",
      "[372/1000]\n",
      "- [VAL] LOSS : 0.0004921777290292084 [SCORE] : 1.0\n",
      "[373/1000]\n",
      "- [TRAIN] LOSS : 0.00035514513244076323 [SCORE] : 0.6\n",
      "[373/1000]\n",
      "- [VAL] LOSS : 0.0004884542431682348 [SCORE] : 1.0\n",
      "[374/1000]\n",
      "- [TRAIN] LOSS : 0.0003524831855126346 [SCORE] : 0.6\n",
      "[374/1000]\n",
      "- [VAL] LOSS : 0.00048475139192305505 [SCORE] : 1.0\n",
      "[375/1000]\n",
      "- [TRAIN] LOSS : 0.0003498419983467708 [SCORE] : 0.6\n",
      "[375/1000]\n",
      "- [VAL] LOSS : 0.00048108099144883454 [SCORE] : 1.0\n",
      "[376/1000]\n",
      "- [TRAIN] LOSS : 0.0003472261373341704 [SCORE] : 0.6\n",
      "[376/1000]\n",
      "- [VAL] LOSS : 0.00047744897892698646 [SCORE] : 1.0\n",
      "[377/1000]\n",
      "- [TRAIN] LOSS : 0.00034463631745893506 [SCORE] : 0.6\n",
      "[377/1000]\n",
      "- [VAL] LOSS : 0.0004738429852295667 [SCORE] : 1.0\n",
      "[378/1000]\n",
      "- [TRAIN] LOSS : 0.0003420684418718641 [SCORE] : 0.6\n",
      "[378/1000]\n",
      "- [VAL] LOSS : 0.00047028870903886855 [SCORE] : 1.0\n",
      "[379/1000]\n",
      "- [TRAIN] LOSS : 0.000339521585071149 [SCORE] : 0.6\n",
      "[379/1000]\n",
      "- [VAL] LOSS : 0.0004667501780204475 [SCORE] : 1.0\n",
      "[380/1000]\n",
      "- [TRAIN] LOSS : 0.00033700240407294284 [SCORE] : 0.6\n",
      "[380/1000]\n",
      "- [VAL] LOSS : 0.00046323638525791466 [SCORE] : 1.0\n",
      "[381/1000]\n",
      "- [TRAIN] LOSS : 0.000334503697619463 [SCORE] : 0.6\n",
      "[381/1000]\n",
      "- [VAL] LOSS : 0.0004597784427460283 [SCORE] : 1.0\n",
      "[382/1000]\n",
      "- [TRAIN] LOSS : 0.0003320304298540577 [SCORE] : 0.6\n",
      "[382/1000]\n",
      "- [VAL] LOSS : 0.00045633199624717236 [SCORE] : 1.0\n",
      "[383/1000]\n",
      "- [TRAIN] LOSS : 0.0003295757768986126 [SCORE] : 0.6\n",
      "[383/1000]\n",
      "- [VAL] LOSS : 0.00045291901915334165 [SCORE] : 1.0\n",
      "[384/1000]\n",
      "- [TRAIN] LOSS : 0.0003271471223949144 [SCORE] : 0.6\n",
      "[384/1000]\n",
      "- [VAL] LOSS : 0.00044954108307138085 [SCORE] : 1.0\n",
      "[385/1000]\n",
      "- [TRAIN] LOSS : 0.00032473624839137 [SCORE] : 0.6\n",
      "[385/1000]\n",
      "- [VAL] LOSS : 0.00044619612162932754 [SCORE] : 1.0\n",
      "[386/1000]\n",
      "- [TRAIN] LOSS : 0.00032234721002168956 [SCORE] : 0.6\n",
      "[386/1000]\n",
      "- [VAL] LOSS : 0.00044287749915383756 [SCORE] : 1.0\n",
      "[387/1000]\n",
      "- [TRAIN] LOSS : 0.0003199833396744604 [SCORE] : 0.6\n",
      "[387/1000]\n",
      "- [VAL] LOSS : 0.00043959327740594745 [SCORE] : 1.0\n",
      "[388/1000]\n",
      "- [TRAIN] LOSS : 0.0003176405696043124 [SCORE] : 0.6\n",
      "[388/1000]\n",
      "- [VAL] LOSS : 0.0004363268963061273 [SCORE] : 1.0\n",
      "[389/1000]\n",
      "- [TRAIN] LOSS : 0.00031531248532701284 [SCORE] : 0.6\n",
      "[389/1000]\n",
      "- [VAL] LOSS : 0.00043309511966072023 [SCORE] : 1.0\n",
      "[390/1000]\n",
      "- [TRAIN] LOSS : 0.0003130101327163478 [SCORE] : 0.6\n",
      "[390/1000]\n",
      "- [VAL] LOSS : 0.0004299007705412805 [SCORE] : 1.0\n",
      "[391/1000]\n",
      "- [TRAIN] LOSS : 0.0003107283642748371 [SCORE] : 0.6\n",
      "[391/1000]\n",
      "- [VAL] LOSS : 0.0004267327021807432 [SCORE] : 1.0\n",
      "[392/1000]\n",
      "- [TRAIN] LOSS : 0.0003084622595148782 [SCORE] : 0.6\n",
      "[392/1000]\n",
      "- [VAL] LOSS : 0.0004235712403897196 [SCORE] : 1.0\n",
      "[393/1000]\n",
      "- [TRAIN] LOSS : 0.0003062226188679536 [SCORE] : 0.6\n",
      "[393/1000]\n",
      "- [VAL] LOSS : 0.0004204695578664541 [SCORE] : 1.0\n",
      "[394/1000]\n",
      "- [TRAIN] LOSS : 0.0003039998089661822 [SCORE] : 0.6\n",
      "[394/1000]\n",
      "- [VAL] LOSS : 0.00041736869025044143 [SCORE] : 1.0\n",
      "[395/1000]\n",
      "- [TRAIN] LOSS : 0.00030179664123958596 [SCORE] : 0.6\n",
      "[395/1000]\n",
      "- [VAL] LOSS : 0.0004143037658650428 [SCORE] : 1.0\n",
      "[396/1000]\n",
      "- [TRAIN] LOSS : 0.000299611627512301 [SCORE] : 0.6\n",
      "[396/1000]\n",
      "- [VAL] LOSS : 0.00041127088479697704 [SCORE] : 1.0\n",
      "[397/1000]\n",
      "- [TRAIN] LOSS : 0.000297448446508497 [SCORE] : 0.6\n",
      "[397/1000]\n",
      "- [VAL] LOSS : 0.00040827025077305734 [SCORE] : 1.0\n",
      "[398/1000]\n",
      "- [TRAIN] LOSS : 0.0002952994565324237 [SCORE] : 0.6\n",
      "[398/1000]\n",
      "- [VAL] LOSS : 0.0004052717122249305 [SCORE] : 1.0\n",
      "[399/1000]\n",
      "- [TRAIN] LOSS : 0.00029317538913649816 [SCORE] : 0.6\n",
      "[399/1000]\n",
      "- [VAL] LOSS : 0.0004023257934022695 [SCORE] : 1.0\n",
      "[400/1000]\n",
      "- [TRAIN] LOSS : 0.00029106336878612635 [SCORE] : 0.6\n",
      "[400/1000]\n",
      "- [VAL] LOSS : 0.00039939393172971904 [SCORE] : 1.0\n",
      "[401/1000]\n",
      "- [TRAIN] LOSS : 0.00028896888252347706 [SCORE] : 0.6\n",
      "[401/1000]\n",
      "- [VAL] LOSS : 0.00039649769314564764 [SCORE] : 1.0\n",
      "[402/1000]\n",
      "- [TRAIN] LOSS : 0.0002868976026851063 [SCORE] : 0.6\n",
      "[402/1000]\n",
      "- [VAL] LOSS : 0.0003936299472115934 [SCORE] : 1.0\n",
      "[403/1000]\n",
      "- [TRAIN] LOSS : 0.0002848425346504276 [SCORE] : 0.6\n",
      "[403/1000]\n",
      "- [VAL] LOSS : 0.00039078015834093094 [SCORE] : 1.0\n",
      "[404/1000]\n",
      "- [TRAIN] LOSS : 0.0002828072853541623 [SCORE] : 0.6\n",
      "[404/1000]\n",
      "- [VAL] LOSS : 0.00038796107401140034 [SCORE] : 1.0\n",
      "[405/1000]\n",
      "- [TRAIN] LOSS : 0.00028079065668862313 [SCORE] : 0.6\n",
      "[405/1000]\n",
      "- [VAL] LOSS : 0.0003851638757623732 [SCORE] : 1.0\n",
      "[406/1000]\n",
      "- [TRAIN] LOSS : 0.0002787927039510881 [SCORE] : 0.6\n",
      "[406/1000]\n",
      "- [VAL] LOSS : 0.00038239365676417947 [SCORE] : 1.0\n",
      "[407/1000]\n",
      "- [TRAIN] LOSS : 0.00027681140151495737 [SCORE] : 0.6\n",
      "[407/1000]\n",
      "- [VAL] LOSS : 0.0003796443925239146 [SCORE] : 1.0\n",
      "[408/1000]\n",
      "- [TRAIN] LOSS : 0.0002748460411870231 [SCORE] : 0.6\n",
      "[408/1000]\n",
      "- [VAL] LOSS : 0.0003769135510083288 [SCORE] : 1.0\n",
      "[409/1000]\n",
      "- [TRAIN] LOSS : 0.0002728990861214697 [SCORE] : 0.6\n",
      "[409/1000]\n",
      "- [VAL] LOSS : 0.0003742149565368891 [SCORE] : 1.0\n",
      "[410/1000]\n",
      "- [TRAIN] LOSS : 0.000270965129796726 [SCORE] : 0.6\n",
      "[410/1000]\n",
      "- [VAL] LOSS : 0.0003715282364282757 [SCORE] : 1.0\n",
      "[411/1000]\n",
      "- [TRAIN] LOSS : 0.0002690499163387964 [SCORE] : 0.6\n",
      "[411/1000]\n",
      "- [VAL] LOSS : 0.0003688696015160531 [SCORE] : 1.0\n",
      "[412/1000]\n",
      "- [TRAIN] LOSS : 0.00026714969523406276 [SCORE] : 0.6\n",
      "[412/1000]\n",
      "- [VAL] LOSS : 0.0003662407980300486 [SCORE] : 1.0\n",
      "[413/1000]\n",
      "- [TRAIN] LOSS : 0.0002652660846554985 [SCORE] : 0.6\n",
      "[413/1000]\n",
      "- [VAL] LOSS : 0.00036361455568112433 [SCORE] : 1.0\n",
      "[414/1000]\n",
      "- [TRAIN] LOSS : 0.00026339894393458965 [SCORE] : 0.6\n",
      "[414/1000]\n",
      "- [VAL] LOSS : 0.0003610224521253258 [SCORE] : 1.0\n",
      "[415/1000]\n",
      "- [TRAIN] LOSS : 0.0002615483128465712 [SCORE] : 0.6\n",
      "[415/1000]\n",
      "- [VAL] LOSS : 0.0003584588412195444 [SCORE] : 1.0\n",
      "[416/1000]\n",
      "- [TRAIN] LOSS : 0.00025971200860415894 [SCORE] : 0.6\n",
      "[416/1000]\n",
      "- [VAL] LOSS : 0.00035590698826126754 [SCORE] : 1.0\n",
      "[417/1000]\n",
      "- [TRAIN] LOSS : 0.00025789325882215054 [SCORE] : 0.6\n",
      "[417/1000]\n",
      "- [VAL] LOSS : 0.0003533765266183764 [SCORE] : 1.0\n",
      "[418/1000]\n",
      "- [TRAIN] LOSS : 0.0002560881820196907 [SCORE] : 0.6\n",
      "[418/1000]\n",
      "- [VAL] LOSS : 0.000350885558873415 [SCORE] : 1.0\n",
      "[419/1000]\n",
      "- [TRAIN] LOSS : 0.00025429922097828237 [SCORE] : 0.6\n",
      "[419/1000]\n",
      "- [VAL] LOSS : 0.00034839127329178154 [SCORE] : 1.0\n",
      "[420/1000]\n",
      "- [TRAIN] LOSS : 0.0002525237223987157 [SCORE] : 0.6\n",
      "[420/1000]\n",
      "- [VAL] LOSS : 0.00034593231976032257 [SCORE] : 1.0\n",
      "[421/1000]\n",
      "- [TRAIN] LOSS : 0.00025076020683627575 [SCORE] : 0.6\n",
      "[421/1000]\n",
      "- [VAL] LOSS : 0.00034348046756349504 [SCORE] : 1.0\n",
      "[422/1000]\n",
      "- [TRAIN] LOSS : 0.00024901361127073566 [SCORE] : 0.6\n",
      "[422/1000]\n",
      "- [VAL] LOSS : 0.0003410520439501852 [SCORE] : 1.0\n",
      "[423/1000]\n",
      "- [TRAIN] LOSS : 0.00024728520074859264 [SCORE] : 0.6\n",
      "[423/1000]\n",
      "- [VAL] LOSS : 0.00033865292789414525 [SCORE] : 1.0\n",
      "[424/1000]\n",
      "- [TRAIN] LOSS : 0.0002455649567612757 [SCORE] : 0.6\n",
      "[424/1000]\n",
      "- [VAL] LOSS : 0.0003362713905517012 [SCORE] : 1.0\n",
      "[425/1000]\n",
      "- [TRAIN] LOSS : 0.00024386420651959875 [SCORE] : 0.6\n",
      "[425/1000]\n",
      "- [VAL] LOSS : 0.0003339057439006865 [SCORE] : 1.0\n",
      "[426/1000]\n",
      "- [TRAIN] LOSS : 0.00024217636382672936 [SCORE] : 0.6\n",
      "[426/1000]\n",
      "- [VAL] LOSS : 0.0003315571811981499 [SCORE] : 1.0\n",
      "[427/1000]\n",
      "- [TRAIN] LOSS : 0.00024050053422494482 [SCORE] : 0.6\n",
      "[427/1000]\n",
      "- [VAL] LOSS : 0.00032922843820415437 [SCORE] : 1.0\n",
      "[428/1000]\n",
      "- [TRAIN] LOSS : 0.0002388394883989046 [SCORE] : 0.6\n",
      "[428/1000]\n",
      "- [VAL] LOSS : 0.000326928828144446 [SCORE] : 1.0\n",
      "[429/1000]\n",
      "- [TRAIN] LOSS : 0.00023719040812769283 [SCORE] : 0.6\n",
      "[429/1000]\n",
      "- [VAL] LOSS : 0.00032463337993249297 [SCORE] : 1.0\n",
      "[430/1000]\n",
      "- [TRAIN] LOSS : 0.00023555785107115906 [SCORE] : 0.6\n",
      "[430/1000]\n",
      "- [VAL] LOSS : 0.00032237943378277123 [SCORE] : 1.0\n",
      "[431/1000]\n",
      "- [TRAIN] LOSS : 0.00023393285810016095 [SCORE] : 0.6\n",
      "[431/1000]\n",
      "- [VAL] LOSS : 0.00032012321753427386 [SCORE] : 1.0\n",
      "[432/1000]\n",
      "- [TRAIN] LOSS : 0.0002323289818984146 [SCORE] : 0.6\n",
      "[432/1000]\n",
      "- [VAL] LOSS : 0.0003178894694428891 [SCORE] : 1.0\n",
      "[433/1000]\n",
      "- [TRAIN] LOSS : 0.00023073271149769424 [SCORE] : 0.6\n",
      "[433/1000]\n",
      "- [VAL] LOSS : 0.00031567455152980983 [SCORE] : 1.0\n",
      "[434/1000]\n",
      "- [TRAIN] LOSS : 0.0002291534940013662 [SCORE] : 0.6\n",
      "[434/1000]\n",
      "- [VAL] LOSS : 0.0003134750004392117 [SCORE] : 1.0\n",
      "[435/1000]\n",
      "- [TRAIN] LOSS : 0.00022758423583582043 [SCORE] : 0.6\n",
      "[435/1000]\n",
      "- [VAL] LOSS : 0.0003113012353423983 [SCORE] : 1.0\n",
      "[436/1000]\n",
      "- [TRAIN] LOSS : 0.00022602885340650876 [SCORE] : 0.6\n",
      "[436/1000]\n",
      "- [VAL] LOSS : 0.000309140159515664 [SCORE] : 1.0\n",
      "[437/1000]\n",
      "- [TRAIN] LOSS : 0.00022448632613910984 [SCORE] : 0.6\n",
      "[437/1000]\n",
      "- [VAL] LOSS : 0.00030699901981279254 [SCORE] : 1.0\n",
      "[438/1000]\n",
      "- [TRAIN] LOSS : 0.00022295656284162155 [SCORE] : 0.6\n",
      "[438/1000]\n",
      "- [VAL] LOSS : 0.00030487458570860326 [SCORE] : 1.0\n",
      "[439/1000]\n",
      "- [TRAIN] LOSS : 0.00022143607687515518 [SCORE] : 0.6\n",
      "[439/1000]\n",
      "- [VAL] LOSS : 0.0003027713391929865 [SCORE] : 1.0\n",
      "[440/1000]\n",
      "- [TRAIN] LOSS : 0.00021993043725766862 [SCORE] : 0.6\n",
      "[440/1000]\n",
      "- [VAL] LOSS : 0.00030067848274484277 [SCORE] : 1.0\n",
      "[441/1000]\n",
      "- [TRAIN] LOSS : 0.00021843561068332444 [SCORE] : 0.6\n",
      "[441/1000]\n",
      "- [VAL] LOSS : 0.00029860055656172335 [SCORE] : 1.0\n",
      "[442/1000]\n",
      "- [TRAIN] LOSS : 0.00021695279574487358 [SCORE] : 0.6\n",
      "[442/1000]\n",
      "- [VAL] LOSS : 0.0002965564781334251 [SCORE] : 1.0\n",
      "[443/1000]\n",
      "- [TRAIN] LOSS : 0.00021548466271876048 [SCORE] : 0.6\n",
      "[443/1000]\n",
      "- [VAL] LOSS : 0.00029451376758515835 [SCORE] : 1.0\n",
      "[444/1000]\n",
      "- [TRAIN] LOSS : 0.00021402624988695607 [SCORE] : 0.6\n",
      "[444/1000]\n",
      "- [VAL] LOSS : 0.00029247920610941947 [SCORE] : 1.0\n",
      "[445/1000]\n",
      "- [TRAIN] LOSS : 0.00021257849099735418 [SCORE] : 0.6\n",
      "[445/1000]\n",
      "- [VAL] LOSS : 0.00029047223506495357 [SCORE] : 1.0\n",
      "[446/1000]\n",
      "- [TRAIN] LOSS : 0.00021114239061716943 [SCORE] : 0.6\n",
      "[446/1000]\n",
      "- [VAL] LOSS : 0.0002884881687350571 [SCORE] : 1.0\n",
      "[447/1000]\n",
      "- [TRAIN] LOSS : 0.00020971941848983987 [SCORE] : 0.6\n",
      "[447/1000]\n",
      "- [VAL] LOSS : 0.00028651198954321444 [SCORE] : 1.0\n",
      "[448/1000]\n",
      "- [TRAIN] LOSS : 0.00020830855646636337 [SCORE] : 0.6\n",
      "[448/1000]\n",
      "- [VAL] LOSS : 0.00028456069412641227 [SCORE] : 1.0\n",
      "[449/1000]\n",
      "- [TRAIN] LOSS : 0.0002069048714474775 [SCORE] : 0.6\n",
      "[449/1000]\n",
      "- [VAL] LOSS : 0.0002826045092660934 [SCORE] : 1.0\n",
      "[450/1000]\n",
      "- [TRAIN] LOSS : 0.00020551503791163366 [SCORE] : 0.6\n",
      "[450/1000]\n",
      "- [VAL] LOSS : 0.00028067672974430025 [SCORE] : 1.0\n",
      "[451/1000]\n",
      "- [TRAIN] LOSS : 0.00020413738626909133 [SCORE] : 0.6\n",
      "[451/1000]\n",
      "- [VAL] LOSS : 0.00027876553940586746 [SCORE] : 1.0\n",
      "[452/1000]\n",
      "- [TRAIN] LOSS : 0.00020276612388746192 [SCORE] : 0.6\n",
      "[452/1000]\n",
      "- [VAL] LOSS : 0.0002768746926449239 [SCORE] : 1.0\n",
      "[453/1000]\n",
      "- [TRAIN] LOSS : 0.00020140876974134397 [SCORE] : 0.6\n",
      "[453/1000]\n",
      "- [VAL] LOSS : 0.0002749761624727398 [SCORE] : 1.0\n",
      "[454/1000]\n",
      "- [TRAIN] LOSS : 0.00020006444732037683 [SCORE] : 0.6\n",
      "[454/1000]\n",
      "- [VAL] LOSS : 0.00027310854056850076 [SCORE] : 1.0\n",
      "[455/1000]\n",
      "- [TRAIN] LOSS : 0.00019872595488171403 [SCORE] : 0.6\n",
      "[455/1000]\n",
      "- [VAL] LOSS : 0.00027125715860165656 [SCORE] : 1.0\n",
      "[456/1000]\n",
      "- [TRAIN] LOSS : 0.00019740015753389646 [SCORE] : 0.6\n",
      "[456/1000]\n",
      "- [VAL] LOSS : 0.00026941701071336865 [SCORE] : 1.0\n",
      "[457/1000]\n",
      "- [TRAIN] LOSS : 0.00019608067862767105 [SCORE] : 0.6\n",
      "[457/1000]\n",
      "- [VAL] LOSS : 0.00026759254978969693 [SCORE] : 1.0\n",
      "[458/1000]\n",
      "- [TRAIN] LOSS : 0.00019477600192961594 [SCORE] : 0.6\n",
      "[458/1000]\n",
      "- [VAL] LOSS : 0.000265798153122887 [SCORE] : 1.0\n",
      "[459/1000]\n",
      "- [TRAIN] LOSS : 0.00019348010876759267 [SCORE] : 0.6\n",
      "[459/1000]\n",
      "- [VAL] LOSS : 0.000264011905528605 [SCORE] : 1.0\n",
      "[460/1000]\n",
      "- [TRAIN] LOSS : 0.00019219653234661866 [SCORE] : 0.6\n",
      "[460/1000]\n",
      "- [VAL] LOSS : 0.00026224387693218887 [SCORE] : 1.0\n",
      "[461/1000]\n",
      "- [TRAIN] LOSS : 0.0001909255147135506 [SCORE] : 0.6\n",
      "[461/1000]\n",
      "- [VAL] LOSS : 0.0002604843466542661 [SCORE] : 1.0\n",
      "[462/1000]\n",
      "- [TRAIN] LOSS : 0.00018966330729502562 [SCORE] : 0.6\n",
      "[462/1000]\n",
      "- [VAL] LOSS : 0.0002587403869256377 [SCORE] : 1.0\n",
      "[463/1000]\n",
      "- [TRAIN] LOSS : 0.0001884118876963233 [SCORE] : 0.6\n",
      "[463/1000]\n",
      "- [VAL] LOSS : 0.0002570193901192397 [SCORE] : 1.0\n",
      "[464/1000]\n",
      "- [TRAIN] LOSS : 0.00018716679333010688 [SCORE] : 0.6\n",
      "[464/1000]\n",
      "- [VAL] LOSS : 0.00025529522099532187 [SCORE] : 1.0\n",
      "[465/1000]\n",
      "- [TRAIN] LOSS : 0.00018593194690765812 [SCORE] : 0.6\n",
      "[465/1000]\n",
      "- [VAL] LOSS : 0.0002535877574700862 [SCORE] : 1.0\n",
      "[466/1000]\n",
      "- [TRAIN] LOSS : 0.0001847061231577148 [SCORE] : 0.6\n",
      "[466/1000]\n",
      "- [VAL] LOSS : 0.0002518905675970018 [SCORE] : 1.0\n",
      "[467/1000]\n",
      "- [TRAIN] LOSS : 0.00018349035672144965 [SCORE] : 0.6\n",
      "[467/1000]\n",
      "- [VAL] LOSS : 0.00025020420434884727 [SCORE] : 1.0\n",
      "[468/1000]\n",
      "- [TRAIN] LOSS : 0.0001822839563828893 [SCORE] : 0.6\n",
      "[468/1000]\n",
      "- [VAL] LOSS : 0.0002485460718162358 [SCORE] : 1.0\n",
      "[469/1000]\n",
      "- [TRAIN] LOSS : 0.0001810851419577375 [SCORE] : 0.6\n",
      "[469/1000]\n",
      "- [VAL] LOSS : 0.0002468978927936405 [SCORE] : 1.0\n",
      "[470/1000]\n",
      "- [TRAIN] LOSS : 0.0001798956043785438 [SCORE] : 0.6\n",
      "[470/1000]\n",
      "- [VAL] LOSS : 0.00024527747882530093 [SCORE] : 1.0\n",
      "[471/1000]\n",
      "- [TRAIN] LOSS : 0.0001787177704197044 [SCORE] : 0.6\n",
      "[471/1000]\n",
      "- [VAL] LOSS : 0.00024365885474253446 [SCORE] : 1.0\n",
      "[472/1000]\n",
      "- [TRAIN] LOSS : 0.00017755129471576462 [SCORE] : 0.6\n",
      "[472/1000]\n",
      "- [VAL] LOSS : 0.00024206105445045978 [SCORE] : 1.0\n",
      "[473/1000]\n",
      "- [TRAIN] LOSS : 0.00017639039191029345 [SCORE] : 0.6\n",
      "[473/1000]\n",
      "- [VAL] LOSS : 0.0002404678671155125 [SCORE] : 1.0\n",
      "[474/1000]\n",
      "- [TRAIN] LOSS : 0.0001752421851657952 [SCORE] : 0.6\n",
      "[474/1000]\n",
      "- [VAL] LOSS : 0.00023888600117061287 [SCORE] : 1.0\n",
      "[475/1000]\n",
      "- [TRAIN] LOSS : 0.000174104042040805 [SCORE] : 0.6\n",
      "[475/1000]\n",
      "- [VAL] LOSS : 0.000237311702221632 [SCORE] : 1.0\n",
      "[476/1000]\n",
      "- [TRAIN] LOSS : 0.00017296883937281866 [SCORE] : 0.6\n",
      "[476/1000]\n",
      "- [VAL] LOSS : 0.00023575166414957494 [SCORE] : 1.0\n",
      "[477/1000]\n",
      "- [TRAIN] LOSS : 0.0001718467896959434 [SCORE] : 0.6\n",
      "[477/1000]\n",
      "- [VAL] LOSS : 0.00023419770877808332 [SCORE] : 1.0\n",
      "[478/1000]\n",
      "- [TRAIN] LOSS : 0.00017073000296174238 [SCORE] : 0.6\n",
      "[478/1000]\n",
      "- [VAL] LOSS : 0.00023266700736712664 [SCORE] : 1.0\n",
      "[479/1000]\n",
      "- [TRAIN] LOSS : 0.0001696237493888475 [SCORE] : 0.6\n",
      "[479/1000]\n",
      "- [VAL] LOSS : 0.00023113861971069127 [SCORE] : 1.0\n",
      "[480/1000]\n",
      "- [TRAIN] LOSS : 0.00016852301826778178 [SCORE] : 0.6\n",
      "[480/1000]\n",
      "- [VAL] LOSS : 0.00022962807270232588 [SCORE] : 1.0\n",
      "[481/1000]\n",
      "- [TRAIN] LOSS : 0.00016743243613746018 [SCORE] : 0.6\n",
      "[481/1000]\n",
      "- [VAL] LOSS : 0.00022812289535067976 [SCORE] : 1.0\n",
      "[482/1000]\n",
      "- [TRAIN] LOSS : 0.00016634831942307453 [SCORE] : 0.6\n",
      "[482/1000]\n",
      "- [VAL] LOSS : 0.0002266312949359417 [SCORE] : 1.0\n",
      "[483/1000]\n",
      "- [TRAIN] LOSS : 0.00016527448557705307 [SCORE] : 0.6\n",
      "[483/1000]\n",
      "- [VAL] LOSS : 0.00022514560259878635 [SCORE] : 1.0\n",
      "[484/1000]\n",
      "- [TRAIN] LOSS : 0.0001642108797871818 [SCORE] : 0.6\n",
      "[484/1000]\n",
      "- [VAL] LOSS : 0.00022366772464010864 [SCORE] : 1.0\n",
      "[485/1000]\n",
      "- [TRAIN] LOSS : 0.00016314874422581246 [SCORE] : 0.6\n",
      "[485/1000]\n",
      "- [VAL] LOSS : 0.0002222024922957644 [SCORE] : 1.0\n",
      "[486/1000]\n",
      "- [TRAIN] LOSS : 0.0001621003587691424 [SCORE] : 0.6\n",
      "[486/1000]\n",
      "- [VAL] LOSS : 0.00022076259483583272 [SCORE] : 1.0\n",
      "[487/1000]\n",
      "- [TRAIN] LOSS : 0.00016105909793016812 [SCORE] : 0.6\n",
      "[487/1000]\n",
      "- [VAL] LOSS : 0.00021932032541371882 [SCORE] : 1.0\n",
      "[488/1000]\n",
      "- [TRAIN] LOSS : 0.00016001959544761728 [SCORE] : 0.6\n",
      "[488/1000]\n",
      "- [VAL] LOSS : 0.00021788013691548258 [SCORE] : 1.0\n",
      "[489/1000]\n",
      "- [TRAIN] LOSS : 0.00015899410742955904 [SCORE] : 0.6\n",
      "[489/1000]\n",
      "- [VAL] LOSS : 0.00021646541426889598 [SCORE] : 1.0\n",
      "[490/1000]\n",
      "- [TRAIN] LOSS : 0.000157975206093397 [SCORE] : 0.6\n",
      "[490/1000]\n",
      "- [VAL] LOSS : 0.00021505527547560632 [SCORE] : 1.0\n",
      "[491/1000]\n",
      "- [TRAIN] LOSS : 0.0001569654651878712 [SCORE] : 0.6\n",
      "[491/1000]\n",
      "- [VAL] LOSS : 0.00021365811699070036 [SCORE] : 1.0\n",
      "[492/1000]\n",
      "- [TRAIN] LOSS : 0.00015595918618297824 [SCORE] : 0.6\n",
      "[492/1000]\n",
      "- [VAL] LOSS : 0.00021226970420684665 [SCORE] : 1.0\n",
      "[493/1000]\n",
      "- [TRAIN] LOSS : 0.00015496164705837147 [SCORE] : 0.6\n",
      "[493/1000]\n",
      "- [VAL] LOSS : 0.00021088602079544216 [SCORE] : 1.0\n",
      "[494/1000]\n",
      "- [TRAIN] LOSS : 0.0001539695983713803 [SCORE] : 0.6\n",
      "[494/1000]\n",
      "- [VAL] LOSS : 0.00020951508486177772 [SCORE] : 1.0\n",
      "[495/1000]\n",
      "- [TRAIN] LOSS : 0.00015298700212345768 [SCORE] : 0.6\n",
      "[495/1000]\n",
      "- [VAL] LOSS : 0.00020816436153836548 [SCORE] : 1.0\n",
      "[496/1000]\n",
      "- [TRAIN] LOSS : 0.0001520124026380169 [SCORE] : 0.6\n",
      "[496/1000]\n",
      "- [VAL] LOSS : 0.00020680682791862637 [SCORE] : 1.0\n",
      "[497/1000]\n",
      "- [TRAIN] LOSS : 0.00015104314176520953 [SCORE] : 0.6\n",
      "[497/1000]\n",
      "- [VAL] LOSS : 0.0002054708602372557 [SCORE] : 1.0\n",
      "[498/1000]\n",
      "- [TRAIN] LOSS : 0.00015007972930713246 [SCORE] : 0.6\n",
      "[498/1000]\n",
      "- [VAL] LOSS : 0.0002041442785412073 [SCORE] : 1.0\n",
      "[499/1000]\n",
      "- [TRAIN] LOSS : 0.00014912568100650486 [SCORE] : 0.6\n",
      "[499/1000]\n",
      "- [VAL] LOSS : 0.00020282657351344824 [SCORE] : 1.0\n",
      "[500/1000]\n",
      "- [TRAIN] LOSS : 0.0001481770605702574 [SCORE] : 0.6\n",
      "[500/1000]\n",
      "- [VAL] LOSS : 0.00020151543139945716 [SCORE] : 1.0\n",
      "[501/1000]\n",
      "- [TRAIN] LOSS : 0.00014723858087866876 [SCORE] : 0.6\n",
      "[501/1000]\n",
      "- [VAL] LOSS : 0.00020021115778945386 [SCORE] : 1.0\n",
      "[502/1000]\n",
      "- [TRAIN] LOSS : 0.0001463056910627832 [SCORE] : 0.6\n",
      "[502/1000]\n",
      "- [VAL] LOSS : 0.00019892209093086421 [SCORE] : 1.0\n",
      "[503/1000]\n",
      "- [TRAIN] LOSS : 0.0001453755792075147 [SCORE] : 0.6\n",
      "[503/1000]\n",
      "- [VAL] LOSS : 0.0001976400235434994 [SCORE] : 1.0\n",
      "[504/1000]\n",
      "- [TRAIN] LOSS : 0.00014445325844765952 [SCORE] : 0.6\n",
      "[504/1000]\n",
      "- [VAL] LOSS : 0.0001963645772775635 [SCORE] : 1.0\n",
      "[505/1000]\n",
      "- [TRAIN] LOSS : 0.00014354000062060852 [SCORE] : 0.6\n",
      "[505/1000]\n",
      "- [VAL] LOSS : 0.0001950997393578291 [SCORE] : 1.0\n",
      "[506/1000]\n",
      "- [TRAIN] LOSS : 0.00014263549286018437 [SCORE] : 0.6\n",
      "[506/1000]\n",
      "- [VAL] LOSS : 0.00019385678751859814 [SCORE] : 1.0\n",
      "[507/1000]\n",
      "- [TRAIN] LOSS : 0.0001417333260178566 [SCORE] : 0.6\n",
      "[507/1000]\n",
      "- [VAL] LOSS : 0.00019260143744759262 [SCORE] : 1.0\n",
      "[508/1000]\n",
      "- [TRAIN] LOSS : 0.00014084030359905834 [SCORE] : 0.6\n",
      "[508/1000]\n",
      "- [VAL] LOSS : 0.00019137185881845653 [SCORE] : 1.0\n",
      "[509/1000]\n",
      "- [TRAIN] LOSS : 0.00013995341626772036 [SCORE] : 0.6\n",
      "[509/1000]\n",
      "- [VAL] LOSS : 0.00019015093857888132 [SCORE] : 1.0\n",
      "[510/1000]\n",
      "- [TRAIN] LOSS : 0.00013907096727052703 [SCORE] : 0.6\n",
      "[510/1000]\n",
      "- [VAL] LOSS : 0.0001889260020107031 [SCORE] : 1.0\n",
      "[511/1000]\n",
      "- [TRAIN] LOSS : 0.0001381965916759024 [SCORE] : 0.6\n",
      "[511/1000]\n",
      "- [VAL] LOSS : 0.0001877118193078786 [SCORE] : 1.0\n",
      "[512/1000]\n",
      "- [TRAIN] LOSS : 0.00013732959487242625 [SCORE] : 0.6\n",
      "[512/1000]\n",
      "- [VAL] LOSS : 0.00018651717982720584 [SCORE] : 1.0\n",
      "[513/1000]\n",
      "- [TRAIN] LOSS : 0.0001364646916044876 [SCORE] : 0.6\n",
      "[513/1000]\n",
      "- [VAL] LOSS : 0.00018531833484303206 [SCORE] : 1.0\n",
      "[514/1000]\n",
      "- [TRAIN] LOSS : 0.00013561067656458665 [SCORE] : 0.6\n",
      "[514/1000]\n",
      "- [VAL] LOSS : 0.00018413063662592322 [SCORE] : 1.0\n",
      "[515/1000]\n",
      "- [TRAIN] LOSS : 0.00013475958694471047 [SCORE] : 0.6\n",
      "[515/1000]\n",
      "- [VAL] LOSS : 0.00018297022324986756 [SCORE] : 1.0\n",
      "[516/1000]\n",
      "- [TRAIN] LOSS : 0.00013391515240073203 [SCORE] : 0.6\n",
      "[516/1000]\n",
      "- [VAL] LOSS : 0.00018178884056396782 [SCORE] : 1.0\n",
      "[517/1000]\n",
      "- [TRAIN] LOSS : 0.0001330770576411548 [SCORE] : 0.6\n",
      "[517/1000]\n",
      "- [VAL] LOSS : 0.00018064129108097404 [SCORE] : 1.0\n",
      "[518/1000]\n",
      "- [TRAIN] LOSS : 0.0001322449703972476 [SCORE] : 0.6\n",
      "[518/1000]\n",
      "- [VAL] LOSS : 0.00017948138702195138 [SCORE] : 1.0\n",
      "[519/1000]\n",
      "- [TRAIN] LOSS : 0.00013140724768163637 [SCORE] : 0.6\n",
      "[519/1000]\n",
      "- [VAL] LOSS : 0.00017836886399891227 [SCORE] : 1.0\n",
      "[520/1000]\n",
      "- [TRAIN] LOSS : 0.00013058737483030806 [SCORE] : 0.6\n",
      "[520/1000]\n",
      "- [VAL] LOSS : 0.00017724829376675189 [SCORE] : 1.0\n",
      "[521/1000]\n",
      "- [TRAIN] LOSS : 0.0001297804248072983 [SCORE] : 0.6\n",
      "[521/1000]\n",
      "- [VAL] LOSS : 0.00017612149531487375 [SCORE] : 1.0\n",
      "[522/1000]\n",
      "- [TRAIN] LOSS : 0.00012896580495483552 [SCORE] : 0.6\n",
      "[522/1000]\n",
      "- [VAL] LOSS : 0.00017502203991170973 [SCORE] : 1.0\n",
      "[523/1000]\n",
      "- [TRAIN] LOSS : 0.00012816179757161686 [SCORE] : 0.6\n",
      "[523/1000]\n",
      "- [VAL] LOSS : 0.000173931970493868 [SCORE] : 1.0\n",
      "[524/1000]\n",
      "- [TRAIN] LOSS : 0.0001273741002175181 [SCORE] : 0.6\n",
      "[524/1000]\n",
      "- [VAL] LOSS : 0.00017282975022681057 [SCORE] : 1.0\n",
      "[525/1000]\n",
      "- [TRAIN] LOSS : 0.00012657996946169686 [SCORE] : 0.6\n",
      "[525/1000]\n",
      "- [VAL] LOSS : 0.00017176636902149767 [SCORE] : 1.0\n",
      "[526/1000]\n",
      "- [TRAIN] LOSS : 0.0001257913412700873 [SCORE] : 0.6\n",
      "[526/1000]\n",
      "- [VAL] LOSS : 0.00017068686429411173 [SCORE] : 1.0\n",
      "[527/1000]\n",
      "- [TRAIN] LOSS : 0.0001250210569802827 [SCORE] : 0.6\n",
      "[527/1000]\n",
      "- [VAL] LOSS : 0.00016961384972091764 [SCORE] : 1.0\n",
      "[528/1000]\n",
      "- [TRAIN] LOSS : 0.0001242388255680756 [SCORE] : 0.6\n",
      "[528/1000]\n",
      "- [VAL] LOSS : 0.00016855854482855648 [SCORE] : 1.0\n",
      "[529/1000]\n",
      "- [TRAIN] LOSS : 0.00012346983906657744 [SCORE] : 0.6\n",
      "[529/1000]\n",
      "- [VAL] LOSS : 0.00016750440408941358 [SCORE] : 1.0\n",
      "[530/1000]\n",
      "- [TRAIN] LOSS : 0.000122704757086467 [SCORE] : 0.6\n",
      "[530/1000]\n",
      "- [VAL] LOSS : 0.0001664602168602869 [SCORE] : 1.0\n",
      "[531/1000]\n",
      "- [TRAIN] LOSS : 0.00012195528155037513 [SCORE] : 0.6\n",
      "[531/1000]\n",
      "- [VAL] LOSS : 0.00016540814249310642 [SCORE] : 1.0\n",
      "[532/1000]\n",
      "- [TRAIN] LOSS : 0.00012119951861677691 [SCORE] : 0.6\n",
      "[532/1000]\n",
      "- [VAL] LOSS : 0.0001643892319407314 [SCORE] : 1.0\n",
      "[533/1000]\n",
      "- [TRAIN] LOSS : 0.00012044933391734958 [SCORE] : 0.6\n",
      "[533/1000]\n",
      "- [VAL] LOSS : 0.00016335435793735087 [SCORE] : 1.0\n",
      "[534/1000]\n",
      "- [TRAIN] LOSS : 0.00011970793081369871 [SCORE] : 0.6\n",
      "[534/1000]\n",
      "- [VAL] LOSS : 0.00016234700160566717 [SCORE] : 1.0\n",
      "[535/1000]\n",
      "- [TRAIN] LOSS : 0.00011896899401714715 [SCORE] : 0.6\n",
      "[535/1000]\n",
      "- [VAL] LOSS : 0.00016134294855874032 [SCORE] : 1.0\n",
      "[536/1000]\n",
      "- [TRAIN] LOSS : 0.00011823903647988724 [SCORE] : 0.6\n",
      "[536/1000]\n",
      "- [VAL] LOSS : 0.0001603403507033363 [SCORE] : 1.0\n",
      "[537/1000]\n",
      "- [TRAIN] LOSS : 0.00011751921774703079 [SCORE] : 0.6\n",
      "[537/1000]\n",
      "- [VAL] LOSS : 0.00015933015674818307 [SCORE] : 1.0\n",
      "[538/1000]\n",
      "- [TRAIN] LOSS : 0.00011679254409197407 [SCORE] : 0.6\n",
      "[538/1000]\n",
      "- [VAL] LOSS : 0.00015834355144761503 [SCORE] : 1.0\n",
      "[539/1000]\n",
      "- [TRAIN] LOSS : 0.00011607009582803585 [SCORE] : 0.6\n",
      "[539/1000]\n",
      "- [VAL] LOSS : 0.00015737253124825656 [SCORE] : 1.0\n",
      "[540/1000]\n",
      "- [TRAIN] LOSS : 0.00011535956679532925 [SCORE] : 0.6\n",
      "[540/1000]\n",
      "- [VAL] LOSS : 0.0001564106933074072 [SCORE] : 1.0\n",
      "[541/1000]\n",
      "- [TRAIN] LOSS : 0.00011465532006695866 [SCORE] : 0.6\n",
      "[541/1000]\n",
      "- [VAL] LOSS : 0.00015545547648798674 [SCORE] : 1.0\n",
      "[542/1000]\n",
      "- [TRAIN] LOSS : 0.00011396296928675534 [SCORE] : 0.6\n",
      "[542/1000]\n",
      "- [VAL] LOSS : 0.00015449279453605413 [SCORE] : 1.0\n",
      "[543/1000]\n",
      "- [TRAIN] LOSS : 0.00011326169139162327 [SCORE] : 0.6\n",
      "[543/1000]\n",
      "- [VAL] LOSS : 0.00015354745846707374 [SCORE] : 1.0\n",
      "[544/1000]\n",
      "- [TRAIN] LOSS : 0.00011256928773946129 [SCORE] : 0.6\n",
      "[544/1000]\n",
      "- [VAL] LOSS : 0.00015260263171512634 [SCORE] : 1.0\n",
      "[545/1000]\n",
      "- [TRAIN] LOSS : 0.00011188301165627005 [SCORE] : 0.6\n",
      "[545/1000]\n",
      "- [VAL] LOSS : 0.00015168155368883163 [SCORE] : 1.0\n",
      "[546/1000]\n",
      "- [TRAIN] LOSS : 0.00011119834137692426 [SCORE] : 0.6\n",
      "[546/1000]\n",
      "- [VAL] LOSS : 0.0001507549750385806 [SCORE] : 1.0\n",
      "[547/1000]\n",
      "- [TRAIN] LOSS : 0.00011052849755894082 [SCORE] : 0.6\n",
      "[547/1000]\n",
      "- [VAL] LOSS : 0.00014982577704358846 [SCORE] : 1.0\n",
      "[548/1000]\n",
      "- [TRAIN] LOSS : 0.00010985454597782034 [SCORE] : 0.6\n",
      "[548/1000]\n",
      "- [VAL] LOSS : 0.00014893269690219313 [SCORE] : 1.0\n",
      "[549/1000]\n",
      "- [TRAIN] LOSS : 0.00010919266593797753 [SCORE] : 0.6\n",
      "[549/1000]\n",
      "- [VAL] LOSS : 0.00014801937504671514 [SCORE] : 1.0\n",
      "[550/1000]\n",
      "- [TRAIN] LOSS : 0.00010852678436397885 [SCORE] : 0.6\n",
      "[550/1000]\n",
      "- [VAL] LOSS : 0.0001471342984586954 [SCORE] : 1.0\n",
      "[551/1000]\n",
      "- [TRAIN] LOSS : 0.00010786790662677958 [SCORE] : 0.6\n",
      "[551/1000]\n",
      "- [VAL] LOSS : 0.00014624287723563612 [SCORE] : 1.0\n",
      "[552/1000]\n",
      "- [TRAIN] LOSS : 0.00010721505799059136 [SCORE] : 0.6\n",
      "[552/1000]\n",
      "- [VAL] LOSS : 0.0001453668373869732 [SCORE] : 1.0\n",
      "[553/1000]\n",
      "- [TRAIN] LOSS : 0.00010656882319987441 [SCORE] : 0.6\n",
      "[553/1000]\n",
      "- [VAL] LOSS : 0.00014449030277319252 [SCORE] : 1.0\n",
      "[554/1000]\n",
      "- [TRAIN] LOSS : 0.00010593385862496992 [SCORE] : 0.6\n",
      "[554/1000]\n",
      "- [VAL] LOSS : 0.00014361330249812454 [SCORE] : 1.0\n",
      "[555/1000]\n",
      "- [TRAIN] LOSS : 0.00010529111508124818 [SCORE] : 0.6\n",
      "[555/1000]\n",
      "- [VAL] LOSS : 0.00014274446584749967 [SCORE] : 1.0\n",
      "[556/1000]\n",
      "- [TRAIN] LOSS : 0.00010465442343653801 [SCORE] : 0.6\n",
      "[556/1000]\n",
      "- [VAL] LOSS : 0.0001418811734765768 [SCORE] : 1.0\n",
      "[557/1000]\n",
      "- [TRAIN] LOSS : 0.00010402475939675545 [SCORE] : 0.6\n",
      "[557/1000]\n",
      "- [VAL] LOSS : 0.00014103455760050565 [SCORE] : 1.0\n",
      "[558/1000]\n",
      "- [TRAIN] LOSS : 0.00010339834213179226 [SCORE] : 0.6\n",
      "[558/1000]\n",
      "- [VAL] LOSS : 0.00014017576177138835 [SCORE] : 1.0\n",
      "[559/1000]\n",
      "- [TRAIN] LOSS : 0.00010277750043314881 [SCORE] : 0.6\n",
      "[559/1000]\n",
      "- [VAL] LOSS : 0.000139338182634674 [SCORE] : 1.0\n",
      "[560/1000]\n",
      "- [TRAIN] LOSS : 0.00010216187680877435 [SCORE] : 0.6\n",
      "[560/1000]\n",
      "- [VAL] LOSS : 0.00013849648530595005 [SCORE] : 1.0\n",
      "[561/1000]\n",
      "- [TRAIN] LOSS : 0.00010154632788423138 [SCORE] : 0.6\n",
      "[561/1000]\n",
      "- [VAL] LOSS : 0.00013766299525741488 [SCORE] : 1.0\n",
      "[562/1000]\n",
      "- [TRAIN] LOSS : 0.00010093873909985025 [SCORE] : 0.6\n",
      "[562/1000]\n",
      "- [VAL] LOSS : 0.00013684014265891165 [SCORE] : 1.0\n",
      "[563/1000]\n",
      "- [TRAIN] LOSS : 0.00010033245926024392 [SCORE] : 0.6\n",
      "[563/1000]\n",
      "- [VAL] LOSS : 0.00013600706006400287 [SCORE] : 1.0\n",
      "[564/1000]\n",
      "- [TRAIN] LOSS : 9.973527897576181e-05 [SCORE] : 0.6\n",
      "[564/1000]\n",
      "- [VAL] LOSS : 0.0001351957762381062 [SCORE] : 1.0\n",
      "[565/1000]\n",
      "- [TRAIN] LOSS : 9.913772397946256e-05 [SCORE] : 0.6\n",
      "[565/1000]\n",
      "- [VAL] LOSS : 0.00013436829613056034 [SCORE] : 1.0\n",
      "[566/1000]\n",
      "- [TRAIN] LOSS : 9.854234934512837e-05 [SCORE] : 0.6\n",
      "[566/1000]\n",
      "- [VAL] LOSS : 0.00013356316776480526 [SCORE] : 1.0\n",
      "[567/1000]\n",
      "- [TRAIN] LOSS : 9.795555937065122e-05 [SCORE] : 0.6\n",
      "[567/1000]\n",
      "- [VAL] LOSS : 0.00013276301615405828 [SCORE] : 1.0\n",
      "[568/1000]\n",
      "- [TRAIN] LOSS : 9.737301467491003e-05 [SCORE] : 0.6\n",
      "[568/1000]\n",
      "- [VAL] LOSS : 0.00013195586507208645 [SCORE] : 1.0\n",
      "[569/1000]\n",
      "- [TRAIN] LOSS : 9.679130040846455e-05 [SCORE] : 0.6\n",
      "[569/1000]\n",
      "- [VAL] LOSS : 0.00013116284389980137 [SCORE] : 1.0\n",
      "[570/1000]\n",
      "- [TRAIN] LOSS : 9.62137009385818e-05 [SCORE] : 0.6\n",
      "[570/1000]\n",
      "- [VAL] LOSS : 0.00013036724703852087 [SCORE] : 1.0\n",
      "[571/1000]\n",
      "- [TRAIN] LOSS : 9.564099333753499e-05 [SCORE] : 0.6\n",
      "[571/1000]\n",
      "- [VAL] LOSS : 0.00012957736907992512 [SCORE] : 1.0\n",
      "[572/1000]\n",
      "- [TRAIN] LOSS : 9.506884768294792e-05 [SCORE] : 0.6\n",
      "[572/1000]\n",
      "- [VAL] LOSS : 0.0001288064377149567 [SCORE] : 1.0\n",
      "[573/1000]\n",
      "- [TRAIN] LOSS : 9.45049764898916e-05 [SCORE] : 0.6\n",
      "[573/1000]\n",
      "- [VAL] LOSS : 0.00012803307618014514 [SCORE] : 1.0\n",
      "[574/1000]\n",
      "- [TRAIN] LOSS : 9.394028796426331e-05 [SCORE] : 0.6\n",
      "[574/1000]\n",
      "- [VAL] LOSS : 0.00012725932174362242 [SCORE] : 1.0\n",
      "[575/1000]\n",
      "- [TRAIN] LOSS : 9.338219897472299e-05 [SCORE] : 0.6\n",
      "[575/1000]\n",
      "- [VAL] LOSS : 0.0001264938764506951 [SCORE] : 1.0\n",
      "[576/1000]\n",
      "- [TRAIN] LOSS : 9.282966323856575e-05 [SCORE] : 0.6\n",
      "[576/1000]\n",
      "- [VAL] LOSS : 0.0001257262338185683 [SCORE] : 1.0\n",
      "[577/1000]\n",
      "- [TRAIN] LOSS : 9.227671350042025e-05 [SCORE] : 0.6\n",
      "[577/1000]\n",
      "- [VAL] LOSS : 0.00012497352145146579 [SCORE] : 1.0\n",
      "[578/1000]\n",
      "- [TRAIN] LOSS : 9.172894909473447e-05 [SCORE] : 0.6\n",
      "[578/1000]\n",
      "- [VAL] LOSS : 0.00012422053259797394 [SCORE] : 1.0\n",
      "[579/1000]\n",
      "- [TRAIN] LOSS : 9.1187502645577e-05 [SCORE] : 0.6\n",
      "[579/1000]\n",
      "- [VAL] LOSS : 0.0001234719529747963 [SCORE] : 1.0\n",
      "[580/1000]\n",
      "- [TRAIN] LOSS : 9.064621651001895e-05 [SCORE] : 0.6\n",
      "[580/1000]\n",
      "- [VAL] LOSS : 0.00012273005268070847 [SCORE] : 1.0\n",
      "[581/1000]\n",
      "- [TRAIN] LOSS : 9.011059494999548e-05 [SCORE] : 0.6\n",
      "[581/1000]\n",
      "- [VAL] LOSS : 0.00012199445336591452 [SCORE] : 1.0\n",
      "[582/1000]\n",
      "- [TRAIN] LOSS : 8.957673635450192e-05 [SCORE] : 0.6\n",
      "[582/1000]\n",
      "- [VAL] LOSS : 0.00012126120418542996 [SCORE] : 1.0\n",
      "[583/1000]\n",
      "- [TRAIN] LOSS : 8.904642794126024e-05 [SCORE] : 0.6\n",
      "[583/1000]\n",
      "- [VAL] LOSS : 0.00012052594684064388 [SCORE] : 1.0\n",
      "[584/1000]\n",
      "- [TRAIN] LOSS : 8.852075285782727e-05 [SCORE] : 0.6\n",
      "[584/1000]\n",
      "- [VAL] LOSS : 0.00011980180715909228 [SCORE] : 1.0\n",
      "[585/1000]\n",
      "- [TRAIN] LOSS : 8.799758846483504e-05 [SCORE] : 0.6\n",
      "[585/1000]\n",
      "- [VAL] LOSS : 0.00011909216118510813 [SCORE] : 1.0\n",
      "[586/1000]\n",
      "- [TRAIN] LOSS : 8.74766546379154e-05 [SCORE] : 0.6\n",
      "[586/1000]\n",
      "- [VAL] LOSS : 0.00011837622878374532 [SCORE] : 1.0\n",
      "[587/1000]\n",
      "- [TRAIN] LOSS : 8.69643112916189e-05 [SCORE] : 0.6\n",
      "[587/1000]\n",
      "- [VAL] LOSS : 0.00011765892122639343 [SCORE] : 1.0\n",
      "[588/1000]\n",
      "- [TRAIN] LOSS : 8.645020546585632e-05 [SCORE] : 0.6\n",
      "[588/1000]\n",
      "- [VAL] LOSS : 0.0001169651368400082 [SCORE] : 1.0\n",
      "[589/1000]\n",
      "- [TRAIN] LOSS : 8.594257427224269e-05 [SCORE] : 0.6\n",
      "[589/1000]\n",
      "- [VAL] LOSS : 0.00011625631304923445 [SCORE] : 1.0\n",
      "[590/1000]\n",
      "- [TRAIN] LOSS : 8.543575580309456e-05 [SCORE] : 0.6\n",
      "[590/1000]\n",
      "- [VAL] LOSS : 0.00011556701065273955 [SCORE] : 1.0\n",
      "[591/1000]\n",
      "- [TRAIN] LOSS : 8.493139175698161e-05 [SCORE] : 0.6\n",
      "[591/1000]\n",
      "- [VAL] LOSS : 0.00011486716539366171 [SCORE] : 1.0\n",
      "[592/1000]\n",
      "- [TRAIN] LOSS : 8.443147841414126e-05 [SCORE] : 0.6\n",
      "[592/1000]\n",
      "- [VAL] LOSS : 0.00011418246140237898 [SCORE] : 1.0\n",
      "[593/1000]\n",
      "- [TRAIN] LOSS : 8.393889002036303e-05 [SCORE] : 0.6\n",
      "[593/1000]\n",
      "- [VAL] LOSS : 0.00011350434215273708 [SCORE] : 1.0\n",
      "[594/1000]\n",
      "- [TRAIN] LOSS : 8.344048910657875e-05 [SCORE] : 0.6\n",
      "[594/1000]\n",
      "- [VAL] LOSS : 0.00011282014747848734 [SCORE] : 1.0\n",
      "[595/1000]\n",
      "- [TRAIN] LOSS : 8.295407315017655e-05 [SCORE] : 0.6\n",
      "[595/1000]\n",
      "- [VAL] LOSS : 0.00011214669939363375 [SCORE] : 1.0\n",
      "[596/1000]\n",
      "- [TRAIN] LOSS : 8.246813861963649e-05 [SCORE] : 0.6\n",
      "[596/1000]\n",
      "- [VAL] LOSS : 0.00011147540499223396 [SCORE] : 1.0\n",
      "[597/1000]\n",
      "- [TRAIN] LOSS : 8.198304737258391e-05 [SCORE] : 0.6\n",
      "[597/1000]\n",
      "- [VAL] LOSS : 0.00011081522097811103 [SCORE] : 1.0\n",
      "[598/1000]\n",
      "- [TRAIN] LOSS : 8.150163800261605e-05 [SCORE] : 0.6\n",
      "[598/1000]\n",
      "- [VAL] LOSS : 0.0001101487287087366 [SCORE] : 1.0\n",
      "[599/1000]\n",
      "- [TRAIN] LOSS : 8.102706075684789e-05 [SCORE] : 0.6\n",
      "[599/1000]\n",
      "- [VAL] LOSS : 0.00010949285933747888 [SCORE] : 1.0\n",
      "[600/1000]\n",
      "- [TRAIN] LOSS : 8.05513009254355e-05 [SCORE] : 0.6\n",
      "[600/1000]\n",
      "- [VAL] LOSS : 0.0001088438366423361 [SCORE] : 1.0\n",
      "[601/1000]\n",
      "- [TRAIN] LOSS : 8.008158110897056e-05 [SCORE] : 0.6\n",
      "[601/1000]\n",
      "- [VAL] LOSS : 0.00010819674207596108 [SCORE] : 1.0\n",
      "[602/1000]\n",
      "- [TRAIN] LOSS : 7.961264491314068e-05 [SCORE] : 0.6\n",
      "[602/1000]\n",
      "- [VAL] LOSS : 0.00010755000403150916 [SCORE] : 1.0\n",
      "[603/1000]\n",
      "- [TRAIN] LOSS : 7.914731662215976e-05 [SCORE] : 0.6\n",
      "[603/1000]\n",
      "- [VAL] LOSS : 0.00010690738417906687 [SCORE] : 1.0\n",
      "[604/1000]\n",
      "- [TRAIN] LOSS : 7.868317576746146e-05 [SCORE] : 0.6\n",
      "[604/1000]\n",
      "- [VAL] LOSS : 0.00010627583105815575 [SCORE] : 1.0\n",
      "[605/1000]\n",
      "- [TRAIN] LOSS : 7.822626430424862e-05 [SCORE] : 0.6\n",
      "[605/1000]\n",
      "- [VAL] LOSS : 0.0001056464170687832 [SCORE] : 1.0\n",
      "[606/1000]\n",
      "- [TRAIN] LOSS : 7.77717177697923e-05 [SCORE] : 0.6\n",
      "[606/1000]\n",
      "- [VAL] LOSS : 0.0001050189821398817 [SCORE] : 1.0\n",
      "[607/1000]\n",
      "- [TRAIN] LOSS : 7.731592704658396e-05 [SCORE] : 0.6\n",
      "[607/1000]\n",
      "- [VAL] LOSS : 0.00010438544995849952 [SCORE] : 1.0\n",
      "[608/1000]\n",
      "- [TRAIN] LOSS : 7.686533111458023e-05 [SCORE] : 0.6\n",
      "[608/1000]\n",
      "- [VAL] LOSS : 0.00010376693535363302 [SCORE] : 1.0\n",
      "[609/1000]\n",
      "- [TRAIN] LOSS : 7.642142869978367e-05 [SCORE] : 0.6\n",
      "[609/1000]\n",
      "- [VAL] LOSS : 0.00010315911640645936 [SCORE] : 1.0\n",
      "[610/1000]\n",
      "- [TRAIN] LOSS : 7.597435990949938e-05 [SCORE] : 0.6\n",
      "[610/1000]\n",
      "- [VAL] LOSS : 0.00010254048538627103 [SCORE] : 1.0\n",
      "[611/1000]\n",
      "- [TRAIN] LOSS : 7.553507469613882e-05 [SCORE] : 0.6\n",
      "[611/1000]\n",
      "- [VAL] LOSS : 0.00010193687921855599 [SCORE] : 1.0\n",
      "[612/1000]\n",
      "- [TRAIN] LOSS : 7.509542034919528e-05 [SCORE] : 0.6\n",
      "[612/1000]\n",
      "- [VAL] LOSS : 0.00010132738680113107 [SCORE] : 1.0\n",
      "[613/1000]\n",
      "- [TRAIN] LOSS : 7.465818101384988e-05 [SCORE] : 0.6\n",
      "[613/1000]\n",
      "- [VAL] LOSS : 0.00010073645535157993 [SCORE] : 1.0\n",
      "[614/1000]\n",
      "- [TRAIN] LOSS : 7.422390723756204e-05 [SCORE] : 0.6\n",
      "[614/1000]\n",
      "- [VAL] LOSS : 0.0001001305427053012 [SCORE] : 1.0\n",
      "[615/1000]\n",
      "- [TRAIN] LOSS : 7.379496564681176e-05 [SCORE] : 0.6\n",
      "[615/1000]\n",
      "- [VAL] LOSS : 9.954401321010664e-05 [SCORE] : 1.0\n",
      "[616/1000]\n",
      "- [TRAIN] LOSS : 7.336370181292296e-05 [SCORE] : 0.6\n",
      "[616/1000]\n",
      "- [VAL] LOSS : 9.895516268443316e-05 [SCORE] : 1.0\n",
      "[617/1000]\n",
      "- [TRAIN] LOSS : 7.293974340427667e-05 [SCORE] : 0.6\n",
      "[617/1000]\n",
      "- [VAL] LOSS : 9.836407116381451e-05 [SCORE] : 1.0\n",
      "[618/1000]\n",
      "- [TRAIN] LOSS : 7.25168560165912e-05 [SCORE] : 0.6\n",
      "[618/1000]\n",
      "- [VAL] LOSS : 9.778769890544936e-05 [SCORE] : 1.0\n",
      "[619/1000]\n",
      "- [TRAIN] LOSS : 7.20997365230384e-05 [SCORE] : 0.6\n",
      "[619/1000]\n",
      "- [VAL] LOSS : 9.720941307023168e-05 [SCORE] : 1.0\n",
      "[620/1000]\n",
      "- [TRAIN] LOSS : 7.167980838858057e-05 [SCORE] : 0.6\n",
      "[620/1000]\n",
      "- [VAL] LOSS : 9.66372390394099e-05 [SCORE] : 1.0\n",
      "[621/1000]\n",
      "- [TRAIN] LOSS : 7.126722436320657e-05 [SCORE] : 0.6\n",
      "[621/1000]\n",
      "- [VAL] LOSS : 9.607127140043303e-05 [SCORE] : 1.0\n",
      "[622/1000]\n",
      "- [TRAIN] LOSS : 7.08536070305854e-05 [SCORE] : 0.6\n",
      "[622/1000]\n",
      "- [VAL] LOSS : 9.550300455885008e-05 [SCORE] : 1.0\n",
      "[623/1000]\n",
      "- [TRAIN] LOSS : 7.044341837172396e-05 [SCORE] : 0.6\n",
      "[623/1000]\n",
      "- [VAL] LOSS : 9.493699326412752e-05 [SCORE] : 1.0\n",
      "[624/1000]\n",
      "- [TRAIN] LOSS : 7.003784400391547e-05 [SCORE] : 0.6\n",
      "[624/1000]\n",
      "- [VAL] LOSS : 9.436862455913797e-05 [SCORE] : 1.0\n",
      "[625/1000]\n",
      "- [TRAIN] LOSS : 6.962979896343313e-05 [SCORE] : 0.6\n",
      "[625/1000]\n",
      "- [VAL] LOSS : 9.383116412209347e-05 [SCORE] : 1.0\n",
      "[626/1000]\n",
      "- [TRAIN] LOSS : 6.922475343647723e-05 [SCORE] : 0.6\n",
      "[626/1000]\n",
      "- [VAL] LOSS : 9.331346518592909e-05 [SCORE] : 1.0\n",
      "[627/1000]\n",
      "- [TRAIN] LOSS : 6.882700848412545e-05 [SCORE] : 0.6\n",
      "[627/1000]\n",
      "- [VAL] LOSS : 9.277914796257392e-05 [SCORE] : 1.0\n",
      "[628/1000]\n",
      "- [TRAIN] LOSS : 6.843016502292207e-05 [SCORE] : 0.6\n",
      "[628/1000]\n",
      "- [VAL] LOSS : 9.225350368069485e-05 [SCORE] : 1.0\n",
      "[629/1000]\n",
      "- [TRAIN] LOSS : 6.803859032515902e-05 [SCORE] : 0.6\n",
      "[629/1000]\n",
      "- [VAL] LOSS : 9.173074795398861e-05 [SCORE] : 1.0\n",
      "[630/1000]\n",
      "- [TRAIN] LOSS : 6.764858990209177e-05 [SCORE] : 0.6\n",
      "[630/1000]\n",
      "- [VAL] LOSS : 9.121494804276153e-05 [SCORE] : 1.0\n",
      "[631/1000]\n",
      "- [TRAIN] LOSS : 6.726831949587601e-05 [SCORE] : 0.6\n",
      "[631/1000]\n",
      "- [VAL] LOSS : 9.068204235518351e-05 [SCORE] : 1.0\n",
      "[632/1000]\n",
      "- [TRAIN] LOSS : 6.687876108723382e-05 [SCORE] : 0.6\n",
      "[632/1000]\n",
      "- [VAL] LOSS : 9.015792602440342e-05 [SCORE] : 1.0\n",
      "[633/1000]\n",
      "- [TRAIN] LOSS : 6.649337095344284e-05 [SCORE] : 0.6\n",
      "[633/1000]\n",
      "- [VAL] LOSS : 8.96430792636238e-05 [SCORE] : 1.0\n",
      "[634/1000]\n",
      "- [TRAIN] LOSS : 6.611379370345579e-05 [SCORE] : 0.6\n",
      "[634/1000]\n",
      "- [VAL] LOSS : 8.912698103813455e-05 [SCORE] : 1.0\n",
      "[635/1000]\n",
      "- [TRAIN] LOSS : 6.573499643612498e-05 [SCORE] : 0.6\n",
      "[635/1000]\n",
      "- [VAL] LOSS : 8.862427057465538e-05 [SCORE] : 1.0\n",
      "[636/1000]\n",
      "- [TRAIN] LOSS : 6.535779818174584e-05 [SCORE] : 0.6\n",
      "[636/1000]\n",
      "- [VAL] LOSS : 8.812138548819348e-05 [SCORE] : 1.0\n",
      "[637/1000]\n",
      "- [TRAIN] LOSS : 6.49871503507408e-05 [SCORE] : 0.6\n",
      "[637/1000]\n",
      "- [VAL] LOSS : 8.761799108469859e-05 [SCORE] : 1.0\n",
      "[638/1000]\n",
      "- [TRAIN] LOSS : 6.46140940564995e-05 [SCORE] : 0.6\n",
      "[638/1000]\n",
      "- [VAL] LOSS : 8.710991824045777e-05 [SCORE] : 1.0\n",
      "[639/1000]\n",
      "- [TRAIN] LOSS : 6.424629452036848e-05 [SCORE] : 0.6\n",
      "[639/1000]\n",
      "- [VAL] LOSS : 8.661016909172758e-05 [SCORE] : 1.0\n",
      "[640/1000]\n",
      "- [TRAIN] LOSS : 6.38811026874464e-05 [SCORE] : 0.6\n",
      "[640/1000]\n",
      "- [VAL] LOSS : 8.611894736532122e-05 [SCORE] : 1.0\n",
      "[641/1000]\n",
      "- [TRAIN] LOSS : 6.351581020377731e-05 [SCORE] : 0.6\n",
      "[641/1000]\n",
      "- [VAL] LOSS : 8.562776201870292e-05 [SCORE] : 1.0\n",
      "[642/1000]\n",
      "- [TRAIN] LOSS : 6.315523763381256e-05 [SCORE] : 0.6\n",
      "[642/1000]\n",
      "- [VAL] LOSS : 8.51367149152793e-05 [SCORE] : 1.0\n",
      "[643/1000]\n",
      "- [TRAIN] LOSS : 6.279663660582932e-05 [SCORE] : 0.6\n",
      "[643/1000]\n",
      "- [VAL] LOSS : 8.465027349302545e-05 [SCORE] : 1.0\n",
      "[644/1000]\n",
      "- [TRAIN] LOSS : 6.243525191772885e-05 [SCORE] : 0.6\n",
      "[644/1000]\n",
      "- [VAL] LOSS : 8.416413038503379e-05 [SCORE] : 1.0\n",
      "[645/1000]\n",
      "- [TRAIN] LOSS : 6.208225992547038e-05 [SCORE] : 0.6\n",
      "[645/1000]\n",
      "- [VAL] LOSS : 8.368051203433424e-05 [SCORE] : 1.0\n",
      "[646/1000]\n",
      "- [TRAIN] LOSS : 6.172831162984949e-05 [SCORE] : 0.6\n",
      "[646/1000]\n",
      "- [VAL] LOSS : 8.32040750537999e-05 [SCORE] : 1.0\n",
      "[647/1000]\n",
      "- [TRAIN] LOSS : 6.137893590979123e-05 [SCORE] : 0.6\n",
      "[647/1000]\n",
      "- [VAL] LOSS : 8.272189734270796e-05 [SCORE] : 1.0\n",
      "[648/1000]\n",
      "- [TRAIN] LOSS : 6.1027545355803645e-05 [SCORE] : 0.6\n",
      "[648/1000]\n",
      "- [VAL] LOSS : 8.224701741710305e-05 [SCORE] : 1.0\n",
      "[649/1000]\n",
      "- [TRAIN] LOSS : 6.0685930657200514e-05 [SCORE] : 0.6\n",
      "[649/1000]\n",
      "- [VAL] LOSS : 8.178131975000724e-05 [SCORE] : 1.0\n",
      "[650/1000]\n",
      "- [TRAIN] LOSS : 6.03382601790751e-05 [SCORE] : 0.6\n",
      "[650/1000]\n",
      "- [VAL] LOSS : 8.13167353044264e-05 [SCORE] : 1.0\n",
      "[651/1000]\n",
      "- [TRAIN] LOSS : 5.9997352824818036e-05 [SCORE] : 0.6\n",
      "[651/1000]\n",
      "- [VAL] LOSS : 8.08486802270636e-05 [SCORE] : 1.0\n",
      "[652/1000]\n",
      "- [TRAIN] LOSS : 5.965725843755839e-05 [SCORE] : 0.6\n",
      "[652/1000]\n",
      "- [VAL] LOSS : 8.037756924750283e-05 [SCORE] : 1.0\n",
      "[653/1000]\n",
      "- [TRAIN] LOSS : 5.9317981625402655e-05 [SCORE] : 0.6\n",
      "[653/1000]\n",
      "- [VAL] LOSS : 7.991182064870372e-05 [SCORE] : 1.0\n",
      "[654/1000]\n",
      "- [TRAIN] LOSS : 5.898317516160508e-05 [SCORE] : 0.6\n",
      "[654/1000]\n",
      "- [VAL] LOSS : 7.945985271362588e-05 [SCORE] : 1.0\n",
      "[655/1000]\n",
      "- [TRAIN] LOSS : 5.864958293386735e-05 [SCORE] : 0.6\n",
      "[655/1000]\n",
      "- [VAL] LOSS : 7.899631600594148e-05 [SCORE] : 1.0\n",
      "[656/1000]\n",
      "- [TRAIN] LOSS : 5.831890860766483e-05 [SCORE] : 0.6\n",
      "[656/1000]\n",
      "- [VAL] LOSS : 7.85469455877319e-05 [SCORE] : 1.0\n",
      "[657/1000]\n",
      "- [TRAIN] LOSS : 5.798761606759702e-05 [SCORE] : 0.6\n",
      "[657/1000]\n",
      "- [VAL] LOSS : 7.809019007254392e-05 [SCORE] : 1.0\n",
      "[658/1000]\n",
      "- [TRAIN] LOSS : 5.765998818484756e-05 [SCORE] : 0.6\n",
      "[658/1000]\n",
      "- [VAL] LOSS : 7.765168993500993e-05 [SCORE] : 1.0\n",
      "[659/1000]\n",
      "- [TRAIN] LOSS : 5.733604484703392e-05 [SCORE] : 0.6\n",
      "[659/1000]\n",
      "- [VAL] LOSS : 7.718888809904456e-05 [SCORE] : 1.0\n",
      "[660/1000]\n",
      "- [TRAIN] LOSS : 5.701027136334839e-05 [SCORE] : 0.6\n",
      "[660/1000]\n",
      "- [VAL] LOSS : 7.674861262785271e-05 [SCORE] : 1.0\n",
      "[661/1000]\n",
      "- [TRAIN] LOSS : 5.668731488791915e-05 [SCORE] : 0.6\n",
      "[661/1000]\n",
      "- [VAL] LOSS : 7.631808693986386e-05 [SCORE] : 1.0\n",
      "[662/1000]\n",
      "- [TRAIN] LOSS : 5.6366907180442165e-05 [SCORE] : 0.6\n",
      "[662/1000]\n",
      "- [VAL] LOSS : 7.588028529426083e-05 [SCORE] : 1.0\n",
      "[663/1000]\n",
      "- [TRAIN] LOSS : 5.6051431844631834e-05 [SCORE] : 0.6\n",
      "[663/1000]\n",
      "- [VAL] LOSS : 7.543952960986644e-05 [SCORE] : 1.0\n",
      "[664/1000]\n",
      "- [TRAIN] LOSS : 5.573410453507677e-05 [SCORE] : 0.6\n",
      "[664/1000]\n",
      "- [VAL] LOSS : 7.500876381527632e-05 [SCORE] : 1.0\n",
      "[665/1000]\n",
      "- [TRAIN] LOSS : 5.5420588372120015e-05 [SCORE] : 0.6\n",
      "[665/1000]\n",
      "- [VAL] LOSS : 7.457931496901438e-05 [SCORE] : 1.0\n",
      "[666/1000]\n",
      "- [TRAIN] LOSS : 5.510757085479175e-05 [SCORE] : 0.6\n",
      "[666/1000]\n",
      "- [VAL] LOSS : 7.414699211949483e-05 [SCORE] : 1.0\n",
      "[667/1000]\n",
      "- [TRAIN] LOSS : 5.479800687074506e-05 [SCORE] : 0.6\n",
      "[667/1000]\n",
      "- [VAL] LOSS : 7.371618266915902e-05 [SCORE] : 1.0\n",
      "[668/1000]\n",
      "- [TRAIN] LOSS : 5.44905903855882e-05 [SCORE] : 0.6\n",
      "[668/1000]\n",
      "- [VAL] LOSS : 7.330348307732493e-05 [SCORE] : 1.0\n",
      "[669/1000]\n",
      "- [TRAIN] LOSS : 5.418363070930354e-05 [SCORE] : 0.6\n",
      "[669/1000]\n",
      "- [VAL] LOSS : 7.28751765564084e-05 [SCORE] : 1.0\n",
      "[670/1000]\n",
      "- [TRAIN] LOSS : 5.387921798198173e-05 [SCORE] : 0.6\n",
      "[670/1000]\n",
      "- [VAL] LOSS : 7.246958557516336e-05 [SCORE] : 1.0\n",
      "[671/1000]\n",
      "- [TRAIN] LOSS : 5.35750608833041e-05 [SCORE] : 0.6\n",
      "[671/1000]\n",
      "- [VAL] LOSS : 7.205263682408258e-05 [SCORE] : 1.0\n",
      "[672/1000]\n",
      "- [TRAIN] LOSS : 5.327536891854834e-05 [SCORE] : 0.6\n",
      "[672/1000]\n",
      "- [VAL] LOSS : 7.163680129451677e-05 [SCORE] : 1.0\n",
      "[673/1000]\n",
      "- [TRAIN] LOSS : 5.2977052352313576e-05 [SCORE] : 0.6\n",
      "[673/1000]\n",
      "- [VAL] LOSS : 7.122683746274561e-05 [SCORE] : 1.0\n",
      "[674/1000]\n",
      "- [TRAIN] LOSS : 5.267571080670071e-05 [SCORE] : 0.6\n",
      "[674/1000]\n",
      "- [VAL] LOSS : 7.08094667061232e-05 [SCORE] : 1.0\n",
      "[675/1000]\n",
      "- [TRAIN] LOSS : 5.238281361622891e-05 [SCORE] : 0.6\n",
      "[675/1000]\n",
      "- [VAL] LOSS : 7.040642231004313e-05 [SCORE] : 1.0\n",
      "[676/1000]\n",
      "- [TRAIN] LOSS : 5.208812253840733e-05 [SCORE] : 0.6\n",
      "[676/1000]\n",
      "- [VAL] LOSS : 7.001317862886935e-05 [SCORE] : 1.0\n",
      "[677/1000]\n",
      "- [TRAIN] LOSS : 5.1795153073423235e-05 [SCORE] : 0.6\n",
      "[677/1000]\n",
      "- [VAL] LOSS : 6.961271719774231e-05 [SCORE] : 1.0\n",
      "[678/1000]\n",
      "- [TRAIN] LOSS : 5.150506694917567e-05 [SCORE] : 0.6\n",
      "[678/1000]\n",
      "- [VAL] LOSS : 6.92133980919607e-05 [SCORE] : 1.0\n",
      "[679/1000]\n",
      "- [TRAIN] LOSS : 5.121744519177203e-05 [SCORE] : 0.6\n",
      "[679/1000]\n",
      "- [VAL] LOSS : 6.881555600557476e-05 [SCORE] : 1.0\n",
      "[680/1000]\n",
      "- [TRAIN] LOSS : 5.093117736881444e-05 [SCORE] : 0.6\n",
      "[680/1000]\n",
      "- [VAL] LOSS : 6.841476715635508e-05 [SCORE] : 1.0\n",
      "[681/1000]\n",
      "- [TRAIN] LOSS : 5.0642697412210204e-05 [SCORE] : 0.6\n",
      "[681/1000]\n",
      "- [VAL] LOSS : 6.802814459661022e-05 [SCORE] : 1.0\n",
      "[682/1000]\n",
      "- [TRAIN] LOSS : 5.036183429183438e-05 [SCORE] : 0.6\n",
      "[682/1000]\n",
      "- [VAL] LOSS : 6.764718273188919e-05 [SCORE] : 1.0\n",
      "[683/1000]\n",
      "- [TRAIN] LOSS : 5.008072924586789e-05 [SCORE] : 0.6\n",
      "[683/1000]\n",
      "- [VAL] LOSS : 6.725459388690069e-05 [SCORE] : 1.0\n",
      "[684/1000]\n",
      "- [TRAIN] LOSS : 4.9801349814515564e-05 [SCORE] : 0.6\n",
      "[684/1000]\n",
      "- [VAL] LOSS : 6.687201675958931e-05 [SCORE] : 1.0\n",
      "[685/1000]\n",
      "- [TRAIN] LOSS : 4.95204962741506e-05 [SCORE] : 0.6\n",
      "[685/1000]\n",
      "- [VAL] LOSS : 6.649077840847895e-05 [SCORE] : 1.0\n",
      "[686/1000]\n",
      "- [TRAIN] LOSS : 4.924534490176787e-05 [SCORE] : 0.6\n",
      "[686/1000]\n",
      "- [VAL] LOSS : 6.61064259475097e-05 [SCORE] : 1.0\n",
      "[687/1000]\n",
      "- [TRAIN] LOSS : 4.89690219789433e-05 [SCORE] : 0.6\n",
      "[687/1000]\n",
      "- [VAL] LOSS : 6.573180144187063e-05 [SCORE] : 1.0\n",
      "[688/1000]\n",
      "- [TRAIN] LOSS : 4.869750300713349e-05 [SCORE] : 0.6\n",
      "[688/1000]\n",
      "- [VAL] LOSS : 6.534997373819351e-05 [SCORE] : 1.0\n",
      "[689/1000]\n",
      "- [TRAIN] LOSS : 4.8426521243527534e-05 [SCORE] : 0.6\n",
      "[689/1000]\n",
      "- [VAL] LOSS : 6.498248694697395e-05 [SCORE] : 1.0\n",
      "[690/1000]\n",
      "- [TRAIN] LOSS : 4.8154166870517655e-05 [SCORE] : 0.6\n",
      "[690/1000]\n",
      "- [VAL] LOSS : 6.461620796471834e-05 [SCORE] : 1.0\n",
      "[691/1000]\n",
      "- [TRAIN] LOSS : 4.7887840385859214e-05 [SCORE] : 0.6\n",
      "[691/1000]\n",
      "- [VAL] LOSS : 6.424706225516275e-05 [SCORE] : 1.0\n",
      "[692/1000]\n",
      "- [TRAIN] LOSS : 4.762076678161975e-05 [SCORE] : 0.6\n",
      "[692/1000]\n",
      "- [VAL] LOSS : 6.388749170582741e-05 [SCORE] : 1.0\n",
      "[693/1000]\n",
      "- [TRAIN] LOSS : 4.7354111302411184e-05 [SCORE] : 0.6\n",
      "[693/1000]\n",
      "- [VAL] LOSS : 6.350780313368887e-05 [SCORE] : 1.0\n",
      "[694/1000]\n",
      "- [TRAIN] LOSS : 4.708747267917109e-05 [SCORE] : 0.6\n",
      "[694/1000]\n",
      "- [VAL] LOSS : 6.315491918940097e-05 [SCORE] : 1.0\n",
      "[695/1000]\n",
      "- [TRAIN] LOSS : 4.6829662460368125e-05 [SCORE] : 0.6\n",
      "[695/1000]\n",
      "- [VAL] LOSS : 6.27947665634565e-05 [SCORE] : 1.0\n",
      "[696/1000]\n",
      "- [TRAIN] LOSS : 4.6566717598276836e-05 [SCORE] : 0.6\n",
      "[696/1000]\n",
      "- [VAL] LOSS : 6.243585812626407e-05 [SCORE] : 1.0\n",
      "[697/1000]\n",
      "- [TRAIN] LOSS : 4.630929870472755e-05 [SCORE] : 0.6\n",
      "[697/1000]\n",
      "- [VAL] LOSS : 6.207371188793331e-05 [SCORE] : 1.0\n",
      "[698/1000]\n",
      "- [TRAIN] LOSS : 4.6052717152633704e-05 [SCORE] : 0.6\n",
      "[698/1000]\n",
      "- [VAL] LOSS : 6.173430301714689e-05 [SCORE] : 1.0\n",
      "[699/1000]\n",
      "- [TRAIN] LOSS : 4.579627675411757e-05 [SCORE] : 0.6\n",
      "[699/1000]\n",
      "- [VAL] LOSS : 6.137922900961712e-05 [SCORE] : 1.0\n",
      "[700/1000]\n",
      "- [TRAIN] LOSS : 4.5541878110573936e-05 [SCORE] : 0.6\n",
      "[700/1000]\n",
      "- [VAL] LOSS : 6.102963016019203e-05 [SCORE] : 1.0\n",
      "[701/1000]\n",
      "- [TRAIN] LOSS : 4.528956233116332e-05 [SCORE] : 0.6\n",
      "[701/1000]\n",
      "- [VAL] LOSS : 6.068969378247857e-05 [SCORE] : 1.0\n",
      "[702/1000]\n",
      "- [TRAIN] LOSS : 4.5035965740680695e-05 [SCORE] : 0.6\n",
      "[702/1000]\n",
      "- [VAL] LOSS : 6.034661419107579e-05 [SCORE] : 1.0\n",
      "[703/1000]\n",
      "- [TRAIN] LOSS : 4.4787565214695255e-05 [SCORE] : 0.6\n",
      "[703/1000]\n",
      "- [VAL] LOSS : 5.998758570058271e-05 [SCORE] : 1.0\n",
      "[704/1000]\n",
      "- [TRAIN] LOSS : 4.4539122609421614e-05 [SCORE] : 0.6\n",
      "[704/1000]\n",
      "- [VAL] LOSS : 5.9646812587743625e-05 [SCORE] : 1.0\n",
      "[705/1000]\n",
      "- [TRAIN] LOSS : 4.4287887916046506e-05 [SCORE] : 0.6\n",
      "[705/1000]\n",
      "- [VAL] LOSS : 5.931568375672214e-05 [SCORE] : 1.0\n",
      "[706/1000]\n",
      "- [TRAIN] LOSS : 4.404419123602565e-05 [SCORE] : 0.6\n",
      "[706/1000]\n",
      "- [VAL] LOSS : 5.8977257140213624e-05 [SCORE] : 1.0\n",
      "[707/1000]\n",
      "- [TRAIN] LOSS : 4.3799721788673195e-05 [SCORE] : 0.6\n",
      "[707/1000]\n",
      "- [VAL] LOSS : 5.8644414821173996e-05 [SCORE] : 1.0\n",
      "[708/1000]\n",
      "- [TRAIN] LOSS : 4.35601063145441e-05 [SCORE] : 0.6\n",
      "[708/1000]\n",
      "- [VAL] LOSS : 5.831683665746823e-05 [SCORE] : 1.0\n",
      "[709/1000]\n",
      "- [TRAIN] LOSS : 4.3317239881920004e-05 [SCORE] : 0.6\n",
      "[709/1000]\n",
      "- [VAL] LOSS : 5.797338599222712e-05 [SCORE] : 1.0\n",
      "[710/1000]\n",
      "- [TRAIN] LOSS : 4.3078269118268506e-05 [SCORE] : 0.6\n",
      "[710/1000]\n",
      "- [VAL] LOSS : 5.766074900748208e-05 [SCORE] : 1.0\n",
      "[711/1000]\n",
      "- [TRAIN] LOSS : 4.283882129432944e-05 [SCORE] : 0.6\n",
      "[711/1000]\n",
      "- [VAL] LOSS : 5.733221041737124e-05 [SCORE] : 1.0\n",
      "[712/1000]\n",
      "- [TRAIN] LOSS : 4.260453703561022e-05 [SCORE] : 0.6\n",
      "[712/1000]\n",
      "- [VAL] LOSS : 5.699647226720117e-05 [SCORE] : 1.0\n",
      "[713/1000]\n",
      "- [TRAIN] LOSS : 4.2367563946754674e-05 [SCORE] : 0.6\n",
      "[713/1000]\n",
      "- [VAL] LOSS : 5.6683329603401944e-05 [SCORE] : 1.0\n",
      "[714/1000]\n",
      "- [TRAIN] LOSS : 4.213454631099012e-05 [SCORE] : 0.6\n",
      "[714/1000]\n",
      "- [VAL] LOSS : 5.6358370784437284e-05 [SCORE] : 1.0\n",
      "[715/1000]\n",
      "- [TRAIN] LOSS : 4.1901000804500656e-05 [SCORE] : 0.6\n",
      "[715/1000]\n",
      "- [VAL] LOSS : 5.6038777984213084e-05 [SCORE] : 1.0\n",
      "[716/1000]\n",
      "- [TRAIN] LOSS : 4.1669392097295106e-05 [SCORE] : 0.6\n",
      "[716/1000]\n",
      "- [VAL] LOSS : 5.572009467869066e-05 [SCORE] : 1.0\n",
      "[717/1000]\n",
      "- [TRAIN] LOSS : 4.144048495315171e-05 [SCORE] : 0.6\n",
      "[717/1000]\n",
      "- [VAL] LOSS : 5.540697384276427e-05 [SCORE] : 1.0\n",
      "[718/1000]\n",
      "- [TRAIN] LOSS : 4.12087514026401e-05 [SCORE] : 0.6\n",
      "[718/1000]\n",
      "- [VAL] LOSS : 5.5094809795264155e-05 [SCORE] : 1.0\n",
      "[719/1000]\n",
      "- [TRAIN] LOSS : 4.0984883404841337e-05 [SCORE] : 0.6\n",
      "[719/1000]\n",
      "- [VAL] LOSS : 5.4788011766504496e-05 [SCORE] : 1.0\n",
      "[720/1000]\n",
      "- [TRAIN] LOSS : 4.075458527950104e-05 [SCORE] : 0.6\n",
      "[720/1000]\n",
      "- [VAL] LOSS : 5.44738068128936e-05 [SCORE] : 1.0\n",
      "[721/1000]\n",
      "- [TRAIN] LOSS : 4.053334353860312e-05 [SCORE] : 0.6\n",
      "[721/1000]\n",
      "- [VAL] LOSS : 5.416063140728511e-05 [SCORE] : 1.0\n",
      "[722/1000]\n",
      "- [TRAIN] LOSS : 4.030962506173334e-05 [SCORE] : 0.6\n",
      "[722/1000]\n",
      "- [VAL] LOSS : 5.385688928072341e-05 [SCORE] : 1.0\n",
      "[723/1000]\n",
      "- [TRAIN] LOSS : 4.00870076797825e-05 [SCORE] : 0.6\n",
      "[723/1000]\n",
      "- [VAL] LOSS : 5.3554376790998504e-05 [SCORE] : 1.0\n",
      "[724/1000]\n",
      "- [TRAIN] LOSS : 3.986551989025126e-05 [SCORE] : 0.6\n",
      "[724/1000]\n",
      "- [VAL] LOSS : 5.325725578586571e-05 [SCORE] : 1.0\n",
      "[725/1000]\n",
      "- [TRAIN] LOSS : 3.964832849305822e-05 [SCORE] : 0.6\n",
      "[725/1000]\n",
      "- [VAL] LOSS : 5.2948340453440323e-05 [SCORE] : 1.0\n",
      "[726/1000]\n",
      "- [TRAIN] LOSS : 3.942783829794886e-05 [SCORE] : 0.6\n",
      "[726/1000]\n",
      "- [VAL] LOSS : 5.2657480409834534e-05 [SCORE] : 1.0\n",
      "[727/1000]\n",
      "- [TRAIN] LOSS : 3.921401160672152e-05 [SCORE] : 0.6\n",
      "[727/1000]\n",
      "- [VAL] LOSS : 5.235913340584375e-05 [SCORE] : 1.0\n",
      "[728/1000]\n",
      "- [TRAIN] LOSS : 3.899691061330183e-05 [SCORE] : 0.6\n",
      "[728/1000]\n",
      "- [VAL] LOSS : 5.206179412198253e-05 [SCORE] : 1.0\n",
      "[729/1000]\n",
      "- [TRAIN] LOSS : 3.87800827108246e-05 [SCORE] : 0.6\n",
      "[729/1000]\n",
      "- [VAL] LOSS : 5.176545164431445e-05 [SCORE] : 1.0\n",
      "[730/1000]\n",
      "- [TRAIN] LOSS : 3.856785018191052e-05 [SCORE] : 0.6\n",
      "[730/1000]\n",
      "- [VAL] LOSS : 5.147421688889153e-05 [SCORE] : 1.0\n",
      "[731/1000]\n",
      "- [TRAIN] LOSS : 3.83590230436918e-05 [SCORE] : 0.6\n",
      "[731/1000]\n",
      "- [VAL] LOSS : 5.1184091717004776e-05 [SCORE] : 1.0\n",
      "[732/1000]\n",
      "- [TRAIN] LOSS : 3.8144941936479884e-05 [SCORE] : 0.6\n",
      "[732/1000]\n",
      "- [VAL] LOSS : 5.089933256385848e-05 [SCORE] : 1.0\n",
      "[733/1000]\n",
      "- [TRAIN] LOSS : 3.7936756113291875e-05 [SCORE] : 0.6\n",
      "[733/1000]\n",
      "- [VAL] LOSS : 5.061126284999773e-05 [SCORE] : 1.0\n",
      "[734/1000]\n",
      "- [TRAIN] LOSS : 3.773079655123486e-05 [SCORE] : 0.6\n",
      "[734/1000]\n",
      "- [VAL] LOSS : 5.032854824094102e-05 [SCORE] : 1.0\n",
      "[735/1000]\n",
      "- [TRAIN] LOSS : 3.7523163761458515e-05 [SCORE] : 0.6\n",
      "[735/1000]\n",
      "- [VAL] LOSS : 5.005123239243403e-05 [SCORE] : 1.0\n",
      "[736/1000]\n",
      "- [TRAIN] LOSS : 3.731430018281874e-05 [SCORE] : 0.6\n",
      "[736/1000]\n",
      "- [VAL] LOSS : 4.975784759153612e-05 [SCORE] : 1.0\n",
      "[737/1000]\n",
      "- [TRAIN] LOSS : 3.711001336341724e-05 [SCORE] : 0.6\n",
      "[737/1000]\n",
      "- [VAL] LOSS : 4.9482390750199556e-05 [SCORE] : 1.0\n",
      "[738/1000]\n",
      "- [TRAIN] LOSS : 3.6905914809419e-05 [SCORE] : 0.6\n",
      "[738/1000]\n",
      "- [VAL] LOSS : 4.920348146697506e-05 [SCORE] : 1.0\n",
      "[739/1000]\n",
      "- [TRAIN] LOSS : 3.670518411430142e-05 [SCORE] : 0.6\n",
      "[739/1000]\n",
      "- [VAL] LOSS : 4.892554716207087e-05 [SCORE] : 1.0\n",
      "[740/1000]\n",
      "- [TRAIN] LOSS : 3.650511237841177e-05 [SCORE] : 0.6\n",
      "[740/1000]\n",
      "- [VAL] LOSS : 4.86529097543098e-05 [SCORE] : 1.0\n",
      "[741/1000]\n",
      "- [TRAIN] LOSS : 3.6303318180822924e-05 [SCORE] : 0.6\n",
      "[741/1000]\n",
      "- [VAL] LOSS : 4.8381163651356474e-05 [SCORE] : 1.0\n",
      "[742/1000]\n",
      "- [TRAIN] LOSS : 3.610409706501135e-05 [SCORE] : 0.6\n",
      "[742/1000]\n",
      "- [VAL] LOSS : 4.81125243823044e-05 [SCORE] : 1.0\n",
      "[743/1000]\n",
      "- [TRAIN] LOSS : 3.590743514602461e-05 [SCORE] : 0.6\n",
      "[743/1000]\n",
      "- [VAL] LOSS : 4.784246993949637e-05 [SCORE] : 1.0\n",
      "[744/1000]\n",
      "- [TRAIN] LOSS : 3.5712578270855984e-05 [SCORE] : 0.6\n",
      "[744/1000]\n",
      "- [VAL] LOSS : 4.756505222758278e-05 [SCORE] : 1.0\n",
      "[745/1000]\n",
      "- [TRAIN] LOSS : 3.551524399275271e-05 [SCORE] : 0.6\n",
      "[745/1000]\n",
      "- [VAL] LOSS : 4.729707870865241e-05 [SCORE] : 1.0\n",
      "[746/1000]\n",
      "- [TRAIN] LOSS : 3.532165871244312e-05 [SCORE] : 0.6\n",
      "[746/1000]\n",
      "- [VAL] LOSS : 4.704269304056652e-05 [SCORE] : 1.0\n",
      "[747/1000]\n",
      "- [TRAIN] LOSS : 3.512983506273789e-05 [SCORE] : 0.6\n",
      "[747/1000]\n",
      "- [VAL] LOSS : 4.676801836467348e-05 [SCORE] : 1.0\n",
      "[748/1000]\n",
      "- [TRAIN] LOSS : 3.493588368049435e-05 [SCORE] : 0.6\n",
      "[748/1000]\n",
      "- [VAL] LOSS : 4.651123526855372e-05 [SCORE] : 1.0\n",
      "[749/1000]\n",
      "- [TRAIN] LOSS : 3.474645915654643e-05 [SCORE] : 0.6\n",
      "[749/1000]\n",
      "- [VAL] LOSS : 4.6251079766079783e-05 [SCORE] : 1.0\n",
      "[750/1000]\n",
      "- [TRAIN] LOSS : 3.455403809008809e-05 [SCORE] : 0.6\n",
      "[750/1000]\n",
      "- [VAL] LOSS : 4.599579915520735e-05 [SCORE] : 1.0\n",
      "[751/1000]\n",
      "- [TRAIN] LOSS : 3.436725837673294e-05 [SCORE] : 0.6\n",
      "[751/1000]\n",
      "- [VAL] LOSS : 4.573728801915422e-05 [SCORE] : 1.0\n",
      "[752/1000]\n",
      "- [TRAIN] LOSS : 3.4181920455012005e-05 [SCORE] : 0.6\n",
      "[752/1000]\n",
      "- [VAL] LOSS : 4.548830111161806e-05 [SCORE] : 1.0\n",
      "[753/1000]\n",
      "- [TRAIN] LOSS : 3.3995608100667595e-05 [SCORE] : 0.6\n",
      "[753/1000]\n",
      "- [VAL] LOSS : 4.522319431998767e-05 [SCORE] : 1.0\n",
      "[754/1000]\n",
      "- [TRAIN] LOSS : 3.380835648082818e-05 [SCORE] : 0.6\n",
      "[754/1000]\n",
      "- [VAL] LOSS : 4.49633298558183e-05 [SCORE] : 1.0\n",
      "[755/1000]\n",
      "- [TRAIN] LOSS : 3.3627230368438174e-05 [SCORE] : 0.6\n",
      "[755/1000]\n",
      "- [VAL] LOSS : 4.4721349695464596e-05 [SCORE] : 1.0\n",
      "[756/1000]\n",
      "- [TRAIN] LOSS : 3.3436762169003484e-05 [SCORE] : 0.6\n",
      "[756/1000]\n",
      "- [VAL] LOSS : 4.4467367843026295e-05 [SCORE] : 1.0\n",
      "[757/1000]\n",
      "- [TRAIN] LOSS : 3.325753095850814e-05 [SCORE] : 0.6\n",
      "[757/1000]\n",
      "- [VAL] LOSS : 4.42182608821895e-05 [SCORE] : 1.0\n",
      "[758/1000]\n",
      "- [TRAIN] LOSS : 3.3076764884754085e-05 [SCORE] : 0.6\n",
      "[758/1000]\n",
      "- [VAL] LOSS : 4.397857628646307e-05 [SCORE] : 1.0\n",
      "[759/1000]\n",
      "- [TRAIN] LOSS : 3.289619950616422e-05 [SCORE] : 0.6\n",
      "[759/1000]\n",
      "- [VAL] LOSS : 4.373125921119936e-05 [SCORE] : 1.0\n",
      "[760/1000]\n",
      "- [TRAIN] LOSS : 3.27169627174347e-05 [SCORE] : 0.6\n",
      "[760/1000]\n",
      "- [VAL] LOSS : 4.3480620661284775e-05 [SCORE] : 1.0\n",
      "[761/1000]\n",
      "- [TRAIN] LOSS : 3.2539907260797916e-05 [SCORE] : 0.6\n",
      "[761/1000]\n",
      "- [VAL] LOSS : 4.323496614233591e-05 [SCORE] : 1.0\n",
      "[762/1000]\n",
      "- [TRAIN] LOSS : 3.2361801822844426e-05 [SCORE] : 0.6\n",
      "[762/1000]\n",
      "- [VAL] LOSS : 4.2994568502763286e-05 [SCORE] : 1.0\n",
      "[763/1000]\n",
      "- [TRAIN] LOSS : 3.218744859623257e-05 [SCORE] : 0.6\n",
      "[763/1000]\n",
      "- [VAL] LOSS : 4.275062747183256e-05 [SCORE] : 1.0\n",
      "[764/1000]\n",
      "- [TRAIN] LOSS : 3.2010427821660416e-05 [SCORE] : 0.6\n",
      "[764/1000]\n",
      "- [VAL] LOSS : 4.251173959346488e-05 [SCORE] : 1.0\n",
      "[765/1000]\n",
      "- [TRAIN] LOSS : 3.183591488777893e-05 [SCORE] : 0.6\n",
      "[765/1000]\n",
      "- [VAL] LOSS : 4.2277792090317234e-05 [SCORE] : 1.0\n",
      "[766/1000]\n",
      "- [TRAIN] LOSS : 3.1662270278805714e-05 [SCORE] : 0.6\n",
      "[766/1000]\n",
      "- [VAL] LOSS : 4.204466677037999e-05 [SCORE] : 1.0\n",
      "[767/1000]\n",
      "- [TRAIN] LOSS : 3.149234689772129e-05 [SCORE] : 0.6\n",
      "[767/1000]\n",
      "- [VAL] LOSS : 4.180824544164352e-05 [SCORE] : 1.0\n",
      "[768/1000]\n",
      "- [TRAIN] LOSS : 3.132222270020672e-05 [SCORE] : 0.6\n",
      "[768/1000]\n",
      "- [VAL] LOSS : 4.1581235564081e-05 [SCORE] : 1.0\n",
      "[769/1000]\n",
      "- [TRAIN] LOSS : 3.1150294065203826e-05 [SCORE] : 0.6\n",
      "[769/1000]\n",
      "- [VAL] LOSS : 4.134655318921432e-05 [SCORE] : 1.0\n",
      "[770/1000]\n",
      "- [TRAIN] LOSS : 3.098125713828874e-05 [SCORE] : 0.6\n",
      "[770/1000]\n",
      "- [VAL] LOSS : 4.110411828150973e-05 [SCORE] : 1.0\n",
      "[771/1000]\n",
      "- [TRAIN] LOSS : 3.0812730801699215e-05 [SCORE] : 0.6\n",
      "[771/1000]\n",
      "- [VAL] LOSS : 4.088790956302546e-05 [SCORE] : 1.0\n",
      "[772/1000]\n",
      "- [TRAIN] LOSS : 3.064549558378834e-05 [SCORE] : 0.6\n",
      "[772/1000]\n",
      "- [VAL] LOSS : 4.065973189426586e-05 [SCORE] : 1.0\n",
      "[773/1000]\n",
      "- [TRAIN] LOSS : 3.0480316430233263e-05 [SCORE] : 0.6\n",
      "[773/1000]\n",
      "- [VAL] LOSS : 4.043644366902299e-05 [SCORE] : 1.0\n",
      "[774/1000]\n",
      "- [TRAIN] LOSS : 3.0312809152140592e-05 [SCORE] : 0.6\n",
      "[774/1000]\n",
      "- [VAL] LOSS : 4.0201219235314056e-05 [SCORE] : 1.0\n",
      "[775/1000]\n",
      "- [TRAIN] LOSS : 3.015139003158159e-05 [SCORE] : 0.6\n",
      "[775/1000]\n",
      "- [VAL] LOSS : 3.998384272563271e-05 [SCORE] : 1.0\n",
      "[776/1000]\n",
      "- [TRAIN] LOSS : 2.9989354819311604e-05 [SCORE] : 0.6\n",
      "[776/1000]\n",
      "- [VAL] LOSS : 3.9754748286213726e-05 [SCORE] : 1.0\n",
      "[777/1000]\n",
      "- [TRAIN] LOSS : 2.9827123519983918e-05 [SCORE] : 0.6\n",
      "[777/1000]\n",
      "- [VAL] LOSS : 3.953070336137898e-05 [SCORE] : 1.0\n",
      "[778/1000]\n",
      "- [TRAIN] LOSS : 2.966539335223691e-05 [SCORE] : 0.6\n",
      "[778/1000]\n",
      "- [VAL] LOSS : 3.931158425984904e-05 [SCORE] : 1.0\n",
      "[779/1000]\n",
      "- [TRAIN] LOSS : 2.9504117386143965e-05 [SCORE] : 0.6\n",
      "[779/1000]\n",
      "- [VAL] LOSS : 3.90931309084408e-05 [SCORE] : 1.0\n",
      "[780/1000]\n",
      "- [TRAIN] LOSS : 2.9342481260149118e-05 [SCORE] : 0.6\n",
      "[780/1000]\n",
      "- [VAL] LOSS : 3.8883921661181375e-05 [SCORE] : 1.0\n",
      "[781/1000]\n",
      "- [TRAIN] LOSS : 2.918527570727747e-05 [SCORE] : 0.6\n",
      "[781/1000]\n",
      "- [VAL] LOSS : 3.865830149152316e-05 [SCORE] : 1.0\n",
      "[782/1000]\n",
      "- [TRAIN] LOSS : 2.9025343064859043e-05 [SCORE] : 0.6\n",
      "[782/1000]\n",
      "- [VAL] LOSS : 3.844638922601007e-05 [SCORE] : 1.0\n",
      "[783/1000]\n",
      "- [TRAIN] LOSS : 2.886956135625951e-05 [SCORE] : 0.6\n",
      "[783/1000]\n",
      "- [VAL] LOSS : 3.82309481210541e-05 [SCORE] : 1.0\n",
      "[784/1000]\n",
      "- [TRAIN] LOSS : 2.871145691945761e-05 [SCORE] : 0.6\n",
      "[784/1000]\n",
      "- [VAL] LOSS : 3.801615093834698e-05 [SCORE] : 1.0\n",
      "[785/1000]\n",
      "- [TRAIN] LOSS : 2.8558914103390028e-05 [SCORE] : 0.6\n",
      "[785/1000]\n",
      "- [VAL] LOSS : 3.780613042181358e-05 [SCORE] : 1.0\n",
      "[786/1000]\n",
      "- [TRAIN] LOSS : 2.84032278311012e-05 [SCORE] : 0.6\n",
      "[786/1000]\n",
      "- [VAL] LOSS : 3.759702303796075e-05 [SCORE] : 1.0\n",
      "[787/1000]\n",
      "- [TRAIN] LOSS : 2.8248052209770928e-05 [SCORE] : 0.6\n",
      "[787/1000]\n",
      "- [VAL] LOSS : 3.7392885133158416e-05 [SCORE] : 1.0\n",
      "[788/1000]\n",
      "- [TRAIN] LOSS : 2.809733153602186e-05 [SCORE] : 0.6\n",
      "[788/1000]\n",
      "- [VAL] LOSS : 3.718097650562413e-05 [SCORE] : 1.0\n",
      "[789/1000]\n",
      "- [TRAIN] LOSS : 2.794629241786121e-05 [SCORE] : 0.6\n",
      "[789/1000]\n",
      "- [VAL] LOSS : 3.697403008118272e-05 [SCORE] : 1.0\n",
      "[790/1000]\n",
      "- [TRAIN] LOSS : 2.7794490051746834e-05 [SCORE] : 0.6\n",
      "[790/1000]\n",
      "- [VAL] LOSS : 3.67677457688842e-05 [SCORE] : 1.0\n",
      "[791/1000]\n",
      "- [TRAIN] LOSS : 2.764631184012008e-05 [SCORE] : 0.6\n",
      "[791/1000]\n",
      "- [VAL] LOSS : 3.656217086245306e-05 [SCORE] : 1.0\n",
      "[792/1000]\n",
      "- [TRAIN] LOSS : 2.749582508840831e-05 [SCORE] : 0.6\n",
      "[792/1000]\n",
      "- [VAL] LOSS : 3.6361616366775706e-05 [SCORE] : 1.0\n",
      "[793/1000]\n",
      "- [TRAIN] LOSS : 2.7350574540226566e-05 [SCORE] : 0.6\n",
      "[793/1000]\n",
      "- [VAL] LOSS : 3.616186950239353e-05 [SCORE] : 1.0\n",
      "[794/1000]\n",
      "- [TRAIN] LOSS : 2.720067113841651e-05 [SCORE] : 0.6\n",
      "[794/1000]\n",
      "- [VAL] LOSS : 3.595435919123702e-05 [SCORE] : 1.0\n",
      "[795/1000]\n",
      "- [TRAIN] LOSS : 2.7054389890205735e-05 [SCORE] : 0.6\n",
      "[795/1000]\n",
      "- [VAL] LOSS : 3.5760309401666746e-05 [SCORE] : 1.0\n",
      "[796/1000]\n",
      "- [TRAIN] LOSS : 2.6906592938757968e-05 [SCORE] : 0.6\n",
      "[796/1000]\n",
      "- [VAL] LOSS : 3.556685624062084e-05 [SCORE] : 1.0\n",
      "[797/1000]\n",
      "- [TRAIN] LOSS : 2.67643375385281e-05 [SCORE] : 0.6\n",
      "[797/1000]\n",
      "- [VAL] LOSS : 3.53655414073728e-05 [SCORE] : 1.0\n",
      "[798/1000]\n",
      "- [TRAIN] LOSS : 2.6620537573762705e-05 [SCORE] : 0.6\n",
      "[798/1000]\n",
      "- [VAL] LOSS : 3.517770528560504e-05 [SCORE] : 1.0\n",
      "[799/1000]\n",
      "- [TRAIN] LOSS : 2.6476377934159244e-05 [SCORE] : 0.6\n",
      "[799/1000]\n",
      "- [VAL] LOSS : 3.497342186165042e-05 [SCORE] : 1.0\n",
      "[800/1000]\n",
      "- [TRAIN] LOSS : 2.6331024249278318e-05 [SCORE] : 0.6\n",
      "[800/1000]\n",
      "- [VAL] LOSS : 3.477838617982343e-05 [SCORE] : 1.0\n",
      "[801/1000]\n",
      "- [TRAIN] LOSS : 2.6192836109354782e-05 [SCORE] : 0.6\n",
      "[801/1000]\n",
      "- [VAL] LOSS : 3.459243816905655e-05 [SCORE] : 1.0\n",
      "[802/1000]\n",
      "- [TRAIN] LOSS : 2.6050725318782496e-05 [SCORE] : 0.6\n",
      "[802/1000]\n",
      "- [VAL] LOSS : 3.439877036726102e-05 [SCORE] : 1.0\n",
      "[803/1000]\n",
      "- [TRAIN] LOSS : 2.5909858838228198e-05 [SCORE] : 0.6\n",
      "[803/1000]\n",
      "- [VAL] LOSS : 3.420574284973554e-05 [SCORE] : 1.0\n",
      "[804/1000]\n",
      "- [TRAIN] LOSS : 2.5769416303470886e-05 [SCORE] : 0.6\n",
      "[804/1000]\n",
      "- [VAL] LOSS : 3.401326102903113e-05 [SCORE] : 1.0\n",
      "[805/1000]\n",
      "- [TRAIN] LOSS : 2.5630514513371358e-05 [SCORE] : 0.6\n",
      "[805/1000]\n",
      "- [VAL] LOSS : 3.382571230758913e-05 [SCORE] : 1.0\n",
      "[806/1000]\n",
      "- [TRAIN] LOSS : 2.549205055402126e-05 [SCORE] : 0.6\n",
      "[806/1000]\n",
      "- [VAL] LOSS : 3.3642962080193684e-05 [SCORE] : 1.0\n",
      "[807/1000]\n",
      "- [TRAIN] LOSS : 2.5355926239474988e-05 [SCORE] : 0.6\n",
      "[807/1000]\n",
      "- [VAL] LOSS : 3.3452397474320605e-05 [SCORE] : 1.0\n",
      "[808/1000]\n",
      "- [TRAIN] LOSS : 2.5219419088292248e-05 [SCORE] : 0.6\n",
      "[808/1000]\n",
      "- [VAL] LOSS : 3.326655496493913e-05 [SCORE] : 1.0\n",
      "[809/1000]\n",
      "- [TRAIN] LOSS : 2.5086851837841096e-05 [SCORE] : 0.6\n",
      "[809/1000]\n",
      "- [VAL] LOSS : 3.3081520086852834e-05 [SCORE] : 1.0\n",
      "[810/1000]\n",
      "- [TRAIN] LOSS : 2.4949617121213426e-05 [SCORE] : 0.6\n",
      "[810/1000]\n",
      "- [VAL] LOSS : 3.290138556621969e-05 [SCORE] : 1.0\n",
      "[811/1000]\n",
      "- [TRAIN] LOSS : 2.4815975484671073e-05 [SCORE] : 0.6\n",
      "[811/1000]\n",
      "- [VAL] LOSS : 3.2713454857002944e-05 [SCORE] : 1.0\n",
      "[812/1000]\n",
      "- [TRAIN] LOSS : 2.468433685862692e-05 [SCORE] : 0.6\n",
      "[812/1000]\n",
      "- [VAL] LOSS : 3.253050454077311e-05 [SCORE] : 1.0\n",
      "[813/1000]\n",
      "- [TRAIN] LOSS : 2.4549546530276227e-05 [SCORE] : 0.6\n",
      "[813/1000]\n",
      "- [VAL] LOSS : 3.2348030799767e-05 [SCORE] : 1.0\n",
      "[814/1000]\n",
      "- [TRAIN] LOSS : 2.4417096028628293e-05 [SCORE] : 0.6\n",
      "[814/1000]\n",
      "- [VAL] LOSS : 3.2178930268855765e-05 [SCORE] : 1.0\n",
      "[815/1000]\n",
      "- [TRAIN] LOSS : 2.4288187463146946e-05 [SCORE] : 0.6\n",
      "[815/1000]\n",
      "- [VAL] LOSS : 3.200196078978479e-05 [SCORE] : 1.0\n",
      "[816/1000]\n",
      "- [TRAIN] LOSS : 2.4157709352342256e-05 [SCORE] : 0.6\n",
      "[816/1000]\n",
      "- [VAL] LOSS : 3.1829902582103387e-05 [SCORE] : 1.0\n",
      "[817/1000]\n",
      "- [TRAIN] LOSS : 2.4026860258648716e-05 [SCORE] : 0.6\n",
      "[817/1000]\n",
      "- [VAL] LOSS : 3.164567533531226e-05 [SCORE] : 1.0\n",
      "[818/1000]\n",
      "- [TRAIN] LOSS : 2.3897575162360832e-05 [SCORE] : 0.6\n",
      "[818/1000]\n",
      "- [VAL] LOSS : 3.14789213007316e-05 [SCORE] : 1.0\n",
      "[819/1000]\n",
      "- [TRAIN] LOSS : 2.377217782244164e-05 [SCORE] : 0.6\n",
      "[819/1000]\n",
      "- [VAL] LOSS : 3.129158722003922e-05 [SCORE] : 1.0\n",
      "[820/1000]\n",
      "- [TRAIN] LOSS : 2.364442389080068e-05 [SCORE] : 0.6\n",
      "[820/1000]\n",
      "- [VAL] LOSS : 3.1117717298911884e-05 [SCORE] : 1.0\n",
      "[821/1000]\n",
      "- [TRAIN] LOSS : 2.3515507291449466e-05 [SCORE] : 0.6\n",
      "[821/1000]\n",
      "- [VAL] LOSS : 3.094862404395826e-05 [SCORE] : 1.0\n",
      "[822/1000]\n",
      "- [TRAIN] LOSS : 2.3390482844358e-05 [SCORE] : 0.6\n",
      "[822/1000]\n",
      "- [VAL] LOSS : 3.0784274713369086e-05 [SCORE] : 1.0\n",
      "[823/1000]\n",
      "- [TRAIN] LOSS : 2.3265377058123705e-05 [SCORE] : 0.6\n",
      "[823/1000]\n",
      "- [VAL] LOSS : 3.061202369281091e-05 [SCORE] : 1.0\n",
      "[824/1000]\n",
      "- [TRAIN] LOSS : 2.313988819272102e-05 [SCORE] : 0.6\n",
      "[824/1000]\n",
      "- [VAL] LOSS : 3.0436154702329077e-05 [SCORE] : 1.0\n",
      "[825/1000]\n",
      "- [TRAIN] LOSS : 2.3019166928861522e-05 [SCORE] : 0.6\n",
      "[825/1000]\n",
      "- [VAL] LOSS : 3.027789898624178e-05 [SCORE] : 1.0\n",
      "[826/1000]\n",
      "- [TRAIN] LOSS : 2.28920816880418e-05 [SCORE] : 0.6\n",
      "[826/1000]\n",
      "- [VAL] LOSS : 3.011599983437918e-05 [SCORE] : 1.0\n",
      "[827/1000]\n",
      "- [TRAIN] LOSS : 2.2770135425768483e-05 [SCORE] : 0.6\n",
      "[827/1000]\n",
      "- [VAL] LOSS : 2.994607166328933e-05 [SCORE] : 1.0\n",
      "[828/1000]\n",
      "- [TRAIN] LOSS : 2.2648887685742618e-05 [SCORE] : 0.6\n",
      "[828/1000]\n",
      "- [VAL] LOSS : 2.9781003831885755e-05 [SCORE] : 1.0\n",
      "[829/1000]\n",
      "- [TRAIN] LOSS : 2.2526790841463176e-05 [SCORE] : 0.6\n",
      "[829/1000]\n",
      "- [VAL] LOSS : 2.961205245810561e-05 [SCORE] : 1.0\n",
      "[830/1000]\n",
      "- [TRAIN] LOSS : 2.2408177028410136e-05 [SCORE] : 0.6\n",
      "[830/1000]\n",
      "- [VAL] LOSS : 2.9456528864102438e-05 [SCORE] : 1.0\n",
      "[831/1000]\n",
      "- [TRAIN] LOSS : 2.2289198144183806e-05 [SCORE] : 0.6\n",
      "[831/1000]\n",
      "- [VAL] LOSS : 2.9293241823324934e-05 [SCORE] : 1.0\n",
      "[832/1000]\n",
      "- [TRAIN] LOSS : 2.2171399875029842e-05 [SCORE] : 0.6\n",
      "[832/1000]\n",
      "- [VAL] LOSS : 2.9126325898687355e-05 [SCORE] : 1.0\n",
      "[833/1000]\n",
      "- [TRAIN] LOSS : 2.205044562894424e-05 [SCORE] : 0.6\n",
      "[833/1000]\n",
      "- [VAL] LOSS : 2.8968370315851644e-05 [SCORE] : 1.0\n",
      "[834/1000]\n",
      "- [TRAIN] LOSS : 2.1934151936875425e-05 [SCORE] : 0.6\n",
      "[834/1000]\n",
      "- [VAL] LOSS : 2.8811042284360155e-05 [SCORE] : 1.0\n",
      "[835/1000]\n",
      "- [TRAIN] LOSS : 2.1815047269531836e-05 [SCORE] : 0.6\n",
      "[835/1000]\n",
      "- [VAL] LOSS : 2.864995985873975e-05 [SCORE] : 1.0\n",
      "[836/1000]\n",
      "- [TRAIN] LOSS : 2.1701455443690067e-05 [SCORE] : 0.6\n",
      "[836/1000]\n",
      "- [VAL] LOSS : 2.8485144866863266e-05 [SCORE] : 1.0\n",
      "[837/1000]\n",
      "- [TRAIN] LOSS : 2.1583016829633075e-05 [SCORE] : 0.6\n",
      "[837/1000]\n",
      "- [VAL] LOSS : 2.8337904950603843e-05 [SCORE] : 1.0\n",
      "[838/1000]\n",
      "- [TRAIN] LOSS : 2.1472488454795288e-05 [SCORE] : 0.6\n",
      "[838/1000]\n",
      "- [VAL] LOSS : 2.818269240378868e-05 [SCORE] : 1.0\n",
      "[839/1000]\n",
      "- [TRAIN] LOSS : 2.1353171117273936e-05 [SCORE] : 0.6\n",
      "[839/1000]\n",
      "- [VAL] LOSS : 2.802394919854123e-05 [SCORE] : 1.0\n",
      "[840/1000]\n",
      "- [TRAIN] LOSS : 2.123978210875066e-05 [SCORE] : 0.6\n",
      "[840/1000]\n",
      "- [VAL] LOSS : 2.7869757104781456e-05 [SCORE] : 1.0\n",
      "[841/1000]\n",
      "- [TRAIN] LOSS : 2.112546659797469e-05 [SCORE] : 0.6\n",
      "[841/1000]\n",
      "- [VAL] LOSS : 2.7711792426998727e-05 [SCORE] : 1.0\n",
      "[842/1000]\n",
      "- [TRAIN] LOSS : 2.10142209349821e-05 [SCORE] : 0.6\n",
      "[842/1000]\n",
      "- [VAL] LOSS : 2.7562835384742357e-05 [SCORE] : 1.0\n",
      "[843/1000]\n",
      "- [TRAIN] LOSS : 2.090289605500099e-05 [SCORE] : 0.6\n",
      "[843/1000]\n",
      "- [VAL] LOSS : 2.7410200345912017e-05 [SCORE] : 1.0\n",
      "[844/1000]\n",
      "- [TRAIN] LOSS : 2.078915582994038e-05 [SCORE] : 0.6\n",
      "[844/1000]\n",
      "- [VAL] LOSS : 2.7262318326393142e-05 [SCORE] : 1.0\n",
      "[845/1000]\n",
      "- [TRAIN] LOSS : 2.068170166846054e-05 [SCORE] : 0.6\n",
      "[845/1000]\n",
      "- [VAL] LOSS : 2.710642911551986e-05 [SCORE] : 1.0\n",
      "[846/1000]\n",
      "- [TRAIN] LOSS : 2.056700025908261e-05 [SCORE] : 0.6\n",
      "[846/1000]\n",
      "- [VAL] LOSS : 2.695535476959776e-05 [SCORE] : 1.0\n",
      "[847/1000]\n",
      "- [TRAIN] LOSS : 2.045858151783856e-05 [SCORE] : 0.6\n",
      "[847/1000]\n",
      "- [VAL] LOSS : 2.680902434804011e-05 [SCORE] : 1.0\n",
      "[848/1000]\n",
      "- [TRAIN] LOSS : 2.0349696266445488e-05 [SCORE] : 0.6\n",
      "[848/1000]\n",
      "- [VAL] LOSS : 2.6658915885491297e-05 [SCORE] : 1.0\n",
      "[849/1000]\n",
      "- [TRAIN] LOSS : 2.0241538065117006e-05 [SCORE] : 0.6\n",
      "[849/1000]\n",
      "- [VAL] LOSS : 2.6517929654801264e-05 [SCORE] : 1.0\n",
      "[850/1000]\n",
      "- [TRAIN] LOSS : 2.0134092786368758e-05 [SCORE] : 0.6\n",
      "[850/1000]\n",
      "- [VAL] LOSS : 2.6364603399997577e-05 [SCORE] : 1.0\n",
      "[851/1000]\n",
      "- [TRAIN] LOSS : 2.0024962941533887e-05 [SCORE] : 0.6\n",
      "[851/1000]\n",
      "- [VAL] LOSS : 2.622876490931958e-05 [SCORE] : 1.0\n",
      "[852/1000]\n",
      "- [TRAIN] LOSS : 1.9920475854936132e-05 [SCORE] : 0.6\n",
      "[852/1000]\n",
      "- [VAL] LOSS : 2.608054091979284e-05 [SCORE] : 1.0\n",
      "[853/1000]\n",
      "- [TRAIN] LOSS : 1.981350524147274e-05 [SCORE] : 0.6\n",
      "[853/1000]\n",
      "- [VAL] LOSS : 2.59414500760613e-05 [SCORE] : 1.0\n",
      "[854/1000]\n",
      "- [TRAIN] LOSS : 1.970887036198595e-05 [SCORE] : 0.6\n",
      "[854/1000]\n",
      "- [VAL] LOSS : 2.578581916168332e-05 [SCORE] : 1.0\n",
      "[855/1000]\n",
      "- [TRAIN] LOSS : 1.9605742090789134e-05 [SCORE] : 0.6\n",
      "[855/1000]\n",
      "- [VAL] LOSS : 2.564782516856212e-05 [SCORE] : 1.0\n",
      "[856/1000]\n",
      "- [TRAIN] LOSS : 1.9500203507050173e-05 [SCORE] : 0.6\n",
      "[856/1000]\n",
      "- [VAL] LOSS : 2.551032775954809e-05 [SCORE] : 1.0\n",
      "[857/1000]\n",
      "- [TRAIN] LOSS : 1.9395337797808073e-05 [SCORE] : 0.6\n",
      "[857/1000]\n",
      "- [VAL] LOSS : 2.5377472411491908e-05 [SCORE] : 1.0\n",
      "[858/1000]\n",
      "- [TRAIN] LOSS : 1.9295111239140777e-05 [SCORE] : 0.6\n",
      "[858/1000]\n",
      "- [VAL] LOSS : 2.5240875402232632e-05 [SCORE] : 1.0\n",
      "[859/1000]\n",
      "- [TRAIN] LOSS : 1.9191636177614176e-05 [SCORE] : 0.6\n",
      "[859/1000]\n",
      "- [VAL] LOSS : 2.5096316676354036e-05 [SCORE] : 1.0\n",
      "[860/1000]\n",
      "- [TRAIN] LOSS : 1.9091265888467508e-05 [SCORE] : 0.6\n",
      "[860/1000]\n",
      "- [VAL] LOSS : 2.495646185707301e-05 [SCORE] : 1.0\n",
      "[861/1000]\n",
      "- [TRAIN] LOSS : 1.8986819213751005e-05 [SCORE] : 0.6\n",
      "[861/1000]\n",
      "- [VAL] LOSS : 2.4817132725729607e-05 [SCORE] : 1.0\n",
      "[862/1000]\n",
      "- [TRAIN] LOSS : 1.8887039823312078e-05 [SCORE] : 0.6\n",
      "[862/1000]\n",
      "- [VAL] LOSS : 2.4686718461452983e-05 [SCORE] : 1.0\n",
      "[863/1000]\n",
      "- [TRAIN] LOSS : 1.878553542458879e-05 [SCORE] : 0.6\n",
      "[863/1000]\n",
      "- [VAL] LOSS : 2.454824607411865e-05 [SCORE] : 1.0\n",
      "[864/1000]\n",
      "- [TRAIN] LOSS : 1.8686320618144237e-05 [SCORE] : 0.6\n",
      "[864/1000]\n",
      "- [VAL] LOSS : 2.441452852508519e-05 [SCORE] : 1.0\n",
      "[865/1000]\n",
      "- [TRAIN] LOSS : 1.8586989820808716e-05 [SCORE] : 0.6\n",
      "[865/1000]\n",
      "- [VAL] LOSS : 2.42811565840384e-05 [SCORE] : 1.0\n",
      "[866/1000]\n",
      "- [TRAIN] LOSS : 1.8488705700292483e-05 [SCORE] : 0.6\n",
      "[866/1000]\n",
      "- [VAL] LOSS : 2.414823029539548e-05 [SCORE] : 1.0\n",
      "[867/1000]\n",
      "- [TRAIN] LOSS : 1.839149229757216e-05 [SCORE] : 0.6\n",
      "[867/1000]\n",
      "- [VAL] LOSS : 2.40158897213405e-05 [SCORE] : 1.0\n",
      "[868/1000]\n",
      "- [TRAIN] LOSS : 1.8293422332741708e-05 [SCORE] : 0.6\n",
      "[868/1000]\n",
      "- [VAL] LOSS : 2.388825305388309e-05 [SCORE] : 1.0\n",
      "[869/1000]\n",
      "- [TRAIN] LOSS : 1.8196836845163488e-05 [SCORE] : 0.6\n",
      "[869/1000]\n",
      "- [VAL] LOSS : 2.3756856535328552e-05 [SCORE] : 1.0\n",
      "[870/1000]\n",
      "- [TRAIN] LOSS : 1.8102537129986255e-05 [SCORE] : 0.6\n",
      "[870/1000]\n",
      "- [VAL] LOSS : 2.3617452825419605e-05 [SCORE] : 1.0\n",
      "[871/1000]\n",
      "- [TRAIN] LOSS : 1.800496787230562e-05 [SCORE] : 0.6\n",
      "[871/1000]\n",
      "- [VAL] LOSS : 2.3491298634326085e-05 [SCORE] : 1.0\n",
      "[872/1000]\n",
      "- [TRAIN] LOSS : 1.7908077309887935e-05 [SCORE] : 0.6\n",
      "[872/1000]\n",
      "- [VAL] LOSS : 2.3369782866211608e-05 [SCORE] : 1.0\n",
      "[873/1000]\n",
      "- [TRAIN] LOSS : 1.7812611834718457e-05 [SCORE] : 0.6\n",
      "[873/1000]\n",
      "- [VAL] LOSS : 2.324014167243149e-05 [SCORE] : 1.0\n",
      "[874/1000]\n",
      "- [TRAIN] LOSS : 1.771860288499738e-05 [SCORE] : 0.6\n",
      "[874/1000]\n",
      "- [VAL] LOSS : 2.3115117073757574e-05 [SCORE] : 1.0\n",
      "[875/1000]\n",
      "- [TRAIN] LOSS : 1.7623621048793817e-05 [SCORE] : 0.6\n",
      "[875/1000]\n",
      "- [VAL] LOSS : 2.2990414436208084e-05 [SCORE] : 1.0\n",
      "[876/1000]\n",
      "- [TRAIN] LOSS : 1.753085274079543e-05 [SCORE] : 0.6\n",
      "[876/1000]\n",
      "- [VAL] LOSS : 2.286195922351908e-05 [SCORE] : 1.0\n",
      "[877/1000]\n",
      "- [TRAIN] LOSS : 1.7440364293482464e-05 [SCORE] : 0.6\n",
      "[877/1000]\n",
      "- [VAL] LOSS : 2.2733987862011418e-05 [SCORE] : 1.0\n",
      "[878/1000]\n",
      "- [TRAIN] LOSS : 1.7348199010787844e-05 [SCORE] : 0.6\n",
      "[878/1000]\n",
      "- [VAL] LOSS : 2.2606445782002993e-05 [SCORE] : 1.0\n",
      "[879/1000]\n",
      "- [TRAIN] LOSS : 1.72555101623099e-05 [SCORE] : 0.6\n",
      "[879/1000]\n",
      "- [VAL] LOSS : 2.2487904061563313e-05 [SCORE] : 1.0\n",
      "[880/1000]\n",
      "- [TRAIN] LOSS : 1.7161107371066465e-05 [SCORE] : 0.6\n",
      "[880/1000]\n",
      "- [VAL] LOSS : 2.2361278752214275e-05 [SCORE] : 1.0\n",
      "[881/1000]\n",
      "- [TRAIN] LOSS : 1.7071335726844457e-05 [SCORE] : 0.6\n",
      "[881/1000]\n",
      "- [VAL] LOSS : 2.2239231839193963e-05 [SCORE] : 1.0\n",
      "[882/1000]\n",
      "- [TRAIN] LOSS : 1.698138848951203e-05 [SCORE] : 0.6\n",
      "[882/1000]\n",
      "- [VAL] LOSS : 2.2126188923721202e-05 [SCORE] : 1.0\n",
      "[883/1000]\n",
      "- [TRAIN] LOSS : 1.689213437809182e-05 [SCORE] : 0.6\n",
      "[883/1000]\n",
      "- [VAL] LOSS : 2.199649861722719e-05 [SCORE] : 1.0\n",
      "[884/1000]\n",
      "- [TRAIN] LOSS : 1.6802717436803504e-05 [SCORE] : 0.6\n",
      "[884/1000]\n",
      "- [VAL] LOSS : 2.188432881666813e-05 [SCORE] : 1.0\n",
      "[885/1000]\n",
      "- [TRAIN] LOSS : 1.6712395093539575e-05 [SCORE] : 0.6\n",
      "[885/1000]\n",
      "- [VAL] LOSS : 2.1772420950583182e-05 [SCORE] : 1.0\n",
      "[886/1000]\n",
      "- [TRAIN] LOSS : 1.662624111607632e-05 [SCORE] : 0.6\n",
      "[886/1000]\n",
      "- [VAL] LOSS : 2.1643940272042528e-05 [SCORE] : 1.0\n",
      "[887/1000]\n",
      "- [TRAIN] LOSS : 1.653677163631073e-05 [SCORE] : 0.6\n",
      "[887/1000]\n",
      "- [VAL] LOSS : 2.1528690922423266e-05 [SCORE] : 1.0\n",
      "[888/1000]\n",
      "- [TRAIN] LOSS : 1.6452372074127196e-05 [SCORE] : 0.6\n",
      "[888/1000]\n",
      "- [VAL] LOSS : 2.1405398001661524e-05 [SCORE] : 1.0\n",
      "[889/1000]\n",
      "- [TRAIN] LOSS : 1.6363479214002535e-05 [SCORE] : 0.6\n",
      "[889/1000]\n",
      "- [VAL] LOSS : 2.1286876290105283e-05 [SCORE] : 1.0\n",
      "[890/1000]\n",
      "- [TRAIN] LOSS : 1.6278445673378884e-05 [SCORE] : 0.6\n",
      "[890/1000]\n",
      "- [VAL] LOSS : 2.1181487682042643e-05 [SCORE] : 1.0\n",
      "[891/1000]\n",
      "- [TRAIN] LOSS : 1.6192860039154765e-05 [SCORE] : 0.6\n",
      "[891/1000]\n",
      "- [VAL] LOSS : 2.1059444407001138e-05 [SCORE] : 1.0\n",
      "[892/1000]\n",
      "- [TRAIN] LOSS : 1.6107099327200558e-05 [SCORE] : 0.6\n",
      "[892/1000]\n",
      "- [VAL] LOSS : 2.0946277800248936e-05 [SCORE] : 1.0\n",
      "[893/1000]\n",
      "- [TRAIN] LOSS : 1.602196880412521e-05 [SCORE] : 0.6\n",
      "[893/1000]\n",
      "- [VAL] LOSS : 2.0833553207921796e-05 [SCORE] : 1.0\n",
      "[894/1000]\n",
      "- [TRAIN] LOSS : 1.5935918266526036e-05 [SCORE] : 0.6\n",
      "[894/1000]\n",
      "- [VAL] LOSS : 2.0708408555947244e-05 [SCORE] : 1.0\n",
      "[895/1000]\n",
      "- [TRAIN] LOSS : 1.5852859784596756e-05 [SCORE] : 0.6\n",
      "[895/1000]\n",
      "- [VAL] LOSS : 2.0604880774044432e-05 [SCORE] : 1.0\n",
      "[896/1000]\n",
      "- [TRAIN] LOSS : 1.577001403347822e-05 [SCORE] : 0.6\n",
      "[896/1000]\n",
      "- [VAL] LOSS : 2.048902024398558e-05 [SCORE] : 1.0\n",
      "[897/1000]\n",
      "- [TRAIN] LOSS : 1.5683856599935097e-05 [SCORE] : 0.6\n",
      "[897/1000]\n",
      "- [VAL] LOSS : 2.0373523511807434e-05 [SCORE] : 1.0\n",
      "[898/1000]\n",
      "- [TRAIN] LOSS : 1.5603491647198098e-05 [SCORE] : 0.6\n",
      "[898/1000]\n",
      "- [VAL] LOSS : 2.026269430643879e-05 [SCORE] : 1.0\n",
      "[899/1000]\n",
      "- [TRAIN] LOSS : 1.55178138508442e-05 [SCORE] : 0.6\n",
      "[899/1000]\n",
      "- [VAL] LOSS : 2.0156539903837256e-05 [SCORE] : 1.0\n",
      "[900/1000]\n",
      "- [TRAIN] LOSS : 1.5438333775819046e-05 [SCORE] : 0.6\n",
      "[900/1000]\n",
      "- [VAL] LOSS : 2.0042174583068117e-05 [SCORE] : 1.0\n",
      "[901/1000]\n",
      "- [TRAIN] LOSS : 1.5357474330812694e-05 [SCORE] : 0.6\n",
      "[901/1000]\n",
      "- [VAL] LOSS : 1.991970930248499e-05 [SCORE] : 1.0\n",
      "[902/1000]\n",
      "- [TRAIN] LOSS : 1.5275665100489276e-05 [SCORE] : 0.6\n",
      "[902/1000]\n",
      "- [VAL] LOSS : 1.982742287509609e-05 [SCORE] : 1.0\n",
      "[903/1000]\n",
      "- [TRAIN] LOSS : 1.5196862174586082e-05 [SCORE] : 0.6\n",
      "[903/1000]\n",
      "- [VAL] LOSS : 1.9718430849025026e-05 [SCORE] : 1.0\n",
      "[904/1000]\n",
      "- [TRAIN] LOSS : 1.5115899410981607e-05 [SCORE] : 0.6\n",
      "[904/1000]\n",
      "- [VAL] LOSS : 1.9609902665251866e-05 [SCORE] : 1.0\n",
      "[905/1000]\n",
      "- [TRAIN] LOSS : 1.5033998700649438e-05 [SCORE] : 0.6\n",
      "[905/1000]\n",
      "- [VAL] LOSS : 1.9501676433719695e-05 [SCORE] : 1.0\n",
      "[906/1000]\n",
      "- [TRAIN] LOSS : 1.495745162477154e-05 [SCORE] : 0.6\n",
      "[906/1000]\n",
      "- [VAL] LOSS : 1.938527202582918e-05 [SCORE] : 1.0\n",
      "[907/1000]\n",
      "- [TRAIN] LOSS : 1.4876749613298065e-05 [SCORE] : 0.6\n",
      "[907/1000]\n",
      "- [VAL] LOSS : 1.9286209862912074e-05 [SCORE] : 1.0\n",
      "[908/1000]\n",
      "- [TRAIN] LOSS : 1.4798230373950598e-05 [SCORE] : 0.6\n",
      "[908/1000]\n",
      "- [VAL] LOSS : 1.9183262338628992e-05 [SCORE] : 1.0\n",
      "[909/1000]\n",
      "- [TRAIN] LOSS : 1.4721546813234454e-05 [SCORE] : 0.6\n",
      "[909/1000]\n",
      "- [VAL] LOSS : 1.9072251234319992e-05 [SCORE] : 1.0\n",
      "[910/1000]\n",
      "- [TRAIN] LOSS : 1.4644708926425665e-05 [SCORE] : 0.6\n",
      "[910/1000]\n",
      "- [VAL] LOSS : 1.8974429622176103e-05 [SCORE] : 1.0\n",
      "[911/1000]\n",
      "- [TRAIN] LOSS : 1.456614536436973e-05 [SCORE] : 0.6\n",
      "[911/1000]\n",
      "- [VAL] LOSS : 1.886843347165268e-05 [SCORE] : 1.0\n",
      "[912/1000]\n",
      "- [TRAIN] LOSS : 1.448857089296022e-05 [SCORE] : 0.6\n",
      "[912/1000]\n",
      "- [VAL] LOSS : 1.8771208488033153e-05 [SCORE] : 1.0\n",
      "[913/1000]\n",
      "- [TRAIN] LOSS : 1.4410776899846194e-05 [SCORE] : 0.6\n",
      "[913/1000]\n",
      "- [VAL] LOSS : 1.8670061763259582e-05 [SCORE] : 1.0\n",
      "[914/1000]\n",
      "- [TRAIN] LOSS : 1.4339148826062835e-05 [SCORE] : 0.6\n",
      "[914/1000]\n",
      "- [VAL] LOSS : 1.8564998754300177e-05 [SCORE] : 1.0\n",
      "[915/1000]\n",
      "- [TRAIN] LOSS : 1.4264551433977127e-05 [SCORE] : 0.6\n",
      "[915/1000]\n",
      "- [VAL] LOSS : 1.8464588720235042e-05 [SCORE] : 1.0\n",
      "[916/1000]\n",
      "- [TRAIN] LOSS : 1.4186230934380244e-05 [SCORE] : 0.6\n",
      "[916/1000]\n",
      "- [VAL] LOSS : 1.8364622519584373e-05 [SCORE] : 1.0\n",
      "[917/1000]\n",
      "- [TRAIN] LOSS : 1.4112132081815313e-05 [SCORE] : 0.6\n",
      "[917/1000]\n",
      "- [VAL] LOSS : 1.8264981918036938e-05 [SCORE] : 1.0\n",
      "[918/1000]\n",
      "- [TRAIN] LOSS : 1.4039810609271324e-05 [SCORE] : 0.6\n",
      "[918/1000]\n",
      "- [VAL] LOSS : 1.8161419575335458e-05 [SCORE] : 1.0\n",
      "[919/1000]\n",
      "- [TRAIN] LOSS : 1.3963345524340791e-05 [SCORE] : 0.6\n",
      "[919/1000]\n",
      "- [VAL] LOSS : 1.8066721167997457e-05 [SCORE] : 1.0\n",
      "[920/1000]\n",
      "- [TRAIN] LOSS : 1.3891456683268189e-05 [SCORE] : 0.6\n",
      "[920/1000]\n",
      "- [VAL] LOSS : 1.796814103727229e-05 [SCORE] : 1.0\n",
      "[921/1000]\n",
      "- [TRAIN] LOSS : 1.381816955472459e-05 [SCORE] : 0.6\n",
      "[921/1000]\n",
      "- [VAL] LOSS : 1.7874106561066583e-05 [SCORE] : 1.0\n",
      "[922/1000]\n",
      "- [TRAIN] LOSS : 1.3745499063588796e-05 [SCORE] : 0.6\n",
      "[922/1000]\n",
      "- [VAL] LOSS : 1.7771924831322394e-05 [SCORE] : 1.0\n",
      "[923/1000]\n",
      "- [TRAIN] LOSS : 1.367421873510466e-05 [SCORE] : 0.6\n",
      "[923/1000]\n",
      "- [VAL] LOSS : 1.767001776897814e-05 [SCORE] : 1.0\n",
      "[924/1000]\n",
      "- [TRAIN] LOSS : 1.3603126202118195e-05 [SCORE] : 0.6\n",
      "[924/1000]\n",
      "- [VAL] LOSS : 1.758120379236061e-05 [SCORE] : 1.0\n",
      "[925/1000]\n",
      "- [TRAIN] LOSS : 1.3531039439840242e-05 [SCORE] : 0.6\n",
      "[925/1000]\n",
      "- [VAL] LOSS : 1.7484353520558216e-05 [SCORE] : 1.0\n",
      "[926/1000]\n",
      "- [TRAIN] LOSS : 1.3458827925205697e-05 [SCORE] : 0.6\n",
      "[926/1000]\n",
      "- [VAL] LOSS : 1.7383539670845494e-05 [SCORE] : 1.0\n",
      "[927/1000]\n",
      "- [TRAIN] LOSS : 1.3390767768820903e-05 [SCORE] : 0.6\n",
      "[927/1000]\n",
      "- [VAL] LOSS : 1.7300137187703513e-05 [SCORE] : 1.0\n",
      "[928/1000]\n",
      "- [TRAIN] LOSS : 1.33185732011043e-05 [SCORE] : 0.6\n",
      "[928/1000]\n",
      "- [VAL] LOSS : 1.7208543795277365e-05 [SCORE] : 1.0\n",
      "[929/1000]\n",
      "- [TRAIN] LOSS : 1.3249340584782961e-05 [SCORE] : 0.6\n",
      "[929/1000]\n",
      "- [VAL] LOSS : 1.711295590212103e-05 [SCORE] : 1.0\n",
      "[930/1000]\n",
      "- [TRAIN] LOSS : 1.3180280166125159e-05 [SCORE] : 0.6\n",
      "[930/1000]\n",
      "- [VAL] LOSS : 1.7017700884025544e-05 [SCORE] : 1.0\n",
      "[931/1000]\n",
      "- [TRAIN] LOSS : 1.3110625756477627e-05 [SCORE] : 0.6\n",
      "[931/1000]\n",
      "- [VAL] LOSS : 1.691849683993496e-05 [SCORE] : 1.0\n",
      "[932/1000]\n",
      "- [TRAIN] LOSS : 1.304076825666319e-05 [SCORE] : 0.6\n",
      "[932/1000]\n",
      "- [VAL] LOSS : 1.6828091247589327e-05 [SCORE] : 1.0\n",
      "[933/1000]\n",
      "- [TRAIN] LOSS : 1.2971471369382925e-05 [SCORE] : 0.6\n",
      "[933/1000]\n",
      "- [VAL] LOSS : 1.6737933037802577e-05 [SCORE] : 1.0\n",
      "[934/1000]\n",
      "- [TRAIN] LOSS : 1.2906315275055628e-05 [SCORE] : 0.6\n",
      "[934/1000]\n",
      "- [VAL] LOSS : 1.665244417381473e-05 [SCORE] : 1.0\n",
      "[935/1000]\n",
      "- [TRAIN] LOSS : 1.2837808678038224e-05 [SCORE] : 0.6\n",
      "[935/1000]\n",
      "- [VAL] LOSS : 1.655452979321126e-05 [SCORE] : 1.0\n",
      "[936/1000]\n",
      "- [TRAIN] LOSS : 1.2769116953374274e-05 [SCORE] : 0.6\n",
      "[936/1000]\n",
      "- [VAL] LOSS : 1.647816134209279e-05 [SCORE] : 1.0\n",
      "[937/1000]\n",
      "- [TRAIN] LOSS : 1.270297971132095e-05 [SCORE] : 0.6\n",
      "[937/1000]\n",
      "- [VAL] LOSS : 1.6380743545596488e-05 [SCORE] : 1.0\n",
      "[938/1000]\n",
      "- [TRAIN] LOSS : 1.2636594298480001e-05 [SCORE] : 0.6\n",
      "[938/1000]\n",
      "- [VAL] LOSS : 1.6292260625050403e-05 [SCORE] : 1.0\n",
      "[939/1000]\n",
      "- [TRAIN] LOSS : 1.257002847220671e-05 [SCORE] : 0.6\n",
      "[939/1000]\n",
      "- [VAL] LOSS : 1.620398325030692e-05 [SCORE] : 1.0\n",
      "[940/1000]\n",
      "- [TRAIN] LOSS : 1.2504418070117632e-05 [SCORE] : 0.6\n",
      "[940/1000]\n",
      "- [VAL] LOSS : 1.6120271538966335e-05 [SCORE] : 1.0\n",
      "[941/1000]\n",
      "- [TRAIN] LOSS : 1.2439798441240176e-05 [SCORE] : 0.6\n",
      "[941/1000]\n",
      "- [VAL] LOSS : 1.6019930626498535e-05 [SCORE] : 1.0\n",
      "[942/1000]\n",
      "- [TRAIN] LOSS : 1.2372624329752095e-05 [SCORE] : 0.6\n",
      "[942/1000]\n",
      "- [VAL] LOSS : 1.5945444829412736e-05 [SCORE] : 1.0\n",
      "[943/1000]\n",
      "- [TRAIN] LOSS : 1.230840889547835e-05 [SCORE] : 0.6\n",
      "[943/1000]\n",
      "- [VAL] LOSS : 1.585421159688849e-05 [SCORE] : 1.0\n",
      "[944/1000]\n",
      "- [TRAIN] LOSS : 1.2242779939697357e-05 [SCORE] : 0.6\n",
      "[944/1000]\n",
      "- [VAL] LOSS : 1.5767476725159213e-05 [SCORE] : 1.0\n",
      "[945/1000]\n",
      "- [TRAIN] LOSS : 1.2178483605869891e-05 [SCORE] : 0.6\n",
      "[945/1000]\n",
      "- [VAL] LOSS : 1.568098559801001e-05 [SCORE] : 1.0\n",
      "[946/1000]\n",
      "- [TRAIN] LOSS : 1.2117133216330937e-05 [SCORE] : 0.6\n",
      "[946/1000]\n",
      "- [VAL] LOSS : 1.5594810975017026e-05 [SCORE] : 1.0\n",
      "[947/1000]\n",
      "- [TRAIN] LOSS : 1.2054383538876816e-05 [SCORE] : 0.6\n",
      "[947/1000]\n",
      "- [VAL] LOSS : 1.551755667605903e-05 [SCORE] : 1.0\n",
      "[948/1000]\n",
      "- [TRAIN] LOSS : 1.1988673425851934e-05 [SCORE] : 0.6\n",
      "[948/1000]\n",
      "- [VAL] LOSS : 1.5427738617290743e-05 [SCORE] : 1.0\n",
      "[949/1000]\n",
      "- [TRAIN] LOSS : 1.1927472830090361e-05 [SCORE] : 0.6\n",
      "[949/1000]\n",
      "- [VAL] LOSS : 1.5351008187280968e-05 [SCORE] : 1.0\n",
      "[950/1000]\n",
      "- [TRAIN] LOSS : 1.1865278459784652e-05 [SCORE] : 0.6\n",
      "[950/1000]\n",
      "- [VAL] LOSS : 1.5266070477082394e-05 [SCORE] : 1.0\n",
      "[951/1000]\n",
      "- [TRAIN] LOSS : 1.180325610524354e-05 [SCORE] : 0.6\n",
      "[951/1000]\n",
      "- [VAL] LOSS : 1.5177172826952301e-05 [SCORE] : 1.0\n",
      "[952/1000]\n",
      "- [TRAIN] LOSS : 1.1742239530576626e-05 [SCORE] : 0.6\n",
      "[952/1000]\n",
      "- [VAL] LOSS : 1.5097169125510845e-05 [SCORE] : 1.0\n",
      "[953/1000]\n",
      "- [TRAIN] LOSS : 1.1678617693178239e-05 [SCORE] : 0.6\n",
      "[953/1000]\n",
      "- [VAL] LOSS : 1.5013146366982255e-05 [SCORE] : 1.0\n",
      "[954/1000]\n",
      "- [TRAIN] LOSS : 1.1619923998296145e-05 [SCORE] : 0.6\n",
      "[954/1000]\n",
      "- [VAL] LOSS : 1.4933641068637371e-05 [SCORE] : 1.0\n",
      "[955/1000]\n",
      "- [TRAIN] LOSS : 1.15586196291891e-05 [SCORE] : 0.6\n",
      "[955/1000]\n",
      "- [VAL] LOSS : 1.4862963325867895e-05 [SCORE] : 1.0\n",
      "[956/1000]\n",
      "- [TRAIN] LOSS : 1.1498281992317061e-05 [SCORE] : 0.6\n",
      "[956/1000]\n",
      "- [VAL] LOSS : 1.4771261703572236e-05 [SCORE] : 1.0\n",
      "[957/1000]\n",
      "- [TRAIN] LOSS : 1.1436112708906876e-05 [SCORE] : 0.6\n",
      "[957/1000]\n",
      "- [VAL] LOSS : 1.4701103282277472e-05 [SCORE] : 1.0\n",
      "[958/1000]\n",
      "- [TRAIN] LOSS : 1.1376882654682656e-05 [SCORE] : 0.6\n",
      "[958/1000]\n",
      "- [VAL] LOSS : 1.4618350178352557e-05 [SCORE] : 1.0\n",
      "[959/1000]\n",
      "- [TRAIN] LOSS : 1.1318578390273615e-05 [SCORE] : 0.6\n",
      "[959/1000]\n",
      "- [VAL] LOSS : 1.453592449252028e-05 [SCORE] : 1.0\n",
      "[960/1000]\n",
      "- [TRAIN] LOSS : 1.126124957409047e-05 [SCORE] : 0.6\n",
      "[960/1000]\n",
      "- [VAL] LOSS : 1.4458149053098168e-05 [SCORE] : 1.0\n",
      "[961/1000]\n",
      "- [TRAIN] LOSS : 1.1200582503079203e-05 [SCORE] : 0.6\n",
      "[961/1000]\n",
      "- [VAL] LOSS : 1.4376419130712748e-05 [SCORE] : 1.0\n",
      "[962/1000]\n",
      "- [TRAIN] LOSS : 1.1140470936273536e-05 [SCORE] : 0.6\n",
      "[962/1000]\n",
      "- [VAL] LOSS : 1.4303352145361714e-05 [SCORE] : 1.0\n",
      "[963/1000]\n",
      "- [TRAIN] LOSS : 1.1084445986853098e-05 [SCORE] : 0.6\n",
      "[963/1000]\n",
      "- [VAL] LOSS : 1.4213485883374233e-05 [SCORE] : 1.0\n",
      "[964/1000]\n",
      "- [TRAIN] LOSS : 1.1026973500823564e-05 [SCORE] : 0.6\n",
      "[964/1000]\n",
      "- [VAL] LOSS : 1.4145248314889614e-05 [SCORE] : 1.0\n",
      "[965/1000]\n",
      "- [TRAIN] LOSS : 1.0970091852868791e-05 [SCORE] : 0.6\n",
      "[965/1000]\n",
      "- [VAL] LOSS : 1.4073101738176774e-05 [SCORE] : 1.0\n",
      "[966/1000]\n",
      "- [TRAIN] LOSS : 1.0910623980938302e-05 [SCORE] : 0.6\n",
      "[966/1000]\n",
      "- [VAL] LOSS : 1.3992634194437414e-05 [SCORE] : 1.0\n",
      "[967/1000]\n",
      "- [TRAIN] LOSS : 1.085525383738665e-05 [SCORE] : 0.6\n",
      "[967/1000]\n",
      "- [VAL] LOSS : 1.3920944184064865e-05 [SCORE] : 1.0\n",
      "[968/1000]\n",
      "- [TRAIN] LOSS : 1.0798462744787684e-05 [SCORE] : 0.6\n",
      "[968/1000]\n",
      "- [VAL] LOSS : 1.3841063264408149e-05 [SCORE] : 1.0\n",
      "[969/1000]\n",
      "- [TRAIN] LOSS : 1.0739869154955766e-05 [SCORE] : 0.6\n",
      "[969/1000]\n",
      "- [VAL] LOSS : 1.3774161743640434e-05 [SCORE] : 1.0\n",
      "[970/1000]\n",
      "- [TRAIN] LOSS : 1.0684981771191814e-05 [SCORE] : 0.6\n",
      "[970/1000]\n",
      "- [VAL] LOSS : 1.3694708286493551e-05 [SCORE] : 1.0\n",
      "[971/1000]\n",
      "- [TRAIN] LOSS : 1.06294225891664e-05 [SCORE] : 0.6\n",
      "[971/1000]\n",
      "- [VAL] LOSS : 1.3623995982925408e-05 [SCORE] : 1.0\n",
      "[972/1000]\n",
      "- [TRAIN] LOSS : 1.0575607302598655e-05 [SCORE] : 0.6\n",
      "[972/1000]\n",
      "- [VAL] LOSS : 1.3553605640481692e-05 [SCORE] : 1.0\n",
      "[973/1000]\n",
      "- [TRAIN] LOSS : 1.0519588113311328e-05 [SCORE] : 0.6\n",
      "[973/1000]\n",
      "- [VAL] LOSS : 1.3474990737449843e-05 [SCORE] : 1.0\n",
      "[974/1000]\n",
      "- [TRAIN] LOSS : 1.0464924192395605e-05 [SCORE] : 0.6\n",
      "[974/1000]\n",
      "- [VAL] LOSS : 1.3400803254626226e-05 [SCORE] : 1.0\n",
      "[975/1000]\n",
      "- [TRAIN] LOSS : 1.0408398793515516e-05 [SCORE] : 0.6\n",
      "[975/1000]\n",
      "- [VAL] LOSS : 1.332688316324493e-05 [SCORE] : 1.0\n",
      "[976/1000]\n",
      "- [TRAIN] LOSS : 1.0356788288845565e-05 [SCORE] : 0.6\n",
      "[976/1000]\n",
      "- [VAL] LOSS : 1.3253227734821849e-05 [SCORE] : 1.0\n",
      "[977/1000]\n",
      "- [TRAIN] LOSS : 1.0300574346426099e-05 [SCORE] : 0.6\n",
      "[977/1000]\n",
      "- [VAL] LOSS : 1.3188347111281473e-05 [SCORE] : 1.0\n",
      "[978/1000]\n",
      "- [TRAIN] LOSS : 1.0247292099544817e-05 [SCORE] : 0.6\n",
      "[978/1000]\n",
      "- [VAL] LOSS : 1.311522919422714e-05 [SCORE] : 1.0\n",
      "[979/1000]\n",
      "- [TRAIN] LOSS : 1.0194557398790494e-05 [SCORE] : 0.6\n",
      "[979/1000]\n",
      "- [VAL] LOSS : 1.304658599110553e-05 [SCORE] : 1.0\n",
      "[980/1000]\n",
      "- [TRAIN] LOSS : 1.0141969445006302e-05 [SCORE] : 0.6\n",
      "[980/1000]\n",
      "- [VAL] LOSS : 1.297392554988619e-05 [SCORE] : 1.0\n",
      "[981/1000]\n",
      "- [TRAIN] LOSS : 1.0091911023361415e-05 [SCORE] : 0.6\n",
      "[981/1000]\n",
      "- [VAL] LOSS : 1.2901628906547558e-05 [SCORE] : 1.0\n",
      "[982/1000]\n",
      "- [TRAIN] LOSS : 1.00364957840308e-05 [SCORE] : 0.6\n",
      "[982/1000]\n",
      "- [VAL] LOSS : 1.283378696825821e-05 [SCORE] : 1.0\n",
      "[983/1000]\n",
      "- [TRAIN] LOSS : 9.98398287871775e-06 [SCORE] : 0.6\n",
      "[983/1000]\n",
      "- [VAL] LOSS : 1.2770459761668462e-05 [SCORE] : 1.0\n",
      "[984/1000]\n",
      "- [TRAIN] LOSS : 9.933602814271581e-06 [SCORE] : 0.6\n",
      "[984/1000]\n",
      "- [VAL] LOSS : 1.2694591532635968e-05 [SCORE] : 1.0\n",
      "[985/1000]\n",
      "- [TRAIN] LOSS : 9.882571976049804e-06 [SCORE] : 0.6\n",
      "[985/1000]\n",
      "- [VAL] LOSS : 1.2631795470952056e-05 [SCORE] : 1.0\n",
      "[986/1000]\n",
      "- [TRAIN] LOSS : 9.830911994868075e-06 [SCORE] : 0.6\n",
      "[986/1000]\n",
      "- [VAL] LOSS : 1.256494488188764e-05 [SCORE] : 1.0\n",
      "[987/1000]\n",
      "- [TRAIN] LOSS : 9.779381177092242e-06 [SCORE] : 0.6\n",
      "[987/1000]\n",
      "- [VAL] LOSS : 1.2494093425630126e-05 [SCORE] : 1.0\n",
      "[988/1000]\n",
      "- [TRAIN] LOSS : 9.726008890235487e-06 [SCORE] : 0.6\n",
      "[988/1000]\n",
      "- [VAL] LOSS : 1.2427680303517263e-05 [SCORE] : 1.0\n",
      "[989/1000]\n",
      "- [TRAIN] LOSS : 9.676328969968987e-06 [SCORE] : 0.6\n",
      "[989/1000]\n",
      "- [VAL] LOSS : 1.2357196283119265e-05 [SCORE] : 1.0\n",
      "[990/1000]\n",
      "- [TRAIN] LOSS : 9.62596747437298e-06 [SCORE] : 0.6\n",
      "[990/1000]\n",
      "- [VAL] LOSS : 1.2291166058275849e-05 [SCORE] : 1.0\n",
      "[991/1000]\n",
      "- [TRAIN] LOSS : 9.577316025873491e-06 [SCORE] : 0.6\n",
      "[991/1000]\n",
      "- [VAL] LOSS : 1.222540140588535e-05 [SCORE] : 1.0\n",
      "[992/1000]\n",
      "- [TRAIN] LOSS : 9.525646404047923e-06 [SCORE] : 0.6\n",
      "[992/1000]\n",
      "- [VAL] LOSS : 1.2168296052550431e-05 [SCORE] : 1.0\n",
      "[993/1000]\n",
      "- [TRAIN] LOSS : 9.47685211940552e-06 [SCORE] : 0.6\n",
      "[993/1000]\n",
      "- [VAL] LOSS : 1.2094454177713487e-05 [SCORE] : 1.0\n",
      "[994/1000]\n",
      "- [TRAIN] LOSS : 9.426227006770204e-06 [SCORE] : 0.6\n",
      "[994/1000]\n",
      "- [VAL] LOSS : 1.203357351187151e-05 [SCORE] : 1.0\n",
      "[995/1000]\n",
      "- [TRAIN] LOSS : 9.378112326885458e-06 [SCORE] : 0.6\n",
      "[995/1000]\n",
      "- [VAL] LOSS : 1.1968646504101343e-05 [SCORE] : 1.0\n",
      "[996/1000]\n",
      "- [TRAIN] LOSS : 9.330129266042302e-06 [SCORE] : 0.6\n",
      "[996/1000]\n",
      "- [VAL] LOSS : 1.190400325867813e-05 [SCORE] : 1.0\n",
      "[997/1000]\n",
      "- [TRAIN] LOSS : 9.282301455944737e-06 [SCORE] : 0.6\n",
      "[997/1000]\n",
      "- [VAL] LOSS : 1.1843920219689608e-05 [SCORE] : 1.0\n",
      "[998/1000]\n",
      "- [TRAIN] LOSS : 9.232669647947962e-06 [SCORE] : 0.6\n",
      "[998/1000]\n",
      "- [VAL] LOSS : 1.1775562597904354e-05 [SCORE] : 1.0\n",
      "[999/1000]\n",
      "- [TRAIN] LOSS : 9.183554220726365e-06 [SCORE] : 0.6\n",
      "[999/1000]\n",
      "- [VAL] LOSS : 1.1711601473507471e-05 [SCORE] : 1.0\n",
      "[1000/1000]\n",
      "- [TRAIN] LOSS : 9.136929656961002e-06 [SCORE] : 0.6\n",
      "[1000/1000]\n",
      "- [VAL] LOSS : 1.1647855899354909e-05 [SCORE] : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 학습의 효과 확인 손실값과 성능평가값 저장 필요\n",
    "LOSS_HISTORY, SCORE_HISTROY=[[],[]], [[],[]]\n",
    "\n",
    "for epoch in range(1,EPOCH+1):\n",
    "    # 학습 모드로 모델 설정\n",
    "    model.train()\n",
    "\n",
    "    # 배치크기 만큼 데이터 로딩해서 학습 진행\n",
    "    loss_total, score_total=0, 0\n",
    "    for featureTS, targetTS in trainDL:\n",
    "\n",
    "        # 학습 진행\n",
    "        pre_y=model(featureTS)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss=bceLoss(pre_y, targetTS)\n",
    "        loss_total += loss.item()\n",
    "\n",
    "        # 성능평가 계산\n",
    "        score=F1Score(task='binary')(pre_y, targetTS)\n",
    "        score_total += score.item()\n",
    "\n",
    "        # 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 에포크 당 검증기능\n",
    "    # 모델 검증 모드 설정\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 검증 데이터셋\n",
    "        val_featureTS=torch.FloatTensor(valDS.featureDF.values)\n",
    "        val_targetTS=torch.FloatTensor(valDS.targetDF.values)\n",
    "\n",
    "        # 추론/평가\n",
    "        pre_val=model(val_featureTS)\n",
    "\n",
    "        # 손실\n",
    "        loss_val=bceLoss(pre_val, val_targetTS)\n",
    "\n",
    "        # 성능평가\n",
    "        score_val=F1Score(task='binary')(pre_val, val_targetTS)\n",
    "    \n",
    "    # 에포크 당 손실값과 성능평가값 저장\n",
    "    LOSS_HISTORY[0].append(loss_total/BATCH_CNT)\n",
    "    SCORE_HISTROY[0].append(score_total/BATCH_CNT)\n",
    "\n",
    "    LOSS_HISTORY[1].append(loss_val)\n",
    "    SCORE_HISTROY[1].append(score_val)\n",
    "\n",
    "    print(f'[{epoch}/{EPOCH}]\\n- [TRAIN] LOSS : {LOSS_HISTORY[0][-1]} [SCORE] : {SCORE_HISTROY[0][-1]}')\n",
    "    print(f'[{epoch}/{EPOCH}]\\n- [VAL] LOSS : {LOSS_HISTORY[1][-1]} [SCORE] : {SCORE_HISTROY[1][-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 후 loss 시각화\n",
    "\n",
    "THRESHOLD=10\n",
    "fg, axes=plt.subplots(1,2,figsize=(10,5))\n",
    "axes[0].plot(range(1, THRESHOLD+1), LOSS_HISTORY[0][:THRESHOLD], label='Train')\n",
    "axes[0].plot(range(1, THRESHOLD+1), LOSS_HISTORY[1][:THRESHOLD], label='Val')\n",
    "axes[0].grid()\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Epoch&Loss')\n",
    "\n",
    "axes[1].plot(range(1, THRESHOLD+1), SCORE_HISTROY[0][:THRESHOLD], label='Train')\n",
    "axes[1].plot(range(1, THRESHOLD+1), SCORE_HISTROY[1][:THRESHOLD], label='Val')\n",
    "axes[1].grid()\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('score')\n",
    "axes[1].set_title('Epoch&score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
