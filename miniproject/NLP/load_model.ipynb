{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "import re\n",
    "import pickle\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 분류하는 모델\n",
    "class SentenceClassifier(nn.Module):\n",
    "    def __init__(self, n_vocab, hidden_dim, embedding_dim, n_layers, n_classes ,dropout=0.5, bidirectional=True, model_type=\"lstm\"):\n",
    "        super().__init__()  # 부모클래스 상속\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=n_vocab, embedding_dim=embedding_dim, padding_idx=0)\n",
    "\n",
    "        # rnn모델 일 경우\n",
    "        if model_type == 'rnn':\n",
    "            self.model = nn.RNN(\n",
    "                input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout, batch_first=True\n",
    "            )\n",
    "        # lstm모델 일 경우\n",
    "        elif model_type == 'lstm':\n",
    "            self.model = nn.LSTM(\n",
    "                input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout, batch_first=True\n",
    "            )\n",
    "\n",
    "        # bidirectional은 양방향성을 의미하는 파라미터\n",
    "        if bidirectional:\n",
    "            self.classifier = nn.Linear(hidden_dim * 2, n_classes)   # 양방향일때 타임스탭에서 양방향의 정보(순방향,역방향)의 출력들을 결합하여 분류기에 전달\n",
    "        else:\n",
    "            self.classifier = nn.Linear(hidden_dim, n_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        output, _ = self.model(embeddings) \n",
    "        last_output = output[:, -1, :]\n",
    "        last_output = self.dropout(last_output)\n",
    "        logits = self.classifier(last_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 새로운 리뷰 데이터 불러오기\n",
    "new_reviews = [\"정말 재미있었어요!\", \"영 별로였어요...\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 한글만 남기고 정규식 적용\n",
    "def re_text(text):\n",
    "    text = re.sub(r'[^\\n가-힇\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reviews = [re_text(review) for review in new_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Okt 토크나이저 로드 및 토큰화\n",
    "tokenizer = Okt()\n",
    "STOP_PATH = 'kor_stopwords.txt'\n",
    "\n",
    "def make_stopwords(STOP_PATH):\n",
    "    with open(STOP_PATH, 'r', encoding='utf-8') as f:\n",
    "        stopwords = f.read().splitlines()\n",
    "    return set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = make_stopwords(STOP_PATH)\n",
    "new_tokens = [[token for token in tokenizer.morphs(review) if token not in stopwords] for review in new_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 단어 사전 로드\n",
    "with open('vocab.pkl', 'rb') as f:\n",
    "    vocab_list = pickle.load(f)\n",
    "\n",
    "# 리스트를 사전으로 변환\n",
    "token_to_id = {token: idx for idx, token in enumerate(vocab_list)}\n",
    "\n",
    "unk_id = token_to_id.get(\"<unk>\", 1)\n",
    "pad_id = token_to_id.get(\"<pad>\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 정수 인코딩\n",
    "new_ids = [[token_to_id.get(token, unk_id) for token in tokens] for tokens in new_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 패딩 적용\n",
    "max_length = 120\n",
    "def pad_sequences(sequences, max_length, pad_value):\n",
    "    result = []\n",
    "    for sequence in sequences:\n",
    "        sequence = sequence[:max_length]\n",
    "        pad_length = max_length - len(sequence)\n",
    "        padded_sequence = sequence + [pad_value] * pad_length\n",
    "        result.append(padded_sequence)\n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ids_padded = pad_sequences(new_ids, max_length, pad_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceClassifier(\n",
       "  (embedding): Embedding(10002, 128, padding_idx=0)\n",
       "  (model): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (classifier): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load('best_model.pth', map_location=device)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰: 정말 재미있었어요\n",
      "예측된 감정: 부정\n",
      "리뷰: 영 별로였어요\n",
      "예측된 감정: 부정\n"
     ]
    }
   ],
   "source": [
    "# 8. 모델 예측\n",
    "new_ids_tensor = torch.tensor(new_ids_padded).to(device)  # 데이터를 모델이 있는 디바이스로 이동\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(new_ids_tensor)\n",
    "    predictions = torch.sigmoid(outputs)\n",
    "\n",
    "# 9. 예측 결과 출력 (0.5 이상이면 긍정, 미만이면 부정)\n",
    "for i, review in enumerate(new_reviews):\n",
    "    prediction = 1 if predictions[i] >= 0.5 else 0\n",
    "    print(f\"리뷰: {review}\")\n",
    "    print(f\"예측된 감정: {'긍정' if prediction == 1 else '부정'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEXT_018",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
