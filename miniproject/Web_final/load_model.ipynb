{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "import re\n",
    "import pickle\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 분류하는 모델\n",
    "class SentenceClassifier(nn.Module):\n",
    "    def __init__(self, n_vocab, hidden_dim, embedding_dim, n_layers, n_classes ,dropout=0.5, bidirectional=True, model_type=\"lstm\"):\n",
    "        super().__init__()  # 부모클래스 상속\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=n_vocab, embedding_dim=embedding_dim, padding_idx=0)\n",
    "\n",
    "        # rnn모델 일 경우\n",
    "        if model_type == 'rnn':\n",
    "            self.model = nn.RNN(\n",
    "                input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout, batch_first=True\n",
    "            )\n",
    "        # lstm모델 일 경우\n",
    "        elif model_type == 'lstm':\n",
    "            self.model = nn.LSTM(\n",
    "                input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout, batch_first=True\n",
    "            )\n",
    "\n",
    "        # bidirectional은 양방향성을 의미하는 파라미터\n",
    "        if bidirectional:\n",
    "            self.classifier = nn.Linear(hidden_dim * 2, n_classes)   # 양방향일때 타임스탭에서 양방향의 정보(순방향,역방향)의 출력들을 결합하여 분류기에 전달\n",
    "        else:\n",
    "            self.classifier = nn.Linear(hidden_dim, n_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        output, _ = self.model(embeddings) \n",
    "        last_output = output[:, -1, :]\n",
    "        last_output = self.dropout(last_output)\n",
    "        logits = self.classifier(last_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 새로운 리뷰 데이터 불러오기\n",
    "new_reviews = [\"1950년대 한국전쟁 직후 가난했지만 낭만이 있던 시대! 초괴의 국극 배우에 도전하는 '타고난 소리천재' 정년이를 둘러싼 경쟁과 연대, 그리고 찬란한 성장기\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 한글만 남기고 정규식 적용\n",
    "def re_text(text):\n",
    "    text = re.sub(r'[^\\n가-힇\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reviews = [re_text(review) for review in new_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Okt 토크나이저 로드 및 토큰화\n",
    "tokenizer = Okt()\n",
    "STOP_PATH = 'kor_stopwords.txt'\n",
    "\n",
    "def make_stopwords(STOP_PATH):\n",
    "    with open(STOP_PATH, 'r', encoding='utf-8') as f:\n",
    "        stopwords = f.read().splitlines()\n",
    "    return set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = make_stopwords(STOP_PATH)\n",
    "new_tokens = [[token for token in tokenizer.morphs(review) if token not in stopwords] for review in new_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 단어 사전 로드\n",
    "with open('vocab.pkl', 'rb') as f:\n",
    "    vocab_list = pickle.load(f)\n",
    "\n",
    "# 리스트를 사전으로 변환\n",
    "token_to_id = {token: idx for idx, token in enumerate(vocab_list)}\n",
    "\n",
    "unk_id = token_to_id.get(\"<unk>\", 1)\n",
    "pad_id = token_to_id.get(\"<pad>\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 정수 인코딩\n",
    "new_ids = [[token_to_id.get(token, unk_id) for token in tokens] for tokens in new_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 패딩 적용\n",
    "max_length = 60\n",
    "def pad_sequences(sequences, max_length, pad_value):\n",
    "    result = []\n",
    "    for sequence in sequences:\n",
    "        sequence = sequence[:max_length]\n",
    "        pad_length = max_length - len(sequence)\n",
    "        padded_sequence = sequence + [pad_value] * pad_length\n",
    "        result.append(padded_sequence)\n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ids_padded = pad_sequences(new_ids, max_length, pad_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDP15\\AppData\\Local\\Temp\\ipykernel_4516\\2756406480.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('best_model.pth', map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceClassifier(\n",
       "  (embedding): Embedding(5002, 128, padding_idx=0)\n",
       "  (model): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (classifier): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load('best_model.pth', map_location=device)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "줄거리: 년대 한국전쟁 직후 가난했지만 낭만이 있던 시대 초괴의 국극 배우에 도전하는 타고난 소리천재 정년이를 둘러싼 경쟁과 연대 그리고 찬란한 성장기\n",
      "예측된 등급: 15세\n"
     ]
    }
   ],
   "source": [
    "# 8. 모델 예측\n",
    "new_ids_tensor = torch.tensor(new_ids_padded).to(device)  # 데이터를 모델이 있는 디바이스로 이동\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(new_ids_tensor)\n",
    "    predictions = torch.sigmoid(outputs)\n",
    "\n",
    "# 9. 예측 결과 출력 (0.5 이상이면 긍정, 미만이면 부정)\n",
    "for i, review in enumerate(new_reviews):\n",
    "    prediction = 1 if predictions[i] >= 0.5 else 0\n",
    "    print(f\"줄거리: {review}\")\n",
    "    print(f\"예측된 등급: {'15세' if prediction == 1 else '나머지'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WEB_AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
